{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/walml/repos/zoobot/notebooks/multiq\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already up-to-date.\n"
     ]
    }
   ],
   "source": [
    "!git pull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import argparse\n",
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib.ticker import StrMethodFormatter\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import seaborn as sns\n",
    "from sklearn import metrics\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from astropy.table import Table  # for NSA\n",
    "from astropy import units as u\n",
    "from sklearn.metrics import confusion_matrix, roc_curve\n",
    "from PIL import Image\n",
    "from scipy.stats import binom\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "from shared_astro_utils import astropy_utils, matching_utils\n",
    "from zoobot.estimators import make_predictions, bayesian_estimator_funcs\n",
    "from zoobot.tfrecord import read_tfrecord\n",
    "from zoobot.uncertainty import discrete_coverage\n",
    "from zoobot.estimators import input_utils, losses\n",
    "from zoobot.tfrecord import catalog_to_tfrecord\n",
    "from zoobot.active_learning import metrics, simulated_metrics, acquisition_utils, check_uncertainty, simulation_timeline, run_estimator_config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    for gpu in gpus:\n",
    "        tf.config.experimental.set_memory_growth(gpu, True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/home/walml/repos/zoobot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start = 50\n",
    "# end = 60\n",
    "start = 0\n",
    "end=5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the (latest) model under `model_name` folder in `results_dir`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/walml/anaconda3/envs/zoobot/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3063: DtypeWarning: Columns (109) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "# catalog_loc = 'data/latest_labelled_catalog.csv\n",
    "catalog_loc = 'data/decals/decals_master_catalog.csv'\n",
    "catalog = pd.read_csv(catalog_loc, dtype={'subject_id': str})  # original catalog\n",
    "# catalog = catalog[:5000]  \n",
    "catalog['file_loc'] = catalog['local_png_loc'].apply(lambda x: '/media/walml/beta/decals/png_native' + x[32:])\n",
    "\n",
    "model_name = 'latest_offline'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Loading multiple tfrecords with interleaving, shuffle=False\n",
      "WARNING:root:Loading multiple tfrecords with interleaving, shuffle=False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/walml/repos/zoobot/data/decals/shards/decals_multiq_128_sim_init_2500_featp4/train_shards/s128_shard_0.tfrecord']\n",
      "loading filenames: <TensorSliceDataset shapes: (), types: tf.string>\n",
      "loading filenames: <TensorSliceDataset shapes: (), types: tf.string>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['J121451.23-032922.1',\n",
       " 'J133349.60+031857.9',\n",
       " 'J100515.67+012721.9',\n",
       " 'J112416.49+091915.4',\n",
       " 'J092951.96+072551.4']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Figures will be saved to here\n",
    "\n",
    "analysis_dir = 'analysis/multiquestion'\n",
    "save_dir = f'{analysis_dir}/{model_name}'\n",
    "if not os.path.exists(save_dir):\n",
    "    os.mkdir(save_dir)\n",
    "\n",
    "results_dir = '/home/walml/repos/zoobot/data/experiments/live/no_cutouts/iteration_0'\n",
    "\n",
    "label_cols = [\n",
    "    'smooth-or-featured_smooth',\n",
    "    'smooth-or-featured_featured-or-disk',\n",
    "    'has-spiral-arms_yes',\n",
    "    'has-spiral-arms_no',\n",
    "#     'spiral-winding_tight',\n",
    "#     'spiral-winding_medium',\n",
    "#     'spiral-winding_loose',\n",
    "    'bar_strong',\n",
    "    'bar_weak',\n",
    "    'bar_no',\n",
    "    'bulge-size_dominant',\n",
    "    'bulge-size_large',\n",
    "    'bulge-size_moderate',\n",
    "    'bulge-size_small',\n",
    "    'bulge-size_none'\n",
    "]\n",
    "\n",
    "questions = [\n",
    "    'smooth-or-featured',\n",
    "    'has-spiral-arms',\n",
    "#     'spiral-winding',\n",
    "    'bar',\n",
    "    'bulge-size'\n",
    "]\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "initial_size = 128\n",
    "final_size = 128\n",
    "channels = 3\n",
    "\n",
    "n_samples = 5\n",
    "\n",
    "# if loading single test tfrecord\n",
    "# tfrecord_locs = [f'data/decals/shards/multilabel_{img_size}/eval/s{initial_size}_shard_0.tfrecord']\n",
    "# tfrecord_locs = ['data/decals/shards/multilabel_master_256/train/s256_shard_0.tfrecord']\n",
    "# tfrecord_locs = glob.glob(f'/media/walml/beta/decals/multilabel_master_{initial_size}/train/*.tfrecord')[start:end]\n",
    "tfrecord_locs = glob.glob(f'/home/walml/repos/zoobot/data/decals/shards/decals_multiq_{initial_size}_sim_init_2500_featp4/train_shards/*.tfrecord')[start:end]\n",
    "\n",
    "# tfrecord_locs = ['data/decals/shards/multilabel_all_temp/train/s128_shard_0.tfrecord']\n",
    "print(tfrecord_locs)\n",
    "eval_config = run_estimator_config.get_eval_config(tfrecord_locs, label_cols, batch_size, initial_size, final_size, channels)\n",
    "dataset = input_utils.get_input(config=eval_config)\n",
    "\n",
    "feature_spec = input_utils.get_feature_spec({'id_str': 'string'})\n",
    "id_str_dataset = input_utils.get_dataset(tfrecord_locs, feature_spec, batch_size=1, shuffle=False, repeat=False)\n",
    "id_strs = [str(d['id_str'].numpy().squeeze())[2:-1] for d in id_str_dataset]\n",
    "id_strs[:5]\n",
    "\n",
    "# n = 0\n",
    "# for batch in id_str_dataset:\n",
    "#     for id_str in batch:\n",
    "#         n+=1\n",
    "# print(n)\n",
    "\n",
    "# counter = Counter()\n",
    "# n = 0\n",
    "# for g_batch, y_batch in dataset:\n",
    "# #     for g in g_batch:\n",
    "# #         counter[g.numpy().sum()] += 1\n",
    "#         n+=tf.shape(g_batch)[0]\n",
    "# print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2592"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(id_strs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # if loading png\n",
    "\n",
    "# print(catalog['file_loc'])\n",
    "# assert all([os.path.isfile(x) for x in catalog['file_loc']])\n",
    "# filenames = tf.constant(list(catalog['file_loc']), dtype=tf.string)\n",
    "# dataset = tf.data.Dataset.from_tensor_slices(filenames)\n",
    "\n",
    "# def parse_image(im):\n",
    "#     im = tf.image.decode_png(im, channels=channels)\n",
    "#     im = tf.image.convert_image_dtype(im, tf.float32)\n",
    "#     im = tf.image.resize(im, [initial_size, initial_size])\n",
    "#     return im\n",
    "\n",
    "\n",
    "# # for im in dataset.take(1):\n",
    "# #     print(im)\n",
    "\n",
    "# # assert False\n",
    "\n",
    "# dataset = dataset.map(tf.io.read_file)\n",
    "# dataset = dataset.map(parse_image)\n",
    "\n",
    "# config = default_estimator_params.get_eval_config(['do not use'], label_cols, batch_size, initial_size, final_size, channels)\n",
    "\n",
    "# dataset = dataset.batch(batch_size)\n",
    "\n",
    "# # for batch in dataset.take(1):\n",
    "# #     print(tf.shape(batch))\n",
    "# # #     plt.imshow(batch[0])\n",
    "\n",
    "\n",
    "# # dataset = dataset.map(lambda x: check_shape(x))\n",
    "\n",
    "# dataset = dataset.map(lambda x: input_utils.preprocess_images(x, config))\n",
    "\n",
    "\n",
    "# # for batch in dataset.take(1):\n",
    "# #     print(tf.shape(batch))\n",
    "# #     plt.imshow(batch[0].numpy().squeeze())\n",
    "\n",
    "\n",
    "# id_strs = catalog['iauname']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{smooth-or-featured, indices 0 to 1, asked after None: (0, 1), has-spiral-arms, indices 2 to 3, asked after <zoobot.estimators.losses.Answer object at 0x7f1d7d107b90>: (2, 3), bar, indices 4 to 6, asked after <zoobot.estimators.losses.Answer object at 0x7f1d7d107b90>: (4, 6), bulge-size, indices 7 to 11, asked after <zoobot.estimators.losses.Answer object at 0x7f1d7d107b90>: (7, 11)}\n",
      "Name: smooth-or-featured, start 0, end 1\n",
      "Name: has-spiral-arms, start 2, end 3\n",
      "Name: bar, start 4, end 6\n",
      "Name: bulge-size, start 7, end 11\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f1d7e93d550>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = run_estimator_config.get_model(label_cols, questions, final_size)\n",
    "\n",
    "checkpoint_dir = f'{results_dir}/estimators/models'\n",
    "# checkpoint_dir = f'{results_dir}/{model_name}/results/models'\n",
    "model.load_weights(checkpoint_dir)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %timeit predictions = model.predict(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<MapDataset shapes: ((None, 128, 128, 1), (None, 12)), types: (tf.float32, tf.float32)>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.predict(dataset).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 1), (2, 3), (4, 6), (7, 11)]\n",
      "0 1\n",
      "2 3\n",
      "4 6\n",
      "7 11\n"
     ]
    }
   ],
   "source": [
    "predictions = np.stack([model.predict(dataset) for n in range(n_samples)], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2592, 12, 5)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for batch_x, batch_y in dataset:\n",
    "#     print(batch_y.numpy())\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels = np.concatenate([batch_y for (_, batch_y) in test_dataset], axis=0)\n",
    "# labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = catalog[label_cols].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots()\n",
    "# ax.hist(predictions[:, 0], alpha=0.5, label='Predictions', density=True)\n",
    "# ax.hist(labels[:, 0] / labels[:, :2].sum(axis=1), alpha=0.5, label='Labels', density=True)\n",
    "# plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(predictions[:, 0].min(), labels[:, 0].min())\n",
    "# print(predictions[:, 0].max(), labels[:, 0].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{smooth-or-featured, indices 0 to 1, asked after None: (0, 1), has-spiral-arms, indices 2 to 3, asked after <zoobot.estimators.losses.Answer object at 0x7f1d90460110>: (2, 3), bar, indices 4 to 6, asked after <zoobot.estimators.losses.Answer object at 0x7f1d90460110>: (4, 6), bulge-size, indices 7 to 11, asked after <zoobot.estimators.losses.Answer object at 0x7f1d90460110>: (7, 11)}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[smooth-or-featured, indices 0 to 1, asked after None,\n",
       " has-spiral-arms, indices 2 to 3, asked after <zoobot.estimators.losses.Answer object at 0x7f1d90460110>,\n",
       " bar, indices 4 to 6, asked after <zoobot.estimators.losses.Answer object at 0x7f1d90460110>,\n",
       " bulge-size, indices 7 to 11, asked after <zoobot.estimators.losses.Answer object at 0x7f1d90460110>]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema = losses.Schema(label_cols, questions)\n",
    "schema.questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# acquisitions = acquisition_utils.mutual_info_acquisition_func_multiq(predictions, schema, retirement=40)\n",
    "# acquisitions.shape\n",
    "# acquisitions\n",
    "\n",
    "# single_q_acquisitions = np.array(acquisition_utils.mutual_info_acquisition_func(predictions[:, 0], expected_votes=40))\n",
    "# single_q_acquisitions[:5], acquisitions[0, :5], acquisitions[1, :5]  # smooth mutual acq should be identical, for both answers by symmmetry\n",
    "# acquisitions[2, :5], acquisitions[3, :5]  # has-spiral-arms also by symmetry\n",
    "# acquisitions[4, :5], acquisitions[5, :5], acquisitions[6, :5]  # but for spiral winding there are 3 answers so *not* identical\n",
    "# predictions.shape, acquisitions.shape, len(id_strs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2592, 12, 5), 2592)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.shape, len(id_strs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.14755389, 0.10230154, 0.03980467, 0.06891213, 0.0749781 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_to_row(prediction, id_str):\n",
    "    row = {\n",
    "        'id_str': id_str\n",
    "    }\n",
    "    for n, col in enumerate(label_cols):\n",
    "        answer = label_cols[n]\n",
    "        row[answer + '_prediction'] = json.dumps(list(prediction[n].astype(float)))\n",
    "#         row[answer + '_acquisition'] = acquisition[n]\n",
    "        row[answer + '_prediction_mean'] = float(prediction[n].mean())\n",
    "#         row[answer + '_acquisition'] = acquisition[n]\n",
    "#         row['total_acquisition'] = acquisition.sum()\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_to_row(prediction, acquisition, id_str):\n",
    "    row = {\n",
    "        'id_str': id_str\n",
    "    }\n",
    "    for n, col in enumerate(label_cols):\n",
    "        answer = label_cols[n]\n",
    "        row[answer + '_prediction'] = prediction[n]\n",
    "#         row[answer + '_acquisition'] = acquisition[n]\n",
    "        row[answer + '_prediction_mean'] = float(prediction[n].mean())\n",
    "#         row[answer + '_acquisition'] = acquisition[n]\n",
    "#         row['total_acquisition'] = acquisition.sum()\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [prediction_to_row(predictions[n], id_strs[n]) for n in range(len(predictions))]\n",
    "# data = [all_to_row(predictions[n], acquisitions[n], id_strs[n]) for n in range(len(predictions))]\n",
    "predictions_df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2592"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predictions_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_str</th>\n",
       "      <th>smooth-or-featured_smooth_prediction</th>\n",
       "      <th>smooth-or-featured_smooth_prediction_mean</th>\n",
       "      <th>smooth-or-featured_featured-or-disk_prediction</th>\n",
       "      <th>smooth-or-featured_featured-or-disk_prediction_mean</th>\n",
       "      <th>has-spiral-arms_yes_prediction</th>\n",
       "      <th>has-spiral-arms_yes_prediction_mean</th>\n",
       "      <th>has-spiral-arms_no_prediction</th>\n",
       "      <th>has-spiral-arms_no_prediction_mean</th>\n",
       "      <th>bar_strong_prediction</th>\n",
       "      <th>...</th>\n",
       "      <th>bulge-size_dominant_prediction</th>\n",
       "      <th>bulge-size_dominant_prediction_mean</th>\n",
       "      <th>bulge-size_large_prediction</th>\n",
       "      <th>bulge-size_large_prediction_mean</th>\n",
       "      <th>bulge-size_moderate_prediction</th>\n",
       "      <th>bulge-size_moderate_prediction_mean</th>\n",
       "      <th>bulge-size_small_prediction</th>\n",
       "      <th>bulge-size_small_prediction_mean</th>\n",
       "      <th>bulge-size_none_prediction</th>\n",
       "      <th>bulge-size_none_prediction_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>J121451.23-032922.1</td>\n",
       "      <td>[0.14755389094352722, 0.10230153799057007, 0.0...</td>\n",
       "      <td>0.086710</td>\n",
       "      <td>[0.8524460792541504, 0.8976984620094299, 0.960...</td>\n",
       "      <td>0.913290</td>\n",
       "      <td>[0.6385693550109863, 0.6716393828392029, 0.911...</td>\n",
       "      <td>0.789702</td>\n",
       "      <td>[0.36143064498901367, 0.32836058735847473, 0.0...</td>\n",
       "      <td>0.210298</td>\n",
       "      <td>[0.4039973020553589, 0.37534236907958984, 0.30...</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.029366053640842438, 0.022077526897192, 0.00...</td>\n",
       "      <td>0.019336</td>\n",
       "      <td>[0.2234601378440857, 0.15756864845752716, 0.05...</td>\n",
       "      <td>0.140846</td>\n",
       "      <td>[0.6638651490211487, 0.6986970901489258, 0.670...</td>\n",
       "      <td>0.647024</td>\n",
       "      <td>[0.0810803771018982, 0.11980143189430237, 0.26...</td>\n",
       "      <td>0.188566</td>\n",
       "      <td>[0.0022282316349446774, 0.0018553226254880428,...</td>\n",
       "      <td>0.004228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>J133349.60+031857.9</td>\n",
       "      <td>[0.489976167678833, 0.21643505990505219, 0.264...</td>\n",
       "      <td>0.335506</td>\n",
       "      <td>[0.510023832321167, 0.7835649251937866, 0.7359...</td>\n",
       "      <td>0.664494</td>\n",
       "      <td>[0.503817081451416, 0.5575586557388306, 0.6817...</td>\n",
       "      <td>0.532710</td>\n",
       "      <td>[0.49618294835090637, 0.4424413740634918, 0.31...</td>\n",
       "      <td>0.467290</td>\n",
       "      <td>[0.22051766514778137, 0.27213191986083984, 0.2...</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.05379382148385048, 0.08663059771060944, 0.0...</td>\n",
       "      <td>0.070095</td>\n",
       "      <td>[0.23564006388187408, 0.43573322892189026, 0.2...</td>\n",
       "      <td>0.336633</td>\n",
       "      <td>[0.4263281226158142, 0.3263751268386841, 0.494...</td>\n",
       "      <td>0.402551</td>\n",
       "      <td>[0.18568971753120422, 0.08520590513944626, 0.1...</td>\n",
       "      <td>0.133640</td>\n",
       "      <td>[0.09854821860790253, 0.06605516374111176, 0.0...</td>\n",
       "      <td>0.057082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>J100515.67+012721.9</td>\n",
       "      <td>[0.5734354853630066, 0.48100507259368896, 0.60...</td>\n",
       "      <td>0.555694</td>\n",
       "      <td>[0.4265645444393158, 0.518994927406311, 0.3995...</td>\n",
       "      <td>0.444306</td>\n",
       "      <td>[0.653565526008606, 0.7093324661254883, 0.6158...</td>\n",
       "      <td>0.669364</td>\n",
       "      <td>[0.34643444418907166, 0.2906675338745117, 0.38...</td>\n",
       "      <td>0.330636</td>\n",
       "      <td>[0.06096137315034866, 0.052049100399017334, 0....</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.013473396189510822, 0.01462953444570303, 0....</td>\n",
       "      <td>0.015411</td>\n",
       "      <td>[0.03820888698101044, 0.034939009696245193, 0....</td>\n",
       "      <td>0.038755</td>\n",
       "      <td>[0.23463788628578186, 0.2413453906774521, 0.20...</td>\n",
       "      <td>0.235645</td>\n",
       "      <td>[0.4517900049686432, 0.480917751789093, 0.4158...</td>\n",
       "      <td>0.448675</td>\n",
       "      <td>[0.26188981533050537, 0.2281682938337326, 0.30...</td>\n",
       "      <td>0.261513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>J112416.49+091915.4</td>\n",
       "      <td>[0.4913593530654907, 0.46961498260498047, 0.37...</td>\n",
       "      <td>0.432307</td>\n",
       "      <td>[0.508640706539154, 0.5303850173950195, 0.6278...</td>\n",
       "      <td>0.567693</td>\n",
       "      <td>[0.40714961290359497, 0.4490378797054291, 0.61...</td>\n",
       "      <td>0.519176</td>\n",
       "      <td>[0.592850387096405, 0.5509620904922485, 0.3870...</td>\n",
       "      <td>0.480824</td>\n",
       "      <td>[0.22937080264091492, 0.20339684188365936, 0.2...</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.026339923962950706, 0.04025294631719589, 0....</td>\n",
       "      <td>0.035443</td>\n",
       "      <td>[0.19396300613880157, 0.28893473744392395, 0.2...</td>\n",
       "      <td>0.237656</td>\n",
       "      <td>[0.6766250133514404, 0.5380905866622925, 0.574...</td>\n",
       "      <td>0.575264</td>\n",
       "      <td>[0.09495995193719864, 0.11039053648710251, 0.1...</td>\n",
       "      <td>0.123194</td>\n",
       "      <td>[0.008112139068543911, 0.022331252694129944, 0...</td>\n",
       "      <td>0.028442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>J092951.96+072551.4</td>\n",
       "      <td>[0.1090061366558075, 0.1872037649154663, 0.174...</td>\n",
       "      <td>0.135098</td>\n",
       "      <td>[0.8909938335418701, 0.8127962350845337, 0.825...</td>\n",
       "      <td>0.864902</td>\n",
       "      <td>[0.8199202418327332, 0.7580419182777405, 0.663...</td>\n",
       "      <td>0.781530</td>\n",
       "      <td>[0.18007972836494446, 0.24195806682109833, 0.3...</td>\n",
       "      <td>0.218470</td>\n",
       "      <td>[0.2977684438228607, 0.27684277296066284, 0.38...</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.011350319720804691, 0.014973313547670841, 0...</td>\n",
       "      <td>0.012354</td>\n",
       "      <td>[0.06438402831554413, 0.14966845512390137, 0.1...</td>\n",
       "      <td>0.107079</td>\n",
       "      <td>[0.6826044321060181, 0.7302970290184021, 0.743...</td>\n",
       "      <td>0.711494</td>\n",
       "      <td>[0.2348530888557434, 0.10250520706176758, 0.10...</td>\n",
       "      <td>0.164697</td>\n",
       "      <td>[0.006808120291680098, 0.002556057181209326, 0...</td>\n",
       "      <td>0.004377</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                id_str               smooth-or-featured_smooth_prediction  \\\n",
       "0  J121451.23-032922.1  [0.14755389094352722, 0.10230153799057007, 0.0...   \n",
       "1  J133349.60+031857.9  [0.489976167678833, 0.21643505990505219, 0.264...   \n",
       "2  J100515.67+012721.9  [0.5734354853630066, 0.48100507259368896, 0.60...   \n",
       "3  J112416.49+091915.4  [0.4913593530654907, 0.46961498260498047, 0.37...   \n",
       "4  J092951.96+072551.4  [0.1090061366558075, 0.1872037649154663, 0.174...   \n",
       "\n",
       "   smooth-or-featured_smooth_prediction_mean  \\\n",
       "0                                   0.086710   \n",
       "1                                   0.335506   \n",
       "2                                   0.555694   \n",
       "3                                   0.432307   \n",
       "4                                   0.135098   \n",
       "\n",
       "      smooth-or-featured_featured-or-disk_prediction  \\\n",
       "0  [0.8524460792541504, 0.8976984620094299, 0.960...   \n",
       "1  [0.510023832321167, 0.7835649251937866, 0.7359...   \n",
       "2  [0.4265645444393158, 0.518994927406311, 0.3995...   \n",
       "3  [0.508640706539154, 0.5303850173950195, 0.6278...   \n",
       "4  [0.8909938335418701, 0.8127962350845337, 0.825...   \n",
       "\n",
       "   smooth-or-featured_featured-or-disk_prediction_mean  \\\n",
       "0                                           0.913290     \n",
       "1                                           0.664494     \n",
       "2                                           0.444306     \n",
       "3                                           0.567693     \n",
       "4                                           0.864902     \n",
       "\n",
       "                      has-spiral-arms_yes_prediction  \\\n",
       "0  [0.6385693550109863, 0.6716393828392029, 0.911...   \n",
       "1  [0.503817081451416, 0.5575586557388306, 0.6817...   \n",
       "2  [0.653565526008606, 0.7093324661254883, 0.6158...   \n",
       "3  [0.40714961290359497, 0.4490378797054291, 0.61...   \n",
       "4  [0.8199202418327332, 0.7580419182777405, 0.663...   \n",
       "\n",
       "   has-spiral-arms_yes_prediction_mean  \\\n",
       "0                             0.789702   \n",
       "1                             0.532710   \n",
       "2                             0.669364   \n",
       "3                             0.519176   \n",
       "4                             0.781530   \n",
       "\n",
       "                       has-spiral-arms_no_prediction  \\\n",
       "0  [0.36143064498901367, 0.32836058735847473, 0.0...   \n",
       "1  [0.49618294835090637, 0.4424413740634918, 0.31...   \n",
       "2  [0.34643444418907166, 0.2906675338745117, 0.38...   \n",
       "3  [0.592850387096405, 0.5509620904922485, 0.3870...   \n",
       "4  [0.18007972836494446, 0.24195806682109833, 0.3...   \n",
       "\n",
       "   has-spiral-arms_no_prediction_mean  \\\n",
       "0                            0.210298   \n",
       "1                            0.467290   \n",
       "2                            0.330636   \n",
       "3                            0.480824   \n",
       "4                            0.218470   \n",
       "\n",
       "                               bar_strong_prediction  ...  \\\n",
       "0  [0.4039973020553589, 0.37534236907958984, 0.30...  ...   \n",
       "1  [0.22051766514778137, 0.27213191986083984, 0.2...  ...   \n",
       "2  [0.06096137315034866, 0.052049100399017334, 0....  ...   \n",
       "3  [0.22937080264091492, 0.20339684188365936, 0.2...  ...   \n",
       "4  [0.2977684438228607, 0.27684277296066284, 0.38...  ...   \n",
       "\n",
       "                      bulge-size_dominant_prediction  \\\n",
       "0  [0.029366053640842438, 0.022077526897192, 0.00...   \n",
       "1  [0.05379382148385048, 0.08663059771060944, 0.0...   \n",
       "2  [0.013473396189510822, 0.01462953444570303, 0....   \n",
       "3  [0.026339923962950706, 0.04025294631719589, 0....   \n",
       "4  [0.011350319720804691, 0.014973313547670841, 0...   \n",
       "\n",
       "  bulge-size_dominant_prediction_mean  \\\n",
       "0                            0.019336   \n",
       "1                            0.070095   \n",
       "2                            0.015411   \n",
       "3                            0.035443   \n",
       "4                            0.012354   \n",
       "\n",
       "                         bulge-size_large_prediction  \\\n",
       "0  [0.2234601378440857, 0.15756864845752716, 0.05...   \n",
       "1  [0.23564006388187408, 0.43573322892189026, 0.2...   \n",
       "2  [0.03820888698101044, 0.034939009696245193, 0....   \n",
       "3  [0.19396300613880157, 0.28893473744392395, 0.2...   \n",
       "4  [0.06438402831554413, 0.14966845512390137, 0.1...   \n",
       "\n",
       "  bulge-size_large_prediction_mean  \\\n",
       "0                         0.140846   \n",
       "1                         0.336633   \n",
       "2                         0.038755   \n",
       "3                         0.237656   \n",
       "4                         0.107079   \n",
       "\n",
       "                      bulge-size_moderate_prediction  \\\n",
       "0  [0.6638651490211487, 0.6986970901489258, 0.670...   \n",
       "1  [0.4263281226158142, 0.3263751268386841, 0.494...   \n",
       "2  [0.23463788628578186, 0.2413453906774521, 0.20...   \n",
       "3  [0.6766250133514404, 0.5380905866622925, 0.574...   \n",
       "4  [0.6826044321060181, 0.7302970290184021, 0.743...   \n",
       "\n",
       "  bulge-size_moderate_prediction_mean  \\\n",
       "0                            0.647024   \n",
       "1                            0.402551   \n",
       "2                            0.235645   \n",
       "3                            0.575264   \n",
       "4                            0.711494   \n",
       "\n",
       "                         bulge-size_small_prediction  \\\n",
       "0  [0.0810803771018982, 0.11980143189430237, 0.26...   \n",
       "1  [0.18568971753120422, 0.08520590513944626, 0.1...   \n",
       "2  [0.4517900049686432, 0.480917751789093, 0.4158...   \n",
       "3  [0.09495995193719864, 0.11039053648710251, 0.1...   \n",
       "4  [0.2348530888557434, 0.10250520706176758, 0.10...   \n",
       "\n",
       "  bulge-size_small_prediction_mean  \\\n",
       "0                         0.188566   \n",
       "1                         0.133640   \n",
       "2                         0.448675   \n",
       "3                         0.123194   \n",
       "4                         0.164697   \n",
       "\n",
       "                          bulge-size_none_prediction  \\\n",
       "0  [0.0022282316349446774, 0.0018553226254880428,...   \n",
       "1  [0.09854821860790253, 0.06605516374111176, 0.0...   \n",
       "2  [0.26188981533050537, 0.2281682938337326, 0.30...   \n",
       "3  [0.008112139068543911, 0.022331252694129944, 0...   \n",
       "4  [0.006808120291680098, 0.002556057181209326, 0...   \n",
       "\n",
       "  bulge-size_none_prediction_mean  \n",
       "0                        0.004228  \n",
       "1                        0.057082  \n",
       "2                        0.261513  \n",
       "3                        0.028442  \n",
       "4                        0.004377  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df['iauname'] = predictions_df['id_str']\n",
    "df = pd.merge(catalog, predictions_df, how='inner', on='iauname')\n",
    "len(df)\n",
    "assert len(df) == len(predictions_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Unnamed: 0', 'iauname', 'nsa_id', 'ra_subject', 'dec_subject',\n",
       "       'petrotheta', 'petroth50', 'petroth90', 'redshift',\n",
       "       'local_fits_loc', 'local_png_loc', 'fits_ready', 'fits_filled',\n",
       "       'png_ready', 'best_match', 'sky_separation', 'nsa_version', 'mag',\n",
       "       'ra', 'dec', 'file_loc', 'subject_id', 'bar_no', 'bar_strong',\n",
       "       'bar_weak', 'bulge-size_dominant', 'bulge-size_large',\n",
       "       'bulge-size_moderate', 'bulge-size_none', 'bulge-size_small',\n",
       "       'disk-edge-on_no', 'disk-edge-on_yes', 'edge-on-bulge_boxy',\n",
       "       'edge-on-bulge_none', 'edge-on-bulge_rounded',\n",
       "       'has-spiral-arms_no', 'has-spiral-arms_yes',\n",
       "       'how-rounded_cigar-shaped', 'how-rounded_in-between',\n",
       "       'how-rounded_round', 'merging_both-v1',\n",
       "       'merging_major-disturbance', 'merging_merger',\n",
       "       'merging_minor-disturbance', 'merging_neither-v1', 'merging_none',\n",
       "       'merging_tidal-debris-v1', 'smooth-or-featured_artifact',\n",
       "       'smooth-or-featured_featured-or-disk', 'smooth-or-featured_smooth',\n",
       "       'spiral-arm-count_1', 'spiral-arm-count_2', 'spiral-arm-count_3',\n",
       "       'spiral-arm-count_4', 'spiral-arm-count_cant-tell',\n",
       "       'spiral-arm-count_more-than-4', 'spiral-winding_loose',\n",
       "       'spiral-winding_medium', 'spiral-winding_tight',\n",
       "       'smooth-or-featured_total-votes', 'how-rounded_total-votes',\n",
       "       'disk-edge-on_total-votes', 'edge-on-bulge_total-votes',\n",
       "       'bar_total-votes', 'has-spiral-arms_total-votes',\n",
       "       'spiral-winding_total-votes', 'spiral-arm-count_total-votes',\n",
       "       'bulge-size_total-votes', 'merging_total-votes',\n",
       "       'smooth-or-featured_smooth_fraction',\n",
       "       'smooth-or-featured_featured-or-disk_fraction',\n",
       "       'smooth-or-featured_artifact_fraction',\n",
       "       'how-rounded_round_fraction', 'how-rounded_in-between_fraction',\n",
       "       'how-rounded_cigar-shaped_fraction', 'disk-edge-on_yes_fraction',\n",
       "       'disk-edge-on_no_fraction', 'edge-on-bulge_rounded_fraction',\n",
       "       'edge-on-bulge_boxy_fraction', 'edge-on-bulge_none_fraction',\n",
       "       'bar_strong_fraction', 'bar_weak_fraction', 'bar_no_fraction',\n",
       "       'has-spiral-arms_yes_fraction', 'has-spiral-arms_no_fraction',\n",
       "       'spiral-winding_tight_fraction', 'spiral-winding_medium_fraction',\n",
       "       'spiral-winding_loose_fraction', 'spiral-arm-count_1_fraction',\n",
       "       'spiral-arm-count_2_fraction', 'spiral-arm-count_3_fraction',\n",
       "       'spiral-arm-count_4_fraction',\n",
       "       'spiral-arm-count_more-than-4_fraction',\n",
       "       'spiral-arm-count_cant-tell_fraction', 'bulge-size_none_fraction',\n",
       "       'bulge-size_small_fraction', 'bulge-size_moderate_fraction',\n",
       "       'bulge-size_large_fraction', 'bulge-size_dominant_fraction',\n",
       "       'merging_merger_fraction', 'merging_tidal-debris-v1_fraction',\n",
       "       'merging_both-v1_fraction', 'merging_neither-v1_fraction',\n",
       "       'merging_major-disturbance_fraction',\n",
       "       'merging_minor-disturbance_fraction', 'merging_none_fraction',\n",
       "       'retirement_limit', 'subject_url', 'upload_date', 'uploader',\n",
       "       'id_str', 'smooth-or-featured_smooth_prediction',\n",
       "       'smooth-or-featured_smooth_prediction_mean',\n",
       "       'smooth-or-featured_featured-or-disk_prediction',\n",
       "       'smooth-or-featured_featured-or-disk_prediction_mean',\n",
       "       'has-spiral-arms_yes_prediction',\n",
       "       'has-spiral-arms_yes_prediction_mean',\n",
       "       'has-spiral-arms_no_prediction',\n",
       "       'has-spiral-arms_no_prediction_mean', 'bar_strong_prediction',\n",
       "       'bar_strong_prediction_mean', 'bar_weak_prediction',\n",
       "       'bar_weak_prediction_mean', 'bar_no_prediction',\n",
       "       'bar_no_prediction_mean', 'bulge-size_dominant_prediction',\n",
       "       'bulge-size_dominant_prediction_mean',\n",
       "       'bulge-size_large_prediction', 'bulge-size_large_prediction_mean',\n",
       "       'bulge-size_moderate_prediction',\n",
       "       'bulge-size_moderate_prediction_mean',\n",
       "       'bulge-size_small_prediction', 'bulge-size_small_prediction_mean',\n",
       "       'bulge-size_none_prediction', 'bulge-size_none_prediction_mean'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       https://panoptes-uploads.zooniverse.org/produc...\n",
       "1       https://panoptes-uploads.zooniverse.org/produc...\n",
       "2       https://panoptes-uploads.zooniverse.org/produc...\n",
       "3       https://panoptes-uploads.zooniverse.org/produc...\n",
       "4       https://panoptes-uploads.zooniverse.org/produc...\n",
       "                              ...                        \n",
       "2587    https://panoptes-uploads.zooniverse.org/produc...\n",
       "2588    https://panoptes-uploads.zooniverse.org/produc...\n",
       "2589    https://panoptes-uploads.zooniverse.org/produc...\n",
       "2590    https://panoptes-uploads.zooniverse.org/produc...\n",
       "2591    https://panoptes-uploads.zooniverse.org/produc...\n",
       "Name: subject_url, Length: 2592, dtype: object"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['subject_url']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       /media/walml/beta/decals/png_native/dr5/J113/J...\n",
       "1       /media/walml/beta/decals/png_native/dr5/J114/J...\n",
       "2       /media/walml/beta/decals/png_native/dr5/J115/J...\n",
       "3       /media/walml/beta/decals/png_native/dr5/J115/J...\n",
       "4       /media/walml/beta/decals/png_native/dr5/J114/J...\n",
       "                              ...                        \n",
       "2587    /media/walml/beta/decals/png_native/dr5/J143/J...\n",
       "2588    /media/walml/beta/decals/png_native/dr5/J150/J...\n",
       "2589    /media/walml/beta/decals/png_native/dr5/J151/J...\n",
       "2590    /media/walml/beta/decals/png_native/dr5/J154/J...\n",
       "2591    /media/walml/beta/decals/png_native/dr5/J144/J...\n",
       "Name: file_loc, Length: 2592, dtype: object"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['file_loc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('temp/master_256_predictions_{}_{}.csv'.format(start, end), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-a871fdc9ebee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copied from trust_the_model.ipynb\n",
    "def show_galaxies(df, scale=3, nrows=3, ncols=3):\n",
    "    fig = plt.gcf()\n",
    "\n",
    "    plt.figure(figsize=(scale * nrows, scale * ncols * 1.025))\n",
    "    gs1 = gridspec.GridSpec(nrows, ncols)\n",
    "    gs1.update(wspace=0.0, hspace=0.0)\n",
    "    galaxy_n = 0\n",
    "    for row_n in range(nrows):\n",
    "        for col_n in range(ncols):\n",
    "            galaxy = df.iloc[galaxy_n]\n",
    "            image = Image.open(galaxy['file_loc'])\n",
    "            ax = plt.subplot(gs1[row_n, col_n])\n",
    "            ax.imshow(image)\n",
    "#             ax.text(10, 20, 'Smooth = {:.2f}'.format(galaxy['smooth-or-featured_smooth_fraction']), fontsize=12, color='r')\n",
    "#             ax.text(10, 50, r'$\\rho = {:.2f}$, Var ${:.3f}$'.format(galaxy['median_prediction'], 3*galaxy['predictions_var']), fontsize=12, color='r')\n",
    "#             ax.text(10, 80, '$L = {:.2f}$'.format(galaxy['bcnn_likelihood']), fontsize=12, color='r')\n",
    "            ax.axis('off')\n",
    "            galaxy_n += 1\n",
    "#     print('Mean L: {:.2f}'.format(df[:nrows * ncols]['bcnn_likelihood'].mean()))\n",
    "    fig = plt.gcf()\n",
    "#     fig.tight_layout()\n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def save_top_n(schema, save_dir):\n",
    "    for question in schema.questions:\n",
    "        for answer in question.answers:\n",
    "            fig = show_galaxies(df.sort_values(answer.text + '_prediction_mean', ascending=False)[:9])\n",
    "            fig.savefig(save_dir + '_' + answer.text + '.png')\n",
    "            plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "save_dir = 'results/temp'\n",
    "save_top_n(schema, save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False  # moove later analysis elsewhere?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots()\n",
    "# ax.scatter(predictions[:, 0], labels[:, 0] / labels[:, :2].sum(axis=1))\n",
    "# plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.get_backend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots()\n",
    "# ax.scatter(predictions[:, 4], labels[:, 4] / labels[:, 4:7].sum(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots()\n",
    "# ax.scatter(predictions[:, 5], labels[:, 5] / labels[:, 4:7].sum(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots()\n",
    "# ax.scatter(predictions[:, 6], labels[:, 6] / labels[:, 4:7].sum(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to check that the right models have been loaded - should be around 40 for smooth, 0-40 for bars\n",
    "# plt.hist(sim_model.total_votes), sim_model.total_votes.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualise Posteriors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for systematic offset - in general, model seems slightly skewed towards low k?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_single_answer_data(df, answer, n=10):\n",
    "    samples = np.stack(df[answer.text + '_prediction'][:n])\n",
    "    labels = df[answer.text][:n].values.astype(int)\n",
    "    total_votes = df[answer.question.text + '_total-votes'][:n].values.astype(int)\n",
    "    return samples, labels, total_votes\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_population_stats(samples, labels, total_votes, title):\n",
    "    # sns.set_context('paper')\n",
    "    sns.set(font_scale=1.)\n",
    "    sns.set_style('white')\n",
    "    alpha = 0.5\n",
    "    # matplotlib.rcParams.update({'font.size': 50}\n",
    "    \n",
    "    mean_samples = samples.mean(axis=-1)\n",
    "    expected_k = mean_samples * total_votes\n",
    "\n",
    "    # dummy for bins\n",
    "    fig, (ax0, ax1) = plt.subplots(nrows=2)\n",
    "    _, bins_rho, _ = ax0.hist(labels/ total_votes, bins=25, alpha=alpha, label='Actual')\n",
    "    _, bins_k, _ = ax1.hist(labels, bins=25, alpha=alpha, label='Actual')\n",
    "    plt.close()\n",
    "\n",
    "    # now for real\n",
    "    fig, (ax0, ax1) = plt.subplots(nrows=2)\n",
    "\n",
    "    _, bins, _ = ax0.hist(mean_samples, bins=bins_rho, alpha=alpha, label='Model')\n",
    "    ax0.hist(labels/ total_votes, bins=bins_rho, alpha=alpha, label='Actual')\n",
    "    ax0.set_xlabel(r'Vote Fraction $\\rho$')\n",
    "    ax0.set_ylabel('Galaxies')\n",
    "    ax0.legend()\n",
    "    ax0.set_xlim([0., 1.])\n",
    "\n",
    "    _, bins, _ = ax1.hist(expected_k, bins=bins_k, alpha=alpha, label='Model')\n",
    "    ax1.hist(labels, bins=bins_k, alpha=alpha, label='Actual')\n",
    "    ax1.set_xlabel(r'Positive Responses $k$')\n",
    "    ax1.set_ylabel('Galaxies')\n",
    "    ax1.legend()\n",
    "    ax1.set_xlim([0, 40])\n",
    "\n",
    "    ax0.set_title(title)\n",
    "    fig.tight_layout()\n",
    "    return fig\n",
    "    # fig.savefig(os.path.join(save_dir, 'posterior_over_full_sample.png'))\n",
    "    # fig.savefig(os.path.join(save_dir, 'posterior_over_full_sample.pdf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "answer = schema.get_answer('smooth-or-featured_smooth')\n",
    "samples, labels, total_votes = get_single_answer_data(df, answer, n=len(df))\n",
    "_ = show_population_stats(samples, labels, total_votes, answer.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for answer in schema.answers:\n",
    "    samples, labels, total_votes = get_single_answer_data(df, answer, n=len(df))\n",
    "    fig = show_population_stats(samples, labels, total_votes, answer.text)\n",
    "    fig.savefig(save_dir + '/population_distribution_' + answer.text + '.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_samples(samples, labels, total_votes):\n",
    "    sns.set_context('paper', font_scale=1.5)\n",
    "    fig, axes = plt.subplots(nrows=len(labels), figsize=(3, len(labels)*1.5), sharex=True)\n",
    "    make_predictions.plot_samples(samples, labels, total_votes, fig, axes, alpha=0.06)\n",
    "    for ax in axes:\n",
    "        ax.set_xlim([0, 50])\n",
    "    \n",
    "    for n in range(len(labels)):\n",
    "#         axes[n].set_ylabel(r'$p(v|D)$', visible=True)\n",
    "        axes[n].set_ylabel(r'$p(v|w)$', visible=True)\n",
    "        axes[n].yaxis.set_visible(True)\n",
    "    \n",
    "    axes[-1].set_xlabel('Volunteer Votes')\n",
    "    fig.tight_layout()\n",
    "\n",
    "    axes[0].legend(\n",
    "        loc='lower center', \n",
    "        bbox_to_anchor=(0.5, 1.1),\n",
    "        ncol=1, \n",
    "        fancybox=True, \n",
    "        shadow=False\n",
    "    )\n",
    "    fig.tight_layout()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "question = 'smooth-or-featured'\n",
    "answer = 'smooth'\n",
    "n = 5\n",
    "samples, labels, total_votes = get_single_answer_data(df, question, answer)\n",
    "_ = custom_samples(samples, labels, total_votes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "question = 'has-spiral-arms'\n",
    "answer = 'yes'\n",
    "n = 5\n",
    "samples, labels, total_votes = get_single_answer_data(df, question, answer)\n",
    "_ = custom_samples(samples, labels, total_votes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def galaxy_posterior_grid(df, schema):\n",
    "    \n",
    "    sns.set_context('paper', font_scale=1.5)\n",
    "    \n",
    "    scale = 1.5\n",
    "    \n",
    "    im_width = 2\n",
    "    posterior_width = 3\n",
    "    height = im_width\n",
    "    \n",
    "    n_galaxies = len(df)\n",
    "    n_posteriors = len(schema.answers)\n",
    "    \n",
    "    fig = plt.figure(figsize=(scale * (im_width + posterior_width*n_posteriors), (scale * n_galaxies * height)))  # width, height format\n",
    "    gs = gridspec.GridSpec(len(df) * height, im_width + posterior_width * len(schema.answers))  # y, x format\n",
    "    image_axes = []\n",
    "    posterior_axes = []  # (galaxy i.e. row, answer) shape\n",
    "    \n",
    "    # create the grid\n",
    "    for galaxy_n in range(len(df)):\n",
    "        y_slice = slice(galaxy_n*height, (galaxy_n+1)*height)\n",
    "        image_axes.append(plt.subplot(gs[y_slice, :im_width]))\n",
    "        \n",
    "        temp_galaxy_axes = []\n",
    "        for answer_n, answer in enumerate(schema.answers):\n",
    "            x_slice = slice(im_width+answer_n*posterior_width, im_width+(answer_n+1)*posterior_width)\n",
    "            temp_galaxy_axes.append(plt.subplot(gs[y_slice, x_slice]))\n",
    "        posterior_axes.append(temp_galaxy_axes)\n",
    "        \n",
    "    \n",
    "    # fill the images\n",
    "    for ax_n, ax in enumerate(image_axes):\n",
    "        plot_galaxy(df['file_loc'][ax_n], ax)\n",
    "    \n",
    "    # fill the posteriors\n",
    "    for answer_n, answer in enumerate(schema.answers):\n",
    "        samples, labels, total_votes = get_single_answer_data(df, answer)\n",
    "        galaxy_axes = [axes[answer_n] for axes in posterior_axes]\n",
    "        make_predictions.plot_samples(samples, labels, total_votes, fig, galaxy_axes, alpha=0.06)\n",
    "    \n",
    "    # fix x limits for comparison\n",
    "    for row_n, axes in enumerate(posterior_axes):\n",
    "        for answer_n, ax in enumerate(axes):\n",
    "            ax.set_xlim([0, 50])\n",
    "            if row_n == 0:\n",
    "                ax.set_title(schema.answers[answer_n].text)\n",
    "        \n",
    "#     for n in range(len(labels)):\n",
    "#         multiple_axes[n].set_ylabel(r'$p(k|N, D)$', visible=True)\n",
    "#         multiple_axes[n].yaxis.set_visible(True)\n",
    "#         single_axes[n].set_ylabel(r'$p(k|N, w)$', visible=True)\n",
    "#         single_axes[n].yaxis.set_visible(True)\n",
    "#         single_axes[n].yaxis.set_major_locator(plt.NullLocator())\n",
    "#         multiple_axes[n].yaxis.set_major_locator(plt.NullLocator())\n",
    "#         if n < len(labels) - 1:\n",
    "#             single_axes[n].xaxis.set_major_locator(plt.NullLocator())\n",
    "#             multiple_axes[n].xaxis.set_major_locator(plt.NullLocator())\n",
    "    \n",
    "# #     if QUESTION == 'bars':\n",
    "# #         question = 'Bar'\n",
    "# #     else:\n",
    "# #         question = 'Smooth'\n",
    "# #     single_axes[-1].set_xlabel(r\"$k$ '{}' votes, of $N$ total\".format(question))\n",
    "# #     multiple_axes[-1].set_xlabel(r\"$k$ '{}' votes, of $N$ total\".format(question))\n",
    "#     fig.tight_layout()\n",
    "\n",
    "    \n",
    "#     multiple_axes[0].legend(\n",
    "#         loc='lower center', \n",
    "#         bbox_to_anchor=(0.5, 1.1),\n",
    "#         ncol=1, \n",
    "#         fancybox=True, \n",
    "#         shadow=False\n",
    "#     )\n",
    "\n",
    "    fig.tight_layout()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = galaxy_posterior_grid(df[:5], schema)\n",
    "fig.savefig(save_dir + '/grid.pdf')\n",
    "fig.savefig(save_dir + '/grid.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def custom_samples_with_galaxies(samples, labels, total_votes, png_locs):\n",
    "    \n",
    "    sns.set_context('paper', font_scale=1.5)\n",
    "    \n",
    "    im_width = 2\n",
    "    single_width = 3\n",
    "    multiple_width = 3\n",
    "    height = im_width\n",
    "    \n",
    "    fig = plt.figure(figsize=(0.8 * len(labels) * height * 2., 0.8 * (im_width + single_width + multiple_width) * 1.75))\n",
    "    gs = gridspec.GridSpec(len(labels) * height, im_width + single_width + multiple_width)  # y, x format\n",
    "    image_axes = []\n",
    "    single_axes = []\n",
    "    multiple_axes = []\n",
    "    for galaxy_n in range(len(labels)):\n",
    "        x_slice = slice(galaxy_n*height, (galaxy_n+1)*height)\n",
    "        image_axes.append(plt.subplot(gs[x_slice, :im_width]))\n",
    "        single_axes.append(plt.subplot(gs[x_slice, im_width:im_width+single_width]))\n",
    "        multiple_axes.append(plt.subplot(gs[x_slice, im_width+single_width:]))\n",
    "    \n",
    "\n",
    "#     fig, axes = plt.subplots(nrows=len(labels), figsize=(3, len(labels)*1.5), sharex=True)\n",
    "    make_predictions.plot_samples(samples[:, :1], labels, total_votes, fig, single_axes, alpha=0.06)\n",
    "    for ax in single_axes:\n",
    "        ax.set_xlim([0, 50])\n",
    "\n",
    "    make_predictions.plot_samples(samples, labels, total_votes, fig, multiple_axes, alpha=0.06)\n",
    "    for ax in multiple_axes:\n",
    "        ax.set_xlim([0, 50])\n",
    "        \n",
    "        \n",
    "    for ax_n, ax in enumerate(image_axes):\n",
    "        plot_galaxy(png_locs[ax_n], ax)\n",
    "        \n",
    "    \n",
    "    for n in range(len(labels)):\n",
    "        multiple_axes[n].set_ylabel(r'$p(k|N, D)$', visible=True)\n",
    "        multiple_axes[n].yaxis.set_visible(True)\n",
    "        single_axes[n].set_ylabel(r'$p(k|N, w)$', visible=True)\n",
    "        single_axes[n].yaxis.set_visible(True)\n",
    "        single_axes[n].yaxis.set_major_locator(plt.NullLocator())\n",
    "        multiple_axes[n].yaxis.set_major_locator(plt.NullLocator())\n",
    "        if n < len(labels) - 1:\n",
    "            single_axes[n].xaxis.set_major_locator(plt.NullLocator())\n",
    "            multiple_axes[n].xaxis.set_major_locator(plt.NullLocator())\n",
    "    \n",
    "#     if QUESTION == 'bars':\n",
    "#         question = 'Bar'\n",
    "#     else:\n",
    "#         question = 'Smooth'\n",
    "#     single_axes[-1].set_xlabel(r\"$k$ '{}' votes, of $N$ total\".format(question))\n",
    "#     multiple_axes[-1].set_xlabel(r\"$k$ '{}' votes, of $N$ total\".format(question))\n",
    "    fig.tight_layout()\n",
    "\n",
    "    single_axes[0].legend(\n",
    "        loc='lower center', \n",
    "        bbox_to_anchor=(0.5, 1.1),\n",
    "        ncol=1, \n",
    "        fancybox=True, \n",
    "        shadow=False\n",
    "    )\n",
    "    \n",
    "    multiple_axes[0].legend(\n",
    "        loc='lower center', \n",
    "        bbox_to_anchor=(0.5, 1.1),\n",
    "        ncol=1, \n",
    "        fancybox=True, \n",
    "        shadow=False\n",
    "    )\n",
    "\n",
    "    \n",
    "    fig.tight_layout()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_galaxy(image_loc, ax, n_examples=10, crop=0):\n",
    "    im_size = 424\n",
    "    im = Image.open(image_loc)\n",
    "#     if QUESTION == 'bars':\n",
    "#         crop = 120\n",
    "#     else:\n",
    "    crop = 35\n",
    "    cropped_im = im.crop((crop, crop, 424 - crop, 424 - crop))\n",
    "    ax.imshow(cropped_im)\n",
    "    ax.grid(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    ax.get_xaxis().set_visible(False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = 'has-spiral-arms'\n",
    "answer = 'yes'\n",
    "n = 5\n",
    "samples, labels, total_votes = get_single_answer_data(question, answer)\n",
    "png_locs = df['file_loc'][:n]\n",
    "\n",
    "# catalog = sim_model.catalog[selected_slice]\n",
    "\n",
    "_ = custom_samples_with_galaxies(samples, labels, total_votes, png_locs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, axes = plt.subplots(1, 10, figsize=(20, 12))\n",
    "# for ax_n, ax in enumerate(axes):\n",
    "#     plot_galaxy(sim_model.catalog.iloc[ax_n]['png_loc'], ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected = slice(80, 73, -1)  #Â smooth\n",
    "\n",
    "# selected = slice(0, 7)\n",
    "\n",
    "if QUESTION == 'bars':\n",
    "    selected = slice(0, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.array(sim_model.model.samples)[selected, :]\n",
    "# np.array(sim_model.labels)[selected]\n",
    "# sim_model.catalog['smooth-or-featured_total-votes'][selected]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = custom_samples_with_galaxies(sim_model, selected)\n",
    "# fig.savefig(os.path.join(save_dir, 'mc_model_{}.png'.format(len(np.array(sim_model.labels)[selected]))))\n",
    "# fig.savefig(os.path.join(save_dir, 'mc_model_{}.pdf'.format(len(np.array(sim_model.labels)[selected]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# be sure to switch label in custom_samples before running this\n",
    "# fig = custom_samples(np.array(single_sim_model.model.samples)[selected, :1], np.array(single_sim_model.labels)[selected], total_votes=single_sim_model.total_votes)\n",
    "# fig.savefig(os.path.join(save_dir, 'single_model_{}.png'.format(len(np.array(sim_model.labels)[selected]))))\n",
    "# fig.savefig(os.path.join(save_dir, 'single_model_{}.eps'.format(len(np.array(sim_model.labels)[selected]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(font_scale=1.2)\n",
    "sns.set_style('white')\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ungrouped_coverage_df = discrete_coverage.evaluate_discrete_coverage(\n",
    "    sim_model.labels, \n",
    "    sim_model.bin_probs)\n",
    "coverage_df = ungrouped_coverage_df.groupby('max_state_error').agg({'prediction': 'sum', 'observed': 'sum'}).reset_index()\n",
    "\n",
    "ungrouped_single_coverage_df = discrete_coverage.evaluate_discrete_coverage(\n",
    "    single_sim_model.labels, \n",
    "    single_sim_model.bin_probs)\n",
    "single_coverage_df = ungrouped_single_coverage_df.groupby('max_state_error').agg({'prediction': 'sum', 'observed': 'sum'}).reset_index()\n",
    "\n",
    "\n",
    "plt.plot(coverage_df['max_state_error'], coverage_df['prediction'], label='MC Model Expects')\n",
    "plt.plot(single_coverage_df['max_state_error'], single_coverage_df['prediction'], label='Single Model Expects')\n",
    "plt.plot(single_coverage_df['max_state_error'], coverage_df['observed'], 'k--', label='Actual')\n",
    "\n",
    "ax.set_xlabel('Max Allowed Vote Error')\n",
    "ax.set_ylabel('Galaxies Within Max Error')\n",
    "ax.legend()\n",
    "ax.xaxis.set_major_formatter(StrMethodFormatter('{x:.0f}'))  # must expect 'x' kw arg\n",
    "\n",
    "ax.set_xlim([0, 15])\n",
    "fig.tight_layout()\n",
    "fig.savefig(os.path.join(save_dir, 'coverage_comparison_200_samples.png'))\n",
    "fig.savefig(os.path.join(save_dir, 'coverage_comparison_200_samples.pdf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ungrouped_coverage_df.to_csv(os.path.join(save_dir, QUESTION + '_ungrouped_coverage_df.csv'), index=False)\n",
    "ungrouped_single_coverage_df.to_csv(os.path.join(save_dir, QUESTION + '_ungrouped_coverage_df.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coverage_df['error'] = coverage_df['prediction'] - coverage_df['observed']\n",
    "coverage_df['relative_error'] = coverage_df['error'] / coverage_df['observed']\n",
    "coverage_df.to_csv(os.path.join(save_dir, QUESTION + '_coverage_df.csv'), index=False)\n",
    "coverage_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_coverage_df['error'] = single_coverage_df['prediction'] - single_coverage_df['observed']\n",
    "single_coverage_df['relative_error'] = single_coverage_df['error'] / single_coverage_df['observed']\n",
    "single_coverage_df.to_csv(os.path.join(save_dir, QUESTION + '_single_coverage_df.csv'), index=False)\n",
    "single_coverage_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO - I might consider adding an MSE model as a comparison, to hopefully beat. I think this might be quite similar though. Ideally I can compare this with previous work somehow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(font_scale=1.2)\n",
    "sns.set_style('white')\n",
    "fig, ax = plt.subplots()\n",
    "ax.hist(sim_model.abs_rho_error, bins=25)\n",
    "# ax.axvline(sim_model.mean_abs_rho_error, color='r') \n",
    "ax.set_xlim([0, 1.])\n",
    "ax.set_ylabel('Galaxies')\n",
    "ax.set_xlabel(r'| Expected $\\hat{\\rho}$ - observed vote fraction $\\frac{k}{N}$ |')\n",
    "fig.tight_layout()\n",
    "fig.savefig(os.path.join(save_dir, 'difference_in_rho.png'))\n",
    "fig.savefig(os.path.join(save_dir, 'difference_in_rho.pdf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_model.abs_rho_error.mean(), single_sim_model.abs_rho_error.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(sim_model.mean_abs_rho_error), np.sqrt(single_sim_model.mean_abs_rho_error)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(sim_model.mean_square_rho_error), np.sqrt(single_sim_model.mean_square_rho_error) # this is the rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alpha = 0.3\n",
    "# n_bins = 25\n",
    "\n",
    "# # dummy for bins\n",
    "# fig, ax = plt.subplots()\n",
    "# _, bins, _  = ax.hist(sim_model.labels / sim_model.total_votes, bins=n_bins, alpha=alpha, label=r'Observed $\\rho$')\n",
    "# ax.hist(sim_model.mean_rho_prediction, bins=n_bins, alpha=alpha, label=r'Mean Rho Prediction $\\hat{\\rho}}$')\n",
    "# # ax.hist(single_sim_model.mean_rho_prediction, bins=bins, alpha=alpha, label=r'Single Rho Prediction $\\hat{\\rho}}$')\n",
    "\n",
    "# fig, ax = plt.subplots()\n",
    "# sns.set(font_scale=1.)\n",
    "# sns.set_style('white')\n",
    "\n",
    "# ax.hist(sim_model.mean_rho_prediction, bins=bins, alpha=alpha, label=r'Mean Rho Prediction $\\hat{\\rho}}$')\n",
    "# # ax.hist(single_sim_model.mean_rho_prediction, bins=bins, alpha=alpha, label=r'Single Rho Prediction $\\hat{\\rho}}$')\n",
    "# ax.hist(sim_model.labels / sim_model.total_votes, bins=bins, alpha=alpha, label=r'Observed $\\rho$')\n",
    "# ax.legend()\n",
    "# ax.set_xlim([0., 1.])\n",
    "# ax.set_ylabel('Galaxies')\n",
    "# ax.set_xlabel(r'Typical vote fraction $\\rho$')\n",
    "# fig.tight_layout()\n",
    "# fig.savefig(os.path.join(save_dir, 'typical_vote_fraction_distribution.png'))\n",
    "\n",
    "# This is a repeat of the above histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(sim_model.mean_rho_prediction > 0.5), np.sum(single_sim_model.mean_rho_prediction > 0.5), np.sum((sim_model.labels / sim_model.total_votes) > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(sim_model.labels / sim_model.total_votes).min(), (sim_model.labels / sim_model.total_votes).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_model.mean_rho_prediction.min(), sim_model.mean_rho_prediction.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_sim_model.mean_rho_prediction.min(), single_sim_model.mean_rho_prediction.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_model.total_votes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save DataFrame of predictions + catalog (GZ2) for use elsewhere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_df = pd.DataFrame(data={\n",
    "    'total_votes': sim_model.total_votes, \n",
    "    'k': sim_model.labels, \n",
    "    'vote_fraction': (sim_model.labels / sim_model.total_votes), \n",
    "    'rho_prediction': sim_model.mean_rho_prediction\n",
    "#     'png_loc': sim_model.catalog.png_loc\n",
    "})\n",
    "safe_catalog_cols = list(set(sim_model.catalog.columns.values) - set(['total_votes', 'ra_subject', 'dec_subject']))\n",
    "df = pd.concat([response_df, sim_model.catalog[safe_catalog_cols]], axis=1)\n",
    "df['smooth'] = df['vote_fraction'] > 0.5\n",
    "df['confidence_proxy'] = np.abs(0.5 - df['rho_prediction'])\n",
    "df['rho_predictions'] = 0\n",
    "for n in range(len(df)):\n",
    "    df['rho_predictions'][n] = json.dumps(list(sim_model.model.samples[n, :]))\n",
    "    df = df.sort_values('confidence_proxy', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['rho_predictions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_parquet('/data/repos/zoobot/notebooks/{}_test_predictions_and_gz2_catalog.parquet'.format(QUESTION))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replicate (ish) Sanchez 2017 ROC Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix((sim_model.labels / sim_model.total_votes) > 0.5, sim_model.mean_rho_prediction > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " 1 - ((66 + 99) / (490 + 1845 + 66 + 99))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " 1 - ((189 + 81) / (1858 + 189 + 81 + 372))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "sns.set(font_scale=1.2)\n",
    "sns.set_style('white')\n",
    "\n",
    "fpr, tpr, _ = roc_curve(df['smooth'], df['rho_prediction'])\n",
    "ax.plot(fpr, tpr, label='All')\n",
    "df_low_entropy = df[df['confidence_proxy'] > 0.3]\n",
    "fpr, tpr, _ = roc_curve(df_low_entropy['smooth'], df_low_entropy['rho_prediction'])\n",
    "ax.plot(fpr, tpr, label=r'\"High Confidence\" i.e. $\\hat{\\rho} < 0.2$ or $\\hat{\\rho} > 0.8$')\n",
    "ax.set_xlabel('False Positive Rate')\n",
    "ax.set_ylabel('True Positive Rate')\n",
    "ax.legend()\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(os.path.join(save_dir, 'roc_curve.png'))\n",
    "fig.savefig(os.path.join(save_dir, 'roc_curve.pdf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df), len(df_low_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replicate(ish) Khan 2018 Confusion Matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> After selecting the OBJIDs from Table 2 based on the probability thresholds of 0.985 and 0.926 for spirals and ellipticals respectively,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdf_array = binom.cdf((df['total_votes'] / 2.).astype(int), df['total_votes'], df['rho_prediction'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df['total_votes'] / 2.).astype(int).sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['total_votes'].sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['rho_prediction'].sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(cdf_array, bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binom.cdf(20, 40, 0.88)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(1 - cdf_array > 0.985)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(cdf_array > 0.926)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_prob_df = df[(cdf_array < (1 - 0.985)) | (cdf_array > 0.926)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(high_prob_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if QUESTION == 'smooth':\n",
    "    spiral_pc_to_keep = 516 / 6677\n",
    "    n_spirals = int(len(df) * spiral_pc_to_keep)\n",
    "    elliptical_pc_to_keep = 550 / 5904\n",
    "    n_ellipticals = int(len(df) * elliptical_pc_to_keep)\n",
    "    print(spiral_pc_to_keep, n_spirals, elliptical_pc_to_keep, n_ellipticals)\n",
    "    high_prob_df = pd.concat([\n",
    "        df.sort_values('rho_prediction')[:n_spirals],\n",
    "        df.sort_values('rho_prediction', ascending=False)[:n_ellipticals]\n",
    "    ])\n",
    "if QUESTION == 'bars':\n",
    "    n_to_keep = int(len(df) * 0.08)\n",
    "    high_prob_df = pd.concat([\n",
    "        df.sort_values('rho_prediction')[:int(n_to_keep/2)],\n",
    "        df.sort_values('rho_prediction', ascending=False)[:int(n_to_keep/2)]\n",
    "    ])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_prob_df.sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(high_prob_df['vote_fraction'] >= 0.5, high_prob_df['rho_prediction'] >= 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error = high_prob_df[~(high_prob_df['vote_fraction'] > 0.5) & (high_prob_df['rho_prediction'] > 0.5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error['vote_fraction'] > 0.5, error['rho_prediction'] > 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open(error.iloc[0]['png_loc'])\n",
    "plt.imshow(img)\n",
    "fontdict = {'size': 16, 'color': 'white'}\n",
    "plt.text(30, 360, r'Expected vote frac $\\hat{\\rho}$: 0.80', fontdict=fontdict)\n",
    "plt.text(30, 400, r'Observed vote frac $\\frac{k}{N}$: 0.50', fontdict=fontdict)\n",
    "plt.axis('off')\n",
    "plt.savefig(os.path.join(save_dir, 'high_prob_error_0.png'))\n",
    "plt.savefig(os.path.join(save_dir, 'high_prob_error_0.eps'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img = Image.open(error.iloc[1]['png_loc'])\n",
    "# plt.imshow(img)\n",
    "# fontdict = {'size': 16, 'color': 'white'}\n",
    "# plt.text(30, 360, r'Expected vote frac $\\hat{\\rho}$: 0.13', fontdict=fontdict)\n",
    "# plt.text(30, 400, r'Observed vote frac $\\frac{k}{N}$: 0.54', fontdict=fontdict)\n",
    "# plt.axis('off')\n",
    "# plt.savefig(os.path.join(save_dir, 'high_prob_error_1.png'))\n",
    "# plt.savefig(os.path.join(save_dir, 'high_prob_error_1.eps'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(df['vote_fraction'][:int(len(df) / 2)] > 0.5, df['rho_prediction'][:int(len(df) / 2)] > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if QUESTION == 'smooth':\n",
    "    labels = ['Smooth', 'Featured']\n",
    "    \n",
    "#     cm = np.array([[ 232,    2], [   0, 191]])\n",
    "#     name = 'confusion_matrix_high_confidence'\n",
    "    \n",
    "    cm = np.array([[ 490,   66],\n",
    "       [  99, 1845]])\n",
    "    name = 'confusion_matrix'\n",
    "    \n",
    "if QUESTION == 'bars':\n",
    "    labels = ['No Bar', 'Bar']\n",
    "    cm = np.array([[100,    0], [   0,   100]])\n",
    "    name = 'confusion_matrix_high_confidence'\n",
    "    \n",
    "#     cm = np.array([[1858,    81], [   189,   372]])\n",
    "#     name = 'confusion_matrix'\n",
    "\n",
    "sns.set(font_scale=3.)\n",
    "sns.set_style('white')\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "ax = sns.heatmap(cm, annot=True, fmt='d', cmap=\"Blues\", xticklabels=labels, yticklabels=labels, cbar=False, square=True, ax=ax)\n",
    "ax.set_xlabel('Predicted')\n",
    "ax.set_ylabel('Observed')\n",
    "fig.tight_layout()\n",
    "fig.savefig(os.path.join(save_dir, '{}.png'.format(name)))\n",
    "fig.savefig(os.path.join(save_dir, '{}.pdf'.format(name)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1 - (8 / (1159 + 83 + 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sim_model.export_performance_metrics(save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw a galaxy, infer a range of p, redraw, and measure accuracy - work in progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot other standard acquisition visualisations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_acquisition_viz = False\n",
    "if new_acquisition_viz:\n",
    "    image_locs = sim_model.catalog['png_loc']\n",
    "    images = np.stack([np.array(Image.open(loc)) for loc in image_locs])\n",
    "    assert images.shape == (2500, 424, 424, 3)\n",
    "    acquisition_utils.save_acquisition_examples(images, sim_model.mutual_info, 'mutual_info', save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, row = plt.subplots(ncols=3, figsize=(12, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# row = sim_model.acquisition_vs_volunteer_votes(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualise Selection of Catalog Features w.r.t. Acquisition Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(constrained_layout=True, figsize=(20, 12))\n",
    "gs = gridspec.GridSpec(6, 5, figure=fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Smooth Votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax0 = plt.subplot(gs[:4, :])\n",
    "sns.scatterplot(\n",
    "    np.array(sim_model.catalog['smooth-or-featured_smooth_fraction'] * 40).astype(int),\n",
    "    sim_model.model.acquisitions, hue=np.array(sim_model.model.acquisitions) > np.array(sim_model.model.acquisitions[103]),\n",
    "    ax=ax0)\n",
    "ax0.set_ylabel('Mutual Information')\n",
    "ax0.set_xlabel('Smooth Votes')\n",
    "ax0.legend([r'Top 10% $\\mathcal{I}$', r'Bottom 90% $\\mathcal{I}$'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax1 = plt.subplot(gs[4:, :])\n",
    "ax1.hist(np.array(sim_model.labels * 40).astype(int), density=True, alpha=0.4)\n",
    "ax1.hist(np.array(sim_model.labels * 40).astype(int)[:200], density=True, alpha=0.4)\n",
    "ax1.set_ylabel('Frequency')\n",
    "ax1.set_xlabel('Smooth Votes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.savefig(os.path.join(save_dir, 'temp.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Redshift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "sns.jointplot(np.array(sim_model.labels * 40).astype(int), sim_model.catalog['redshift'], kind='kde')\n",
    "ax0.set_ylabel('Redshift')\n",
    "ax0.set_xlabel('Volunteer Votes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax0 = plt.subplot(gs[:2, :])\n",
    "sns.jointplot(np.array(sim_model.labels * 40).astype(int), sim_model.catalog['redshift'], kind='kde', ax=ax0)\n",
    "ax0.set_ylabel('Redshift')\n",
    "ax0.set_xlabel('Volunteer Votes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax0 = plt.subplot(gs[:2, :])\n",
    "sns.jointplot(sim_model.catalog['redshift'], sim_model.model.acquisitions, ax=ax0)\n",
    "ax0.set_ylabel('Mutual Information')\n",
    "ax0.set_xlabel('Redshift')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax1 = plt.subplot(gs[4:, :])\n",
    "\n",
    "ax1.hist(sim_model.catalog['redshift'], density=True, alpha=0.4)\n",
    "# ax1.hist(sim_model.catalog['redshift'], density=True, alpha=0.4)\n",
    "ax1.set_ylabel('Frequency')\n",
    "ax1.set_xlabel('Smooth Votes')\n",
    "# TODO sort by mutual information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Below here is only relevant for DECALS, with extra questions. TODO update with GZ2 merger options?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merger_strs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merger_label = 'merging_major-disturbance'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax0 = plt.subplot(gs[:2, :])\n",
    "sns.scatterplot(sim_model.catalog[merger_label], sim_model.model.mutual_info, ax=ax0)\n",
    "ax0.set_ylabel('Mutual Information')\n",
    "ax0.set_xlabel(merger_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.hist(sim_model.catalog[merger_label], bins=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featured_no_merger = sim_model.model.mutual_info[(sim_model.catalog[merger_label] == 0) & (sim_model.catalog['smooth-or-featured_smooth_fraction'] < 0.4)]\n",
    "featured_merger = sim_model.model.mutual_info[(sim_model.catalog[merger_label] > 0) & (sim_model.catalog['smooth-or-featured_smooth_fraction'] < 0.4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featured_no_merger.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featured_merger.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax.hist(featured_no_merger, alpha=0.3, density=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax.hist(featured_merger, alpha=0.3, density=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.scatterplot(\n",
    "    sim_model.catalog['smooth-or-featured_artifact'], \n",
    "    sim_model.model.mutual_info, \n",
    "    hue=sim_model.model.mutual_info > sim_model.model.mutual_info[103])\n",
    "ax.set_xlim([0, 14.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(\n",
    "    sim_model.catalog['smooth-or-featured_artifact'], \n",
    "    sim_model.model.mutual_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax.hist(\n",
    "    sim_model.catalog['smooth-or-featured_artifact'][sim_model.model.mutual_info > sim_model.model.mutual_info[100]],\n",
    "    density=True,\n",
    "    alpha=0.4,\n",
    ")\n",
    "ax.hist(\n",
    "    sim_model.catalog['smooth-or-featured_artifact'][sim_model.model.mutual_info < sim_model.model.mutual_info[100]],\n",
    "    density=True,\n",
    "    alpha=0.4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "has-spiral-arms_yes\n",
    "spiral-winding_prediction-encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(\n",
    "    sim_model.catalog['has-spiral-arms_yes'][sim_model.catalog['smooth-or-featured_smooth_fraction'] < 0.5], \n",
    "    sim_model.model.mutual_info[sim_model.catalog['smooth-or-featured_smooth_fraction'] < 0.5], \n",
    "    hue=sim_model.model.mutual_info > sim_model.model.mutual_info[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.hist(\n",
    "    sim_model.catalog['has-spiral-arms_yes'][sim_model.model.mutual_info > sim_model.model.mutual_info[100]],\n",
    "    density=True,\n",
    "    alpha=0.4,\n",
    ")\n",
    "ax.hist(\n",
    "    sim_model.catalog['has-spiral-arms_yes'][sim_model.model.mutual_info < sim_model.model.mutual_info[100]],\n",
    "    density=True,\n",
    "    alpha=0.4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.hist(\n",
    "    sim_model.catalog['redshift'][sim_model.model.mutual_info > sim_model.model.mutual_info[100]],\n",
    "    density=True,\n",
    "    alpha=0.4,\n",
    ")\n",
    "ax.hist(\n",
    "    sim_model.catalog['redshift'][sim_model.model.mutual_info < sim_model.model.mutual_info[100]],\n",
    "    density=True,\n",
    "    alpha=0.4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.hist(\n",
    "    sim_model.catalog['merging_major-disturbance'][sim_model.model.mutual_info > sim_model.model.mutual_info[100]],\n",
    "    density=True,\n",
    "    alpha=0.4,\n",
    ")\n",
    "ax.hist(\n",
    "    sim_model.catalog['merging_major-disturbance'][sim_model.model.mutual_info < sim_model.model.mutual_info[100]],\n",
    "    density=True,\n",
    "    alpha=0.4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for merger_label in merger_strs:\n",
    "    print('\\n' + merger_label)\n",
    "    print(sim_model.model.mutual_info[sim_model.catalog[merger_label] > 1].mean())\n",
    "    print(sim_model.model.mutual_info[sim_model.catalog[merger_label] == 1].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "    {'Volunteer Response': 'Merging', 'Mean Mutual Information': sim_model.model.mutual_info[sim_model.catalog['merging_both-v1'] > 1].mean()},\n",
    "    {'Volunteer Response': 'Major Disturbance', 'Mean Mutual Information': sim_model.model.mutual_info[sim_model.catalog['merging_major-disturbance'] > 1].mean()},\n",
    "    {'Volunteer Response': 'Minor Disturbance', 'Mean Mutual Information': sim_model.model.mutual_info[sim_model.catalog['merging_minor-disturbance'] > 1].mean()},\n",
    "    {'Volunteer Response': 'No Disturbance', 'Mean Mutual Information': sim_model.model.mutual_info[sim_model.catalog['merging_none'] > 20].mean()}\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax = sns.barplot(data=df, y='Volunteer Response', x='Mean Mutual Information', ax=ax)\n",
    "ax.set_xlim([0.2, 0.36])\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sim_model.model.mutual_info[(sim_model.catalog['merging_minor-disturbance'] + sim_model.catalog['merging_major-disturbance']) > 0].mean())\n",
    "print(sim_model.model.mutual_info[(sim_model.catalog['merging_minor-disturbance'] + sim_model.catalog['merging_major-disturbance']) == 0].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(sim_model.catalog['merging_tidal-debris-v1'], bins=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('zoobot': conda)",
   "language": "python",
   "name": "python37664bitzoobotcondad3adbdfef5c444648572db3b6ec7c1e0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
