{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/walml/repos/zoobot/notebooks/multiq\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already up-to-date.\n"
     ]
    }
   ],
   "source": [
    "!git pull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import argparse\n",
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib.ticker import StrMethodFormatter\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import seaborn as sns\n",
    "from sklearn import metrics\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from astropy.table import Table  # for NSA\n",
    "from astropy import units as u\n",
    "from sklearn.metrics import confusion_matrix, roc_curve\n",
    "from PIL import Image\n",
    "from scipy.stats import binom\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "from shared_astro_utils import astropy_utils, matching_utils\n",
    "from zoobot.estimators import make_predictions, bayesian_estimator_funcs\n",
    "from zoobot.tfrecord import read_tfrecord\n",
    "from zoobot.uncertainty import discrete_coverage\n",
    "from zoobot.estimators import input_utils, losses\n",
    "from zoobot.tfrecord import catalog_to_tfrecord\n",
    "from zoobot.active_learning import metrics, simulated_metrics, acquisition_utils, check_uncertainty, simulation_timeline, run_estimator_config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    for gpu in gpus:\n",
    "        tf.config.experimental.set_memory_growth(gpu, True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/home/walml/repos/zoobot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start = 50\n",
    "# end = 60\n",
    "# start = 0\n",
    "# end=5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the (latest) model under `model_name` folder in `results_dir`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/walml/anaconda3/envs/zoobot/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3063: DtypeWarning: Columns (109) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "# catalog_loc = 'data/latest_labelled_catalog.csv\n",
    "catalog_loc = 'data/decals/decals_master_catalog.csv'\n",
    "catalog = pd.read_csv(catalog_loc, dtype={'subject_id': str})  # original catalog\n",
    "# catalog = catalog[:5000]  \n",
    "catalog['file_loc'] = catalog['local_png_loc'].apply(lambda x: '/media/walml/beta/decals/png_native' + x[32:])\n",
    "\n",
    "model_name = 'latest_offline'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Loading multiple tfrecords with interleaving, shuffle=False\n",
      "WARNING:root:Loading multiple tfrecords with interleaving, shuffle=False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/walml/repos/zoobot/data/decals/shards/decals_multiq_128/train_shards/s128_shard_5.tfrecord', '/home/walml/repos/zoobot/data/decals/shards/decals_multiq_128/train_shards/s128_shard_8.tfrecord', '/home/walml/repos/zoobot/data/decals/shards/decals_multiq_128/train_shards/s128_shard_4.tfrecord', '/home/walml/repos/zoobot/data/decals/shards/decals_multiq_128/train_shards/s128_shard_3.tfrecord', '/home/walml/repos/zoobot/data/decals/shards/decals_multiq_128/train_shards/s128_shard_7.tfrecord', '/home/walml/repos/zoobot/data/decals/shards/decals_multiq_128/train_shards/s128_shard_9.tfrecord', '/home/walml/repos/zoobot/data/decals/shards/decals_multiq_128/train_shards/s128_shard_1.tfrecord', '/home/walml/repos/zoobot/data/decals/shards/decals_multiq_128/train_shards/s128_shard_2.tfrecord', '/home/walml/repos/zoobot/data/decals/shards/decals_multiq_128/train_shards/s128_shard_0.tfrecord', '/home/walml/repos/zoobot/data/decals/shards/decals_multiq_128/train_shards/s128_shard_6.tfrecord', '/home/walml/repos/zoobot/data/decals/shards/decals_multiq_128/eval_shards/s128_shard_1.tfrecord', '/home/walml/repos/zoobot/data/decals/shards/decals_multiq_128/eval_shards/s128_shard_0.tfrecord']\n",
      "loading filenames: <TensorSliceDataset shapes: (), types: tf.string>\n",
      "loading filenames: <TensorSliceDataset shapes: (), types: tf.string>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['J094659.39+020723.9',\n",
       " 'J091444.05-005136.7',\n",
       " 'J123541.18+114001.8',\n",
       " 'J161603.63+003150.8',\n",
       " 'J015757.77-001112.5']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Figures will be saved to here\n",
    "\n",
    "analysis_dir = 'analysis/multiquestion'\n",
    "save_dir = f'{analysis_dir}/{model_name}'\n",
    "if not os.path.exists(save_dir):\n",
    "    os.mkdir(save_dir)\n",
    "\n",
    "# results_dir = '/home/walml/repos/zoobot/data/experiments/live/no_cutouts/iteration_0'\n",
    "results_dir = '/home/walml/repos/zoobot/results/smooth_or_featured_offline'\n",
    "label_cols = [\n",
    "    'smooth-or-featured_smooth',\n",
    "    'smooth-or-featured_featured-or-disk',\n",
    "#     'has-spiral-arms_yes',\n",
    "#     'has-spiral-arms_no',\n",
    "#     'spiral-winding_tight',\n",
    "#     'spiral-winding_medium',\n",
    "#     'spiral-winding_loose',\n",
    "#     'bar_strong',\n",
    "#     'bar_weak',\n",
    "#     'bar_no',\n",
    "#     'bulge-size_dominant',\n",
    "#     'bulge-size_large',\n",
    "#     'bulge-size_moderate',\n",
    "#     'bulge-size_small',\n",
    "#     'bulge-size_none'\n",
    "]\n",
    "\n",
    "questions = [\n",
    "    'smooth-or-featured',\n",
    "#     'has-spiral-arms',\n",
    "#     'spiral-winding',\n",
    "#     'bar',\n",
    "#     'bulge-size'\n",
    "]\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "initial_size = 128\n",
    "final_size = 64\n",
    "channels = 3\n",
    "\n",
    "n_samples = 5\n",
    "\n",
    "# if loading single test tfrecord\n",
    "# tfrecord_locs = [f'data/decals/shards/multilabel_{img_size}/eval/s{initial_size}_shard_0.tfrecord']\n",
    "# tfrecord_locs = ['data/decals/shards/multilabel_master_256/train/s256_shard_0.tfrecord']\n",
    "# tfrecord_locs = glob.glob(f'/media/walml/beta/decals/multilabel_master_{initial_size}/train/*.tfrecord')[start:end]\n",
    "# tfrecord_locs = glob.glob(f'/home/walml/repos/zoobot/data/decals/shards/decals_multiq_{initial_size}_sim_init_2500_featp4/train_shards/*.tfrecord')[start:end]\n",
    "\n",
    "# for all labelled galaxies\n",
    "train_locs = glob.glob(f'/home/walml/repos/zoobot/data/decals/shards/decals_multiq_{initial_size}/train_shards/*.tfrecord')\n",
    "eval_locs = glob.glob(f'/home/walml/repos/zoobot/data/decals/shards/decals_multiq_{initial_size}/eval_shards/*.tfrecord')\n",
    "tfrecord_locs = train_locs + eval_locs\n",
    "\n",
    "print(tfrecord_locs)\n",
    "eval_config = run_estimator_config.get_eval_config(tfrecord_locs, label_cols, batch_size, initial_size, final_size, channels)\n",
    "dataset = input_utils.get_input(config=eval_config)\n",
    "\n",
    "feature_spec = input_utils.get_feature_spec({'id_str': 'string'})\n",
    "id_str_dataset = input_utils.get_dataset(tfrecord_locs, feature_spec, batch_size=1, shuffle=False, repeat=False)\n",
    "id_strs = [str(d['id_str'].numpy().squeeze())[2:-1] for d in id_str_dataset]\n",
    "id_strs[:5]\n",
    "\n",
    "# n = 0\n",
    "# for batch in id_str_dataset:\n",
    "#     for id_str in batch:\n",
    "#         n+=1\n",
    "# print(n)\n",
    "\n",
    "# counter = Counter()\n",
    "# n = 0\n",
    "# for g_batch, y_batch in dataset:\n",
    "# #     for g in g_batch:\n",
    "# #         counter[g.numpy().sum()] += 1\n",
    "#         n+=tf.shape(g_batch)[0]\n",
    "# print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42833"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(id_strs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # if loading png\n",
    "\n",
    "# print(catalog['file_loc'])\n",
    "# assert all([os.path.isfile(x) for x in catalog['file_loc']])\n",
    "# filenames = tf.constant(list(catalog['file_loc']), dtype=tf.string)\n",
    "# dataset = tf.data.Dataset.from_tensor_slices(filenames)\n",
    "\n",
    "# def parse_image(im):\n",
    "#     im = tf.image.decode_png(im, channels=channels)\n",
    "#     im = tf.image.convert_image_dtype(im, tf.float32)\n",
    "#     im = tf.image.resize(im, [initial_size, initial_size])\n",
    "#     return im\n",
    "\n",
    "\n",
    "# # for im in dataset.take(1):\n",
    "# #     print(im)\n",
    "\n",
    "# # assert False\n",
    "\n",
    "# dataset = dataset.map(tf.io.read_file)\n",
    "# dataset = dataset.map(parse_image)\n",
    "\n",
    "# config = default_estimator_params.get_eval_config(['do not use'], label_cols, batch_size, initial_size, final_size, channels)\n",
    "\n",
    "# dataset = dataset.batch(batch_size)\n",
    "\n",
    "# # for batch in dataset.take(1):\n",
    "# #     print(tf.shape(batch))\n",
    "# # #     plt.imshow(batch[0])\n",
    "\n",
    "\n",
    "# # dataset = dataset.map(lambda x: check_shape(x))\n",
    "\n",
    "# dataset = dataset.map(lambda x: input_utils.preprocess_images(x, config))\n",
    "\n",
    "\n",
    "# # for batch in dataset.take(1):\n",
    "# #     print(tf.shape(batch))\n",
    "# #     plt.imshow(batch[0].numpy().squeeze())\n",
    "\n",
    "\n",
    "# id_strs = catalog['iauname']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{smooth-or-featured, indices 0 to 1, asked after None: (0, 1)}\n",
      "Name: smooth-or-featured, start 0, end 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f559fe3f7d0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = run_estimator_config.get_model(label_cols, questions, final_size)\n",
    "\n",
    "# checkpoint_dir = f'{results_dir}/estimators/models'\n",
    "checkpoint_dir = f'{results_dir}/models'\n",
    "model.load_weights(checkpoint_dir)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %timeit predictions = model.predict(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<MapDataset shapes: ((None, 64, 64, 1), (None, 2)), types: (tf.float32, tf.float32)>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.predict(dataset).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 1)]\n",
      "0 1\n"
     ]
    }
   ],
   "source": [
    "predictions = np.stack([model.predict(dataset) for n in range(n_samples)], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42833, 2, 5)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for batch_x, batch_y in dataset:\n",
    "#     print(batch_y.numpy())\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels = np.concatenate([batch_y for (_, batch_y) in test_dataset], axis=0)\n",
    "# labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = catalog[label_cols].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots()\n",
    "# ax.hist(predictions[:, 0], alpha=0.5, label='Predictions', density=True)\n",
    "# ax.hist(labels[:, 0] / labels[:, :2].sum(axis=1), alpha=0.5, label='Labels', density=True)\n",
    "# plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(predictions[:, 0].min(), labels[:, 0].min())\n",
    "# print(predictions[:, 0].max(), labels[:, 0].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{smooth-or-featured, indices 0 to 1, asked after None: (0, 1)}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[smooth-or-featured, indices 0 to 1, asked after None]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema = losses.Schema(label_cols, questions)\n",
    "schema.questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# acquisitions = acquisition_utils.mutual_info_acquisition_func_multiq(predictions, schema, retirement=40)\n",
    "# acquisitions.shape\n",
    "# acquisitions\n",
    "\n",
    "# single_q_acquisitions = np.array(acquisition_utils.mutual_info_acquisition_func(predictions[:, 0], expected_votes=40))\n",
    "# single_q_acquisitions[:5], acquisitions[0, :5], acquisitions[1, :5]  # smooth mutual acq should be identical, for both answers by symmmetry\n",
    "# acquisitions[2, :5], acquisitions[3, :5]  # has-spiral-arms also by symmetry\n",
    "# acquisitions[4, :5], acquisitions[5, :5], acquisitions[6, :5]  # but for spiral winding there are 3 answers so *not* identical\n",
    "# predictions.shape, acquisitions.shape, len(id_strs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((42833, 2, 5), 42833)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.shape, len(id_strs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.6142819 , 0.6134897 , 0.6071179 , 0.65839624, 0.6788209 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_to_row(prediction, id_str):\n",
    "    row = {\n",
    "        'id_str': id_str\n",
    "    }\n",
    "    for n, col in enumerate(label_cols):\n",
    "        answer = label_cols[n]\n",
    "        row[answer + '_prediction'] = json.dumps(list(prediction[n].astype(float)))\n",
    "#         row[answer + '_acquisition'] = acquisition[n]\n",
    "        row[answer + '_prediction_mean'] = float(prediction[n].mean())\n",
    "#         row[answer + '_acquisition'] = acquisition[n]\n",
    "#         row['total_acquisition'] = acquisition.sum()\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_to_row(prediction, acquisition, id_str):\n",
    "    row = {\n",
    "        'id_str': id_str\n",
    "    }\n",
    "    for n, col in enumerate(label_cols):\n",
    "        answer = label_cols[n]\n",
    "        row[answer + '_prediction'] = prediction[n]\n",
    "#         row[answer + '_acquisition'] = acquisition[n]\n",
    "        row[answer + '_prediction_mean'] = float(prediction[n].mean())\n",
    "#         row[answer + '_acquisition'] = acquisition[n]\n",
    "#         row['total_acquisition'] = acquisition.sum()\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [prediction_to_row(predictions[n], id_strs[n]) for n in range(len(predictions))]\n",
    "# data = [all_to_row(predictions[n], acquisitions[n], id_strs[n]) for n in range(len(predictions))]\n",
    "predictions_df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42833"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predictions_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_str</th>\n",
       "      <th>smooth-or-featured_smooth_prediction</th>\n",
       "      <th>smooth-or-featured_smooth_prediction_mean</th>\n",
       "      <th>smooth-or-featured_featured-or-disk_prediction</th>\n",
       "      <th>smooth-or-featured_featured-or-disk_prediction_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>J094659.39+020723.9</td>\n",
       "      <td>[0.6142818927764893, 0.6134896874427795, 0.607...</td>\n",
       "      <td>0.634421</td>\n",
       "      <td>[0.38571813702583313, 0.38651028275489807, 0.3...</td>\n",
       "      <td>0.365579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>J091444.05-005136.7</td>\n",
       "      <td>[0.37360063195228577, 0.5307837128639221, 0.28...</td>\n",
       "      <td>0.454325</td>\n",
       "      <td>[0.6263993382453918, 0.4692162871360779, 0.714...</td>\n",
       "      <td>0.545675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>J123541.18+114001.8</td>\n",
       "      <td>[0.0437084399163723, 0.12914761900901794, 0.16...</td>\n",
       "      <td>0.114587</td>\n",
       "      <td>[0.9562916159629822, 0.8708523511886597, 0.831...</td>\n",
       "      <td>0.885413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>J161603.63+003150.8</td>\n",
       "      <td>[0.49912092089653015, 0.4809390902519226, 0.43...</td>\n",
       "      <td>0.457504</td>\n",
       "      <td>[0.5008791089057922, 0.5190609097480774, 0.568...</td>\n",
       "      <td>0.542496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>J015757.77-001112.5</td>\n",
       "      <td>[0.6810203790664673, 0.6857025623321533, 0.635...</td>\n",
       "      <td>0.657201</td>\n",
       "      <td>[0.3189796209335327, 0.3142974078655243, 0.364...</td>\n",
       "      <td>0.342799</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                id_str               smooth-or-featured_smooth_prediction  \\\n",
       "0  J094659.39+020723.9  [0.6142818927764893, 0.6134896874427795, 0.607...   \n",
       "1  J091444.05-005136.7  [0.37360063195228577, 0.5307837128639221, 0.28...   \n",
       "2  J123541.18+114001.8  [0.0437084399163723, 0.12914761900901794, 0.16...   \n",
       "3  J161603.63+003150.8  [0.49912092089653015, 0.4809390902519226, 0.43...   \n",
       "4  J015757.77-001112.5  [0.6810203790664673, 0.6857025623321533, 0.635...   \n",
       "\n",
       "   smooth-or-featured_smooth_prediction_mean  \\\n",
       "0                                   0.634421   \n",
       "1                                   0.454325   \n",
       "2                                   0.114587   \n",
       "3                                   0.457504   \n",
       "4                                   0.657201   \n",
       "\n",
       "      smooth-or-featured_featured-or-disk_prediction  \\\n",
       "0  [0.38571813702583313, 0.38651028275489807, 0.3...   \n",
       "1  [0.6263993382453918, 0.4692162871360779, 0.714...   \n",
       "2  [0.9562916159629822, 0.8708523511886597, 0.831...   \n",
       "3  [0.5008791089057922, 0.5190609097480774, 0.568...   \n",
       "4  [0.3189796209335327, 0.3142974078655243, 0.364...   \n",
       "\n",
       "   smooth-or-featured_featured-or-disk_prediction_mean  \n",
       "0                                           0.365579    \n",
       "1                                           0.545675    \n",
       "2                                           0.885413    \n",
       "3                                           0.542496    \n",
       "4                                           0.342799    "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df['iauname'] = predictions_df['id_str']\n",
    "df = pd.merge(catalog, predictions_df, how='inner', on='iauname')\n",
    "len(df)\n",
    "assert len(df) == len(predictions_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        https://panoptes-uploads.zooniverse.org/produc...\n",
       "1        https://panoptes-uploads.zooniverse.org/produc...\n",
       "2        https://panoptes-uploads.zooniverse.org/produc...\n",
       "3        https://panoptes-uploads.zooniverse.org/produc...\n",
       "4        https://panoptes-uploads.zooniverse.org/produc...\n",
       "                               ...                        \n",
       "42828    https://panoptes-uploads.zooniverse.org/produc...\n",
       "42829    https://panoptes-uploads.zooniverse.org/produc...\n",
       "42830    https://panoptes-uploads.zooniverse.org/produc...\n",
       "42831    https://panoptes-uploads.zooniverse.org/produc...\n",
       "42832    https://panoptes-uploads.zooniverse.org/produc...\n",
       "Name: subject_url, Length: 42833, dtype: object"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['subject_url']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        /media/walml/beta/decals/png_native/dr5/J114/J...\n",
       "1        /media/walml/beta/decals/png_native/dr5/J114/J...\n",
       "2        /media/walml/beta/decals/png_native/dr5/J114/J...\n",
       "3        /media/walml/beta/decals/png_native/dr5/J114/J...\n",
       "4        /media/walml/beta/decals/png_native/dr5/J114/J...\n",
       "                               ...                        \n",
       "42828    /media/walml/beta/decals/png_native/dr5/J135/J...\n",
       "42829    /media/walml/beta/decals/png_native/dr5/J135/J...\n",
       "42830    /media/walml/beta/decals/png_native/dr5/J142/J...\n",
       "42831    /media/walml/beta/decals/png_native/dr5/J144/J...\n",
       "42832    /media/walml/beta/decals/png_native/dr5/J143/J...\n",
       "Name: file_loc, Length: 42833, dtype: object"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['file_loc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('temp/smooth_or_featured_labelled_latest.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-a871fdc9ebee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copied from trust_the_model.ipynb\n",
    "def show_galaxies(df, scale=3, nrows=3, ncols=3):\n",
    "    fig = plt.gcf()\n",
    "\n",
    "    plt.figure(figsize=(scale * nrows, scale * ncols * 1.025))\n",
    "    gs1 = gridspec.GridSpec(nrows, ncols)\n",
    "    gs1.update(wspace=0.0, hspace=0.0)\n",
    "    galaxy_n = 0\n",
    "    for row_n in range(nrows):\n",
    "        for col_n in range(ncols):\n",
    "            galaxy = df.iloc[galaxy_n]\n",
    "            image = Image.open(galaxy['file_loc'])\n",
    "            ax = plt.subplot(gs1[row_n, col_n])\n",
    "            ax.imshow(image)\n",
    "#             ax.text(10, 20, 'Smooth = {:.2f}'.format(galaxy['smooth-or-featured_smooth_fraction']), fontsize=12, color='r')\n",
    "#             ax.text(10, 50, r'$\\rho = {:.2f}$, Var ${:.3f}$'.format(galaxy['median_prediction'], 3*galaxy['predictions_var']), fontsize=12, color='r')\n",
    "#             ax.text(10, 80, '$L = {:.2f}$'.format(galaxy['bcnn_likelihood']), fontsize=12, color='r')\n",
    "            ax.axis('off')\n",
    "            galaxy_n += 1\n",
    "#     print('Mean L: {:.2f}'.format(df[:nrows * ncols]['bcnn_likelihood'].mean()))\n",
    "    fig = plt.gcf()\n",
    "#     fig.tight_layout()\n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def save_top_n(schema, save_dir):\n",
    "    for question in schema.questions:\n",
    "        for answer in question.answers:\n",
    "            fig = show_galaxies(df.sort_values(answer.text + '_prediction_mean', ascending=False)[:9])\n",
    "            fig.savefig(save_dir + '_' + answer.text + '.png')\n",
    "            plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "save_dir = 'results/temp'\n",
    "save_top_n(schema, save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False  # moove later analysis elsewhere?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots()\n",
    "# ax.scatter(predictions[:, 0], labels[:, 0] / labels[:, :2].sum(axis=1))\n",
    "# plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.get_backend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots()\n",
    "# ax.scatter(predictions[:, 4], labels[:, 4] / labels[:, 4:7].sum(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots()\n",
    "# ax.scatter(predictions[:, 5], labels[:, 5] / labels[:, 4:7].sum(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots()\n",
    "# ax.scatter(predictions[:, 6], labels[:, 6] / labels[:, 4:7].sum(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to check that the right models have been loaded - should be around 40 for smooth, 0-40 for bars\n",
    "# plt.hist(sim_model.total_votes), sim_model.total_votes.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def galaxy_posterior_grid(df, schema):\n",
    "    \n",
    "    sns.set_context('paper', font_scale=1.5)\n",
    "    \n",
    "    scale = 1.5\n",
    "    \n",
    "    im_width = 2\n",
    "    posterior_width = 3\n",
    "    height = im_width\n",
    "    \n",
    "    n_galaxies = len(df)\n",
    "    n_posteriors = len(schema.answers)\n",
    "    \n",
    "    fig = plt.figure(figsize=(scale * (im_width + posterior_width*n_posteriors), (scale * n_galaxies * height)))  # width, height format\n",
    "    gs = gridspec.GridSpec(len(df) * height, im_width + posterior_width * len(schema.answers))  # y, x format\n",
    "    image_axes = []\n",
    "    posterior_axes = []  # (galaxy i.e. row, answer) shape\n",
    "    \n",
    "    # create the grid\n",
    "    for galaxy_n in range(len(df)):\n",
    "        y_slice = slice(galaxy_n*height, (galaxy_n+1)*height)\n",
    "        image_axes.append(plt.subplot(gs[y_slice, :im_width]))\n",
    "        \n",
    "        temp_galaxy_axes = []\n",
    "        for answer_n, answer in enumerate(schema.answers):\n",
    "            x_slice = slice(im_width+answer_n*posterior_width, im_width+(answer_n+1)*posterior_width)\n",
    "            temp_galaxy_axes.append(plt.subplot(gs[y_slice, x_slice]))\n",
    "        posterior_axes.append(temp_galaxy_axes)\n",
    "        \n",
    "    \n",
    "    # fill the images\n",
    "    for ax_n, ax in enumerate(image_axes):\n",
    "        plot_galaxy(df['file_loc'][ax_n], ax)\n",
    "    \n",
    "    # fill the posteriors\n",
    "    for answer_n, answer in enumerate(schema.answers):\n",
    "        samples, labels, total_votes = get_single_answer_data(df, answer)\n",
    "        galaxy_axes = [axes[answer_n] for axes in posterior_axes]\n",
    "        make_predictions.plot_samples(samples, labels, total_votes, fig, galaxy_axes, alpha=0.06)\n",
    "    \n",
    "    # fix x limits for comparison\n",
    "    for row_n, axes in enumerate(posterior_axes):\n",
    "        for answer_n, ax in enumerate(axes):\n",
    "            ax.set_xlim([0, 50])\n",
    "            if row_n == 0:\n",
    "                ax.set_title(schema.answers[answer_n].text)\n",
    "        \n",
    "#     for n in range(len(labels)):\n",
    "#         multiple_axes[n].set_ylabel(r'$p(k|N, D)$', visible=True)\n",
    "#         multiple_axes[n].yaxis.set_visible(True)\n",
    "#         single_axes[n].set_ylabel(r'$p(k|N, w)$', visible=True)\n",
    "#         single_axes[n].yaxis.set_visible(True)\n",
    "#         single_axes[n].yaxis.set_major_locator(plt.NullLocator())\n",
    "#         multiple_axes[n].yaxis.set_major_locator(plt.NullLocator())\n",
    "#         if n < len(labels) - 1:\n",
    "#             single_axes[n].xaxis.set_major_locator(plt.NullLocator())\n",
    "#             multiple_axes[n].xaxis.set_major_locator(plt.NullLocator())\n",
    "    \n",
    "# #     if QUESTION == 'bars':\n",
    "# #         question = 'Bar'\n",
    "# #     else:\n",
    "# #         question = 'Smooth'\n",
    "# #     single_axes[-1].set_xlabel(r\"$k$ '{}' votes, of $N$ total\".format(question))\n",
    "# #     multiple_axes[-1].set_xlabel(r\"$k$ '{}' votes, of $N$ total\".format(question))\n",
    "#     fig.tight_layout()\n",
    "\n",
    "    \n",
    "#     multiple_axes[0].legend(\n",
    "#         loc='lower center', \n",
    "#         bbox_to_anchor=(0.5, 1.1),\n",
    "#         ncol=1, \n",
    "#         fancybox=True, \n",
    "#         shadow=False\n",
    "#     )\n",
    "\n",
    "    fig.tight_layout()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = galaxy_posterior_grid(df[:5], schema)\n",
    "fig.savefig(save_dir + '/grid.pdf')\n",
    "fig.savefig(save_dir + '/grid.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def custom_samples_with_galaxies(samples, labels, total_votes, png_locs):\n",
    "    \n",
    "    sns.set_context('paper', font_scale=1.5)\n",
    "    \n",
    "    im_width = 2\n",
    "    single_width = 3\n",
    "    multiple_width = 3\n",
    "    height = im_width\n",
    "    \n",
    "    fig = plt.figure(figsize=(0.8 * len(labels) * height * 2., 0.8 * (im_width + single_width + multiple_width) * 1.75))\n",
    "    gs = gridspec.GridSpec(len(labels) * height, im_width + single_width + multiple_width)  # y, x format\n",
    "    image_axes = []\n",
    "    single_axes = []\n",
    "    multiple_axes = []\n",
    "    for galaxy_n in range(len(labels)):\n",
    "        x_slice = slice(galaxy_n*height, (galaxy_n+1)*height)\n",
    "        image_axes.append(plt.subplot(gs[x_slice, :im_width]))\n",
    "        single_axes.append(plt.subplot(gs[x_slice, im_width:im_width+single_width]))\n",
    "        multiple_axes.append(plt.subplot(gs[x_slice, im_width+single_width:]))\n",
    "    \n",
    "\n",
    "#     fig, axes = plt.subplots(nrows=len(labels), figsize=(3, len(labels)*1.5), sharex=True)\n",
    "    make_predictions.plot_samples(samples[:, :1], labels, total_votes, fig, single_axes, alpha=0.06)\n",
    "    for ax in single_axes:\n",
    "        ax.set_xlim([0, 50])\n",
    "\n",
    "    make_predictions.plot_samples(samples, labels, total_votes, fig, multiple_axes, alpha=0.06)\n",
    "    for ax in multiple_axes:\n",
    "        ax.set_xlim([0, 50])\n",
    "        \n",
    "        \n",
    "    for ax_n, ax in enumerate(image_axes):\n",
    "        plot_galaxy(png_locs[ax_n], ax)\n",
    "        \n",
    "    \n",
    "    for n in range(len(labels)):\n",
    "        multiple_axes[n].set_ylabel(r'$p(k|N, D)$', visible=True)\n",
    "        multiple_axes[n].yaxis.set_visible(True)\n",
    "        single_axes[n].set_ylabel(r'$p(k|N, w)$', visible=True)\n",
    "        single_axes[n].yaxis.set_visible(True)\n",
    "        single_axes[n].yaxis.set_major_locator(plt.NullLocator())\n",
    "        multiple_axes[n].yaxis.set_major_locator(plt.NullLocator())\n",
    "        if n < len(labels) - 1:\n",
    "            single_axes[n].xaxis.set_major_locator(plt.NullLocator())\n",
    "            multiple_axes[n].xaxis.set_major_locator(plt.NullLocator())\n",
    "    \n",
    "#     if QUESTION == 'bars':\n",
    "#         question = 'Bar'\n",
    "#     else:\n",
    "#         question = 'Smooth'\n",
    "#     single_axes[-1].set_xlabel(r\"$k$ '{}' votes, of $N$ total\".format(question))\n",
    "#     multiple_axes[-1].set_xlabel(r\"$k$ '{}' votes, of $N$ total\".format(question))\n",
    "    fig.tight_layout()\n",
    "\n",
    "    single_axes[0].legend(\n",
    "        loc='lower center', \n",
    "        bbox_to_anchor=(0.5, 1.1),\n",
    "        ncol=1, \n",
    "        fancybox=True, \n",
    "        shadow=False\n",
    "    )\n",
    "    \n",
    "    multiple_axes[0].legend(\n",
    "        loc='lower center', \n",
    "        bbox_to_anchor=(0.5, 1.1),\n",
    "        ncol=1, \n",
    "        fancybox=True, \n",
    "        shadow=False\n",
    "    )\n",
    "\n",
    "    \n",
    "    fig.tight_layout()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_galaxy(image_loc, ax, n_examples=10, crop=0):\n",
    "    im_size = 424\n",
    "    im = Image.open(image_loc)\n",
    "#     if QUESTION == 'bars':\n",
    "#         crop = 120\n",
    "#     else:\n",
    "    crop = 35\n",
    "    cropped_im = im.crop((crop, crop, 424 - crop, 424 - crop))\n",
    "    ax.imshow(cropped_im)\n",
    "    ax.grid(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    ax.get_xaxis().set_visible(False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = 'has-spiral-arms'\n",
    "answer = 'yes'\n",
    "n = 5\n",
    "samples, labels, total_votes = get_single_answer_data(question, answer)\n",
    "png_locs = df['file_loc'][:n]\n",
    "\n",
    "# catalog = sim_model.catalog[selected_slice]\n",
    "\n",
    "_ = custom_samples_with_galaxies(samples, labels, total_votes, png_locs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, axes = plt.subplots(1, 10, figsize=(20, 12))\n",
    "# for ax_n, ax in enumerate(axes):\n",
    "#     plot_galaxy(sim_model.catalog.iloc[ax_n]['png_loc'], ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected = slice(80, 73, -1)  #Â smooth\n",
    "\n",
    "# selected = slice(0, 7)\n",
    "\n",
    "if QUESTION == 'bars':\n",
    "    selected = slice(0, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.array(sim_model.model.samples)[selected, :]\n",
    "# np.array(sim_model.labels)[selected]\n",
    "# sim_model.catalog['smooth-or-featured_total-votes'][selected]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = custom_samples_with_galaxies(sim_model, selected)\n",
    "# fig.savefig(os.path.join(save_dir, 'mc_model_{}.png'.format(len(np.array(sim_model.labels)[selected]))))\n",
    "# fig.savefig(os.path.join(save_dir, 'mc_model_{}.pdf'.format(len(np.array(sim_model.labels)[selected]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# be sure to switch label in custom_samples before running this\n",
    "# fig = custom_samples(np.array(single_sim_model.model.samples)[selected, :1], np.array(single_sim_model.labels)[selected], total_votes=single_sim_model.total_votes)\n",
    "# fig.savefig(os.path.join(save_dir, 'single_model_{}.png'.format(len(np.array(sim_model.labels)[selected]))))\n",
    "# fig.savefig(os.path.join(save_dir, 'single_model_{}.eps'.format(len(np.array(sim_model.labels)[selected]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(font_scale=1.2)\n",
    "sns.set_style('white')\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ungrouped_coverage_df = discrete_coverage.evaluate_discrete_coverage(\n",
    "    sim_model.labels, \n",
    "    sim_model.bin_probs)\n",
    "coverage_df = ungrouped_coverage_df.groupby('max_state_error').agg({'prediction': 'sum', 'observed': 'sum'}).reset_index()\n",
    "\n",
    "ungrouped_single_coverage_df = discrete_coverage.evaluate_discrete_coverage(\n",
    "    single_sim_model.labels, \n",
    "    single_sim_model.bin_probs)\n",
    "single_coverage_df = ungrouped_single_coverage_df.groupby('max_state_error').agg({'prediction': 'sum', 'observed': 'sum'}).reset_index()\n",
    "\n",
    "\n",
    "plt.plot(coverage_df['max_state_error'], coverage_df['prediction'], label='MC Model Expects')\n",
    "plt.plot(single_coverage_df['max_state_error'], single_coverage_df['prediction'], label='Single Model Expects')\n",
    "plt.plot(single_coverage_df['max_state_error'], coverage_df['observed'], 'k--', label='Actual')\n",
    "\n",
    "ax.set_xlabel('Max Allowed Vote Error')\n",
    "ax.set_ylabel('Galaxies Within Max Error')\n",
    "ax.legend()\n",
    "ax.xaxis.set_major_formatter(StrMethodFormatter('{x:.0f}'))  # must expect 'x' kw arg\n",
    "\n",
    "ax.set_xlim([0, 15])\n",
    "fig.tight_layout()\n",
    "fig.savefig(os.path.join(save_dir, 'coverage_comparison_200_samples.png'))\n",
    "fig.savefig(os.path.join(save_dir, 'coverage_comparison_200_samples.pdf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ungrouped_coverage_df.to_csv(os.path.join(save_dir, QUESTION + '_ungrouped_coverage_df.csv'), index=False)\n",
    "ungrouped_single_coverage_df.to_csv(os.path.join(save_dir, QUESTION + '_ungrouped_coverage_df.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coverage_df['error'] = coverage_df['prediction'] - coverage_df['observed']\n",
    "coverage_df['relative_error'] = coverage_df['error'] / coverage_df['observed']\n",
    "coverage_df.to_csv(os.path.join(save_dir, QUESTION + '_coverage_df.csv'), index=False)\n",
    "coverage_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_coverage_df['error'] = single_coverage_df['prediction'] - single_coverage_df['observed']\n",
    "single_coverage_df['relative_error'] = single_coverage_df['error'] / single_coverage_df['observed']\n",
    "single_coverage_df.to_csv(os.path.join(save_dir, QUESTION + '_single_coverage_df.csv'), index=False)\n",
    "single_coverage_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO - I might consider adding an MSE model as a comparison, to hopefully beat. I think this might be quite similar though. Ideally I can compare this with previous work somehow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(font_scale=1.2)\n",
    "sns.set_style('white')\n",
    "fig, ax = plt.subplots()\n",
    "ax.hist(sim_model.abs_rho_error, bins=25)\n",
    "# ax.axvline(sim_model.mean_abs_rho_error, color='r') \n",
    "ax.set_xlim([0, 1.])\n",
    "ax.set_ylabel('Galaxies')\n",
    "ax.set_xlabel(r'| Expected $\\hat{\\rho}$ - observed vote fraction $\\frac{k}{N}$ |')\n",
    "fig.tight_layout()\n",
    "fig.savefig(os.path.join(save_dir, 'difference_in_rho.png'))\n",
    "fig.savefig(os.path.join(save_dir, 'difference_in_rho.pdf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_model.abs_rho_error.mean(), single_sim_model.abs_rho_error.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(sim_model.mean_abs_rho_error), np.sqrt(single_sim_model.mean_abs_rho_error)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(sim_model.mean_square_rho_error), np.sqrt(single_sim_model.mean_square_rho_error) # this is the rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alpha = 0.3\n",
    "# n_bins = 25\n",
    "\n",
    "# # dummy for bins\n",
    "# fig, ax = plt.subplots()\n",
    "# _, bins, _  = ax.hist(sim_model.labels / sim_model.total_votes, bins=n_bins, alpha=alpha, label=r'Observed $\\rho$')\n",
    "# ax.hist(sim_model.mean_rho_prediction, bins=n_bins, alpha=alpha, label=r'Mean Rho Prediction $\\hat{\\rho}}$')\n",
    "# # ax.hist(single_sim_model.mean_rho_prediction, bins=bins, alpha=alpha, label=r'Single Rho Prediction $\\hat{\\rho}}$')\n",
    "\n",
    "# fig, ax = plt.subplots()\n",
    "# sns.set(font_scale=1.)\n",
    "# sns.set_style('white')\n",
    "\n",
    "# ax.hist(sim_model.mean_rho_prediction, bins=bins, alpha=alpha, label=r'Mean Rho Prediction $\\hat{\\rho}}$')\n",
    "# # ax.hist(single_sim_model.mean_rho_prediction, bins=bins, alpha=alpha, label=r'Single Rho Prediction $\\hat{\\rho}}$')\n",
    "# ax.hist(sim_model.labels / sim_model.total_votes, bins=bins, alpha=alpha, label=r'Observed $\\rho$')\n",
    "# ax.legend()\n",
    "# ax.set_xlim([0., 1.])\n",
    "# ax.set_ylabel('Galaxies')\n",
    "# ax.set_xlabel(r'Typical vote fraction $\\rho$')\n",
    "# fig.tight_layout()\n",
    "# fig.savefig(os.path.join(save_dir, 'typical_vote_fraction_distribution.png'))\n",
    "\n",
    "# This is a repeat of the above histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(sim_model.mean_rho_prediction > 0.5), np.sum(single_sim_model.mean_rho_prediction > 0.5), np.sum((sim_model.labels / sim_model.total_votes) > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(sim_model.labels / sim_model.total_votes).min(), (sim_model.labels / sim_model.total_votes).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_model.mean_rho_prediction.min(), sim_model.mean_rho_prediction.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_sim_model.mean_rho_prediction.min(), single_sim_model.mean_rho_prediction.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_model.total_votes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save DataFrame of predictions + catalog (GZ2) for use elsewhere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_df = pd.DataFrame(data={\n",
    "    'total_votes': sim_model.total_votes, \n",
    "    'k': sim_model.labels, \n",
    "    'vote_fraction': (sim_model.labels / sim_model.total_votes), \n",
    "    'rho_prediction': sim_model.mean_rho_prediction\n",
    "#     'png_loc': sim_model.catalog.png_loc\n",
    "})\n",
    "safe_catalog_cols = list(set(sim_model.catalog.columns.values) - set(['total_votes', 'ra_subject', 'dec_subject']))\n",
    "df = pd.concat([response_df, sim_model.catalog[safe_catalog_cols]], axis=1)\n",
    "df['smooth'] = df['vote_fraction'] > 0.5\n",
    "df['confidence_proxy'] = np.abs(0.5 - df['rho_prediction'])\n",
    "df['rho_predictions'] = 0\n",
    "for n in range(len(df)):\n",
    "    df['rho_predictions'][n] = json.dumps(list(sim_model.model.samples[n, :]))\n",
    "    df = df.sort_values('confidence_proxy', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['rho_predictions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_parquet('/data/repos/zoobot/notebooks/{}_test_predictions_and_gz2_catalog.parquet'.format(QUESTION))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replicate (ish) Sanchez 2017 ROC Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix((sim_model.labels / sim_model.total_votes) > 0.5, sim_model.mean_rho_prediction > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " 1 - ((66 + 99) / (490 + 1845 + 66 + 99))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " 1 - ((189 + 81) / (1858 + 189 + 81 + 372))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "sns.set(font_scale=1.2)\n",
    "sns.set_style('white')\n",
    "\n",
    "fpr, tpr, _ = roc_curve(df['smooth'], df['rho_prediction'])\n",
    "ax.plot(fpr, tpr, label='All')\n",
    "df_low_entropy = df[df['confidence_proxy'] > 0.3]\n",
    "fpr, tpr, _ = roc_curve(df_low_entropy['smooth'], df_low_entropy['rho_prediction'])\n",
    "ax.plot(fpr, tpr, label=r'\"High Confidence\" i.e. $\\hat{\\rho} < 0.2$ or $\\hat{\\rho} > 0.8$')\n",
    "ax.set_xlabel('False Positive Rate')\n",
    "ax.set_ylabel('True Positive Rate')\n",
    "ax.legend()\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(os.path.join(save_dir, 'roc_curve.png'))\n",
    "fig.savefig(os.path.join(save_dir, 'roc_curve.pdf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df), len(df_low_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replicate(ish) Khan 2018 Confusion Matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> After selecting the OBJIDs from Table 2 based on the probability thresholds of 0.985 and 0.926 for spirals and ellipticals respectively,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdf_array = binom.cdf((df['total_votes'] / 2.).astype(int), df['total_votes'], df['rho_prediction'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df['total_votes'] / 2.).astype(int).sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['total_votes'].sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['rho_prediction'].sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(cdf_array, bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binom.cdf(20, 40, 0.88)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(1 - cdf_array > 0.985)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(cdf_array > 0.926)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_prob_df = df[(cdf_array < (1 - 0.985)) | (cdf_array > 0.926)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(high_prob_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if QUESTION == 'smooth':\n",
    "    spiral_pc_to_keep = 516 / 6677\n",
    "    n_spirals = int(len(df) * spiral_pc_to_keep)\n",
    "    elliptical_pc_to_keep = 550 / 5904\n",
    "    n_ellipticals = int(len(df) * elliptical_pc_to_keep)\n",
    "    print(spiral_pc_to_keep, n_spirals, elliptical_pc_to_keep, n_ellipticals)\n",
    "    high_prob_df = pd.concat([\n",
    "        df.sort_values('rho_prediction')[:n_spirals],\n",
    "        df.sort_values('rho_prediction', ascending=False)[:n_ellipticals]\n",
    "    ])\n",
    "if QUESTION == 'bars':\n",
    "    n_to_keep = int(len(df) * 0.08)\n",
    "    high_prob_df = pd.concat([\n",
    "        df.sort_values('rho_prediction')[:int(n_to_keep/2)],\n",
    "        df.sort_values('rho_prediction', ascending=False)[:int(n_to_keep/2)]\n",
    "    ])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_prob_df.sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(high_prob_df['vote_fraction'] >= 0.5, high_prob_df['rho_prediction'] >= 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error = high_prob_df[~(high_prob_df['vote_fraction'] > 0.5) & (high_prob_df['rho_prediction'] > 0.5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error['vote_fraction'] > 0.5, error['rho_prediction'] > 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open(error.iloc[0]['png_loc'])\n",
    "plt.imshow(img)\n",
    "fontdict = {'size': 16, 'color': 'white'}\n",
    "plt.text(30, 360, r'Expected vote frac $\\hat{\\rho}$: 0.80', fontdict=fontdict)\n",
    "plt.text(30, 400, r'Observed vote frac $\\frac{k}{N}$: 0.50', fontdict=fontdict)\n",
    "plt.axis('off')\n",
    "plt.savefig(os.path.join(save_dir, 'high_prob_error_0.png'))\n",
    "plt.savefig(os.path.join(save_dir, 'high_prob_error_0.eps'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img = Image.open(error.iloc[1]['png_loc'])\n",
    "# plt.imshow(img)\n",
    "# fontdict = {'size': 16, 'color': 'white'}\n",
    "# plt.text(30, 360, r'Expected vote frac $\\hat{\\rho}$: 0.13', fontdict=fontdict)\n",
    "# plt.text(30, 400, r'Observed vote frac $\\frac{k}{N}$: 0.54', fontdict=fontdict)\n",
    "# plt.axis('off')\n",
    "# plt.savefig(os.path.join(save_dir, 'high_prob_error_1.png'))\n",
    "# plt.savefig(os.path.join(save_dir, 'high_prob_error_1.eps'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(df['vote_fraction'][:int(len(df) / 2)] > 0.5, df['rho_prediction'][:int(len(df) / 2)] > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if QUESTION == 'smooth':\n",
    "    labels = ['Smooth', 'Featured']\n",
    "    \n",
    "#     cm = np.array([[ 232,    2], [   0, 191]])\n",
    "#     name = 'confusion_matrix_high_confidence'\n",
    "    \n",
    "    cm = np.array([[ 490,   66],\n",
    "       [  99, 1845]])\n",
    "    name = 'confusion_matrix'\n",
    "    \n",
    "if QUESTION == 'bars':\n",
    "    labels = ['No Bar', 'Bar']\n",
    "    cm = np.array([[100,    0], [   0,   100]])\n",
    "    name = 'confusion_matrix_high_confidence'\n",
    "    \n",
    "#     cm = np.array([[1858,    81], [   189,   372]])\n",
    "#     name = 'confusion_matrix'\n",
    "\n",
    "sns.set(font_scale=3.)\n",
    "sns.set_style('white')\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "ax = sns.heatmap(cm, annot=True, fmt='d', cmap=\"Blues\", xticklabels=labels, yticklabels=labels, cbar=False, square=True, ax=ax)\n",
    "ax.set_xlabel('Predicted')\n",
    "ax.set_ylabel('Observed')\n",
    "fig.tight_layout()\n",
    "fig.savefig(os.path.join(save_dir, '{}.png'.format(name)))\n",
    "fig.savefig(os.path.join(save_dir, '{}.pdf'.format(name)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1 - (8 / (1159 + 83 + 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sim_model.export_performance_metrics(save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw a galaxy, infer a range of p, redraw, and measure accuracy - work in progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot other standard acquisition visualisations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_acquisition_viz = False\n",
    "if new_acquisition_viz:\n",
    "    image_locs = sim_model.catalog['png_loc']\n",
    "    images = np.stack([np.array(Image.open(loc)) for loc in image_locs])\n",
    "    assert images.shape == (2500, 424, 424, 3)\n",
    "    acquisition_utils.save_acquisition_examples(images, sim_model.mutual_info, 'mutual_info', save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, row = plt.subplots(ncols=3, figsize=(12, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# row = sim_model.acquisition_vs_volunteer_votes(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualise Selection of Catalog Features w.r.t. Acquisition Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(constrained_layout=True, figsize=(20, 12))\n",
    "gs = gridspec.GridSpec(6, 5, figure=fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Smooth Votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax0 = plt.subplot(gs[:4, :])\n",
    "sns.scatterplot(\n",
    "    np.array(sim_model.catalog['smooth-or-featured_smooth_fraction'] * 40).astype(int),\n",
    "    sim_model.model.acquisitions, hue=np.array(sim_model.model.acquisitions) > np.array(sim_model.model.acquisitions[103]),\n",
    "    ax=ax0)\n",
    "ax0.set_ylabel('Mutual Information')\n",
    "ax0.set_xlabel('Smooth Votes')\n",
    "ax0.legend([r'Top 10% $\\mathcal{I}$', r'Bottom 90% $\\mathcal{I}$'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax1 = plt.subplot(gs[4:, :])\n",
    "ax1.hist(np.array(sim_model.labels * 40).astype(int), density=True, alpha=0.4)\n",
    "ax1.hist(np.array(sim_model.labels * 40).astype(int)[:200], density=True, alpha=0.4)\n",
    "ax1.set_ylabel('Frequency')\n",
    "ax1.set_xlabel('Smooth Votes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.savefig(os.path.join(save_dir, 'temp.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Redshift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "sns.jointplot(np.array(sim_model.labels * 40).astype(int), sim_model.catalog['redshift'], kind='kde')\n",
    "ax0.set_ylabel('Redshift')\n",
    "ax0.set_xlabel('Volunteer Votes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax0 = plt.subplot(gs[:2, :])\n",
    "sns.jointplot(np.array(sim_model.labels * 40).astype(int), sim_model.catalog['redshift'], kind='kde', ax=ax0)\n",
    "ax0.set_ylabel('Redshift')\n",
    "ax0.set_xlabel('Volunteer Votes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax0 = plt.subplot(gs[:2, :])\n",
    "sns.jointplot(sim_model.catalog['redshift'], sim_model.model.acquisitions, ax=ax0)\n",
    "ax0.set_ylabel('Mutual Information')\n",
    "ax0.set_xlabel('Redshift')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax1 = plt.subplot(gs[4:, :])\n",
    "\n",
    "ax1.hist(sim_model.catalog['redshift'], density=True, alpha=0.4)\n",
    "# ax1.hist(sim_model.catalog['redshift'], density=True, alpha=0.4)\n",
    "ax1.set_ylabel('Frequency')\n",
    "ax1.set_xlabel('Smooth Votes')\n",
    "# TODO sort by mutual information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Below here is only relevant for DECALS, with extra questions. TODO update with GZ2 merger options?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merger_strs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merger_label = 'merging_major-disturbance'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax0 = plt.subplot(gs[:2, :])\n",
    "sns.scatterplot(sim_model.catalog[merger_label], sim_model.model.mutual_info, ax=ax0)\n",
    "ax0.set_ylabel('Mutual Information')\n",
    "ax0.set_xlabel(merger_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.hist(sim_model.catalog[merger_label], bins=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featured_no_merger = sim_model.model.mutual_info[(sim_model.catalog[merger_label] == 0) & (sim_model.catalog['smooth-or-featured_smooth_fraction'] < 0.4)]\n",
    "featured_merger = sim_model.model.mutual_info[(sim_model.catalog[merger_label] > 0) & (sim_model.catalog['smooth-or-featured_smooth_fraction'] < 0.4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featured_no_merger.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featured_merger.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax.hist(featured_no_merger, alpha=0.3, density=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax.hist(featured_merger, alpha=0.3, density=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.scatterplot(\n",
    "    sim_model.catalog['smooth-or-featured_artifact'], \n",
    "    sim_model.model.mutual_info, \n",
    "    hue=sim_model.model.mutual_info > sim_model.model.mutual_info[103])\n",
    "ax.set_xlim([0, 14.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(\n",
    "    sim_model.catalog['smooth-or-featured_artifact'], \n",
    "    sim_model.model.mutual_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax.hist(\n",
    "    sim_model.catalog['smooth-or-featured_artifact'][sim_model.model.mutual_info > sim_model.model.mutual_info[100]],\n",
    "    density=True,\n",
    "    alpha=0.4,\n",
    ")\n",
    "ax.hist(\n",
    "    sim_model.catalog['smooth-or-featured_artifact'][sim_model.model.mutual_info < sim_model.model.mutual_info[100]],\n",
    "    density=True,\n",
    "    alpha=0.4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "has-spiral-arms_yes\n",
    "spiral-winding_prediction-encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(\n",
    "    sim_model.catalog['has-spiral-arms_yes'][sim_model.catalog['smooth-or-featured_smooth_fraction'] < 0.5], \n",
    "    sim_model.model.mutual_info[sim_model.catalog['smooth-or-featured_smooth_fraction'] < 0.5], \n",
    "    hue=sim_model.model.mutual_info > sim_model.model.mutual_info[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.hist(\n",
    "    sim_model.catalog['has-spiral-arms_yes'][sim_model.model.mutual_info > sim_model.model.mutual_info[100]],\n",
    "    density=True,\n",
    "    alpha=0.4,\n",
    ")\n",
    "ax.hist(\n",
    "    sim_model.catalog['has-spiral-arms_yes'][sim_model.model.mutual_info < sim_model.model.mutual_info[100]],\n",
    "    density=True,\n",
    "    alpha=0.4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.hist(\n",
    "    sim_model.catalog['redshift'][sim_model.model.mutual_info > sim_model.model.mutual_info[100]],\n",
    "    density=True,\n",
    "    alpha=0.4,\n",
    ")\n",
    "ax.hist(\n",
    "    sim_model.catalog['redshift'][sim_model.model.mutual_info < sim_model.model.mutual_info[100]],\n",
    "    density=True,\n",
    "    alpha=0.4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.hist(\n",
    "    sim_model.catalog['merging_major-disturbance'][sim_model.model.mutual_info > sim_model.model.mutual_info[100]],\n",
    "    density=True,\n",
    "    alpha=0.4,\n",
    ")\n",
    "ax.hist(\n",
    "    sim_model.catalog['merging_major-disturbance'][sim_model.model.mutual_info < sim_model.model.mutual_info[100]],\n",
    "    density=True,\n",
    "    alpha=0.4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for merger_label in merger_strs:\n",
    "    print('\\n' + merger_label)\n",
    "    print(sim_model.model.mutual_info[sim_model.catalog[merger_label] > 1].mean())\n",
    "    print(sim_model.model.mutual_info[sim_model.catalog[merger_label] == 1].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "    {'Volunteer Response': 'Merging', 'Mean Mutual Information': sim_model.model.mutual_info[sim_model.catalog['merging_both-v1'] > 1].mean()},\n",
    "    {'Volunteer Response': 'Major Disturbance', 'Mean Mutual Information': sim_model.model.mutual_info[sim_model.catalog['merging_major-disturbance'] > 1].mean()},\n",
    "    {'Volunteer Response': 'Minor Disturbance', 'Mean Mutual Information': sim_model.model.mutual_info[sim_model.catalog['merging_minor-disturbance'] > 1].mean()},\n",
    "    {'Volunteer Response': 'No Disturbance', 'Mean Mutual Information': sim_model.model.mutual_info[sim_model.catalog['merging_none'] > 20].mean()}\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax = sns.barplot(data=df, y='Volunteer Response', x='Mean Mutual Information', ax=ax)\n",
    "ax.set_xlim([0.2, 0.36])\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sim_model.model.mutual_info[(sim_model.catalog['merging_minor-disturbance'] + sim_model.catalog['merging_major-disturbance']) > 0].mean())\n",
    "print(sim_model.model.mutual_info[(sim_model.catalog['merging_minor-disturbance'] + sim_model.catalog['merging_major-disturbance']) == 0].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(sim_model.catalog['merging_tidal-debris-v1'], bins=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('zoobot': conda)",
   "language": "python",
   "name": "python37664bitzoobotcondad3adbdfef5c444648572db3b6ec7c1e0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
