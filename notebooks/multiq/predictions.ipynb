{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/walml/repos/zoobot/notebooks/multiq\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already up-to-date.\n"
     ]
    }
   ],
   "source": [
    "!git pull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import argparse\n",
    "import glob\n",
    "import json\n",
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib.ticker import StrMethodFormatter\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import seaborn as sns\n",
    "from sklearn import metrics\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from astropy.table import Table  # for NSA\n",
    "from astropy import units as u\n",
    "from sklearn.metrics import confusion_matrix, roc_curve\n",
    "from PIL import Image\n",
    "from scipy.stats import binom\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error, mean_absolute_error\n",
    "\n",
    "from shared_astro_utils import astropy_utils, matching_utils\n",
    "from zoobot.estimators import make_predictions, bayesian_estimator_funcs\n",
    "from zoobot.tfrecord import read_tfrecord\n",
    "from zoobot.uncertainty import discrete_coverage\n",
    "from zoobot.estimators import input_utils, losses\n",
    "from zoobot.tfrecord import catalog_to_tfrecord\n",
    "from zoobot.active_learning import metrics, simulated_metrics, acquisition_utils, check_uncertainty, simulation_timeline, run_estimator_config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    for gpu in gpus:\n",
    "        tf.config.experimental.set_memory_growth(gpu, True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/home/walml/repos/zoobot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start = 50\n",
    "# end = 60\n",
    "# start = 0\n",
    "# end=5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the (latest) model under `model_name` folder in `results_dir`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# catalog_loc = 'data/latest_labelled_catalog.csv\n",
    "# catalog_loc = 'data/decals/decals_master_catalog.csv'\n",
    "catalog_loc = 'data/gz2/gz2_master_catalog.csv'\n",
    "catalog = pd.read_csv(catalog_loc, dtype={'subject_id': str})  # original catalog\n",
    "catalog['file_loc'] = catalog['local_png_loc'].apply(lambda x: '/media/walml/beta/decals/png_native' + x[32:])\n",
    "\n",
    "\n",
    "# catalog_loc = 'data/decals/temp_calibration_catalog.csv'\n",
    "# catalog = pd.read_csv(catalog_loc, dtype={'subject_id': str})  # original catalog\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Loading multiple tfrecords with interleaving, shuffle=False\n",
      "WARNING:root:Loading multiple tfrecords with interleaving, shuffle=False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{smooth-or-featured, indices 0 to 1, asked after None: (0, 1), has-spiral-arms, indices 2 to 3, asked after <zoobot.estimators.losses.Answer object at 0x7f78a221cd10>: (2, 3), bar, indices 4 to 5, asked after <zoobot.estimators.losses.Answer object at 0x7f78a221cd10>: (4, 5), bulge-size, indices 6 to 9, asked after <zoobot.estimators.losses.Answer object at 0x7f78a221cd10>: (6, 9)}\n",
      "['/home/walml/repos/zoobot/data/gz2/shards/all_featp5_facep5_sim_2p5_300/eval_shards/s300_shard_0.tfrecord']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['dr7objid_588017726011736202',\n",
       " 'dr7objid_587727942423937083',\n",
       " 'dr7objid_588017604676092033',\n",
       " 'dr7objid_588017626160037993',\n",
       " 'dr7objid_587742551225008388']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Figures will be saved to here\n",
    "\n",
    "analysis_dir = 'analysis/multiquestion'\n",
    "# save_dir = f'{analysis_dir}/{model_name}'\n",
    "# if not os.path.exists(save_dir):\n",
    "#     os.mkdir(save_dir)\n",
    "\n",
    "# results_dir = '/home/walml/repos/zoobot/data/experiments/live/no_cutouts/iteration_0'\n",
    "# results_dir = '/home/walml/repos/zoobot/results/smooth_or_featured_offline'\n",
    "# results_dir = '/home/walml/repos/zoobot/results/debug'\n",
    "# results_dir = '/home/walml/repos/zoobot/results/latest/effnetB0_decals_mf_244px_256init_10k'\n",
    "# results_dir = '/home/walml/repos/zoobot/results/latest/latest_offline_full'\n",
    "\n",
    "# two identical models, trained at different times\n",
    "# results_dir = '/home/walml/repos/zoobot/results/latest/latest_offline_10k_x2val_b256'\n",
    "# results_dir = '/home/walml/repos/zoobot/results/latest/latest_offline_10k_x2val'\n",
    "\n",
    "# results_dir = '/home/walml/repos/zoobot/results/latest/latest_dirichlet_c100_active_n3_layers'\n",
    "# results_dir = '/home/walml/repos/zoobot/results/all_featp5_facep5_sim_256_arc_final_0'\n",
    "\n",
    "questions = [\n",
    "    'smooth-or-featured',\n",
    "    'has-spiral-arms',\n",
    "    'bar',\n",
    "    'bulge-size'\n",
    "]\n",
    "\n",
    "# decals cols\n",
    "# version = 'decals'\n",
    "# label_cols = [\n",
    "#     'smooth-or-featured_smooth',\n",
    "#     'smooth-or-featured_featured-or-disk',\n",
    "#     'has-spiral-arms_yes',\n",
    "#     'has-spiral-arms_no',\n",
    "#     'bar_strong',\n",
    "#     'bar_weak',\n",
    "#     'bar_no',\n",
    "#     'bulge-size_dominant',\n",
    "#     'bulge-size_large',\n",
    "#     'bulge-size_moderate',\n",
    "#     'bulge-size_small',\n",
    "#     'bulge-size_none'\n",
    "# ]\n",
    "\n",
    "# gz2 cols\n",
    "version = 'gz2'\n",
    "label_cols = [\n",
    "    'smooth-or-featured_smooth',\n",
    "    'smooth-or-featured_featured-or-disk',\n",
    "    'has-spiral-arms_yes',\n",
    "    'has-spiral-arms_no',\n",
    "    'bar_yes',\n",
    "    'bar_no',\n",
    "    'bulge-size_dominant',\n",
    "    'bulge-size_obvious',\n",
    "    'bulge-size_just-noticeable',\n",
    "    'bulge-size_no'\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "schema = losses.Schema(label_cols, questions, version=version)\n",
    "\n",
    "batch_size = 8\n",
    "initial_size = 300\n",
    "# initial_size = 128\n",
    "crop_size = int(initial_size * 0.75)\n",
    "# crop_size = 128\n",
    "final_size = 224\n",
    "channels = 3\n",
    "\n",
    "n_samples = 10\n",
    "\n",
    "# if loading single test tfrecord\n",
    "# tfrecord_locs = [f'data/decals/shards/multilabel_{img_size}/eval/s{initial_size}_shard_0.tfrecord']\n",
    "# tfrecord_locs = ['data/decals/shards/multilabel_master_256/train/s256_shard_0.tfrecord']\n",
    "# tfrecord_locs = glob.glob(f'/media/walml/beta/decals/multilabel_master_{initial_size}/train/*.tfrecord')[start:end]\n",
    "# tfrecord_locs = glob.glob(f'/home/walml/repos/zoobot/data/decals/shards/decals_multiq_{initial_size}_sim_init_2500_featp4/train_shards/*.tfrecord')[start:end]\n",
    "\n",
    "# for all labelled decals galaxies\n",
    "# train_locs = glob.glob(f'/home/walml/repos/zoobot/data/decals/shards/decals_multiq_{initial_size}/train_shards/*.tfrecord')\n",
    "# eval_locs = glob.glob(f'/home/walml/repos/zoobot/data/decals/shards/decals_multiq_{initial_size}/eval_shards/*.tfrecord')\n",
    "# tfrecord_locs = train_locs + eval_locs\n",
    "\n",
    "# for all decals galaxies after filter\n",
    "# train_locs = glob.glob(f'/home/walml/repos/zoobot/data/decals/shards/multilabel_master_filtered_{initial_size}/train/*.tfrecord')\n",
    "# eval_locs = glob.glob(f'/home/walml/repos/zoobot/data/decals/shards/multilabel_master_filtered_{initial_size}/eval/*.tfrecord')\n",
    "# tfrecord_locs = eval_locs\n",
    "\n",
    "# tfrecord_locs = train_locs[:1]\n",
    "\n",
    "# for calibration dr5 galaxies\n",
    "# eval_locs = glob.glob(f'/home/walml/repos/zoobot/data/decals/shards/temp_calibration_shards_feat/train/*.tfrecord')\n",
    "# tfrecord_locs = eval_locs\n",
    "\n",
    "# for 10k labelled/filtered GZ2 galaxies\n",
    "# train_locs = glob.glob(f'/home/walml/repos/zoobot/data/gz2/shards/all_featp5_facep5_sim_2p5_{initial_size}/train_shards/*.tfrecord')\n",
    "eval_locs = glob.glob(f'/home/walml/repos/zoobot/data/gz2/shards/all_featp5_facep5_sim_2p5_{initial_size}/eval_shards/*.tfrecord')\n",
    "# tfrecord_locs = train_locs + eval_locs\n",
    "tfrecord_locs = eval_locs\n",
    "\n",
    "# for 10k UNFILTERED GZ2 galaxies\n",
    "# eval_locs = glob.glob(f'/home/walml/repos/zoobot/data/gz2/shards/all_featp5_facep5_sim_{initial_size}_unfiltered/eval_shards/*.tfrecord')\n",
    "# tfrecord_locs = train_locs + eval_locs\n",
    "# tfrecord_locs = eval_locs\n",
    "\n",
    "\n",
    "print(tfrecord_locs)\n",
    "eval_config = run_estimator_config.get_eval_config(tfrecord_locs, label_cols, batch_size, initial_size, final_size, channels)\n",
    "# print(eval_config.greyscale)\n",
    "# print(eval_config.permute_channels)\n",
    "eval_config.drop_remainder = False\n",
    "dataset = input_utils.get_input(config=eval_config)\n",
    "\n",
    "feature_spec = input_utils.get_feature_spec({'id_str': 'string'})\n",
    "id_str_dataset = input_utils.get_dataset(tfrecord_locs, feature_spec, batch_size=1, shuffle=False, repeat=False, drop_remainder=False)\n",
    "id_strs = [str(d['id_str'].numpy().squeeze())[2:-1] for d in id_str_dataset]\n",
    "id_strs[:5]\n",
    "\n",
    "# n = 0\n",
    "# for batch in id_str_dataset:\n",
    "#     for id_str in batch:\n",
    "#         n+=1\n",
    "# print(n)\n",
    "\n",
    "# counter = Counter()\n",
    "# n = 0\n",
    "# for g_batch, y_batch in dataset:\n",
    "# #     for g in g_batch:\n",
    "# #         counter[g.numpy().sum()] += 1\n",
    "#         n+=tf.shape(g_batch)[0]\n",
    "# print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, axes = plt.subplots(ncols=3)\n",
    "# n=0\n",
    "# for images, labels in dataset.take(3):\n",
    "#     image = images[0]\n",
    "#     axes[n].imshow(image.numpy().squeeze())\n",
    "#     n+= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4000"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(id_strs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # if loading png\n",
    "\n",
    "# print(catalog['file_loc'])\n",
    "# assert all([os.path.isfile(x) for x in catalog['file_loc']])\n",
    "# filenames = tf.constant(list(catalog['file_loc']), dtype=tf.string)\n",
    "# dataset = tf.data.Dataset.from_tensor_slices(filenames)\n",
    "\n",
    "# def parse_image(im):\n",
    "#     im = tf.image.decode_png(im, channels=channels)\n",
    "#     im = tf.image.convert_image_dtype(im, tf.float32)\n",
    "#     im = tf.image.resize(im, [initial_size, initial_size])\n",
    "#     return im\n",
    "\n",
    "\n",
    "# # for im in dataset.take(1):\n",
    "# #     print(im)\n",
    "\n",
    "# # assert False\n",
    "\n",
    "# dataset = dataset.map(tf.io.read_file)\n",
    "# dataset = dataset.map(parse_image)\n",
    "\n",
    "# config = default_estimator_params.get_eval_config(['do not use'], label_cols, batch_size, initial_size, final_size, channels)\n",
    "\n",
    "# dataset = dataset.batch(batch_size)\n",
    "\n",
    "# # for batch in dataset.take(1):\n",
    "# #     print(tf.shape(batch))\n",
    "# # #     plt.imshow(batch[0])\n",
    "\n",
    "\n",
    "# # dataset = dataset.map(lambda x: check_shape(x))\n",
    "\n",
    "# dataset = dataset.map(lambda x: input_utils.preprocess_images(x, config))\n",
    "\n",
    "\n",
    "# # for batch in dataset.take(1):\n",
    "# #     print(tf.shape(batch))\n",
    "# #     plt.imshow(batch[0].numpy().squeeze())\n",
    "\n",
    "\n",
    "# id_strs = catalog['iauname']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 300, 300, 1)\n"
     ]
    }
   ],
   "source": [
    "for images, _ in dataset.take(1):\n",
    "    print(images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Crop size and final size are similar: skipping resizing and cropping directly to final_size (ignoring crop_size)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results/temp/latest_offline_sim_unfiltered/in_progress\n"
     ]
    }
   ],
   "source": [
    "model = run_estimator_config.get_model(schema, initial_size, crop_size, final_size)\n",
    "# checkpoint_dir = 'results/debug_300/models/final'\n",
    "# checkpoint_dir = 'results/latest/test/models/final'\n",
    "checkpoint_dir = 'results/temp/latest_offline_sim_unfiltered/in_progress'\n",
    "# checkpoint_dir = 'results/latest/latest_dirichlet_baseline_a/final'\n",
    "\n",
    "# iteration 0!\n",
    "# checkpoint_dir = f'{results_dir}/iteration_0/estimators/models'\n",
    "# checkpoint_dir = f'{results_dir}/models'\n",
    "# checkpoint_dir = f'{results_dir}/final'\n",
    "\n",
    "print(checkpoint_dir)\n",
    "load_status = model.load_weights(checkpoint_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f785024ccd0>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_status.assert_nontrivial_match()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f785024ccd0>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_status.assert_existing_objects_matched()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.1637856, 25.7217   ],\n",
       "       [ 4.240965 , 17.857807 ],\n",
       "       [ 2.5053477,  5.255993 ],\n",
       "       [ 6.9282327, 10.114271 ],\n",
       "       [ 1.1699128, 28.25859  ],\n",
       "       [ 1.5261496, 14.851337 ],\n",
       "       [ 1.223648 , 23.347664 ],\n",
       "       [10.208698 , 15.582774 ],\n",
       "       [ 2.0329623,  7.5228977],\n",
       "       [ 1.423986 , 13.80774  ]], dtype=float32)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(dataset.take(5))[:10, :2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[22.870869 ,  1.0020524],\n",
       "       [ 1.9166465,  1.6685133],\n",
       "       [ 4.0535784,  1.3302182],\n",
       "       [ 2.3363771,  1.4959371],\n",
       "       [18.832624 ,  1.0005579],\n",
       "       [21.760794 ,  1.0022479],\n",
       "       [17.637577 ,  1.0057342],\n",
       "       [ 1.5637734,  2.458299 ],\n",
       "       [ 5.3624516,  1.087073 ],\n",
       "       [18.150488 ,  1.0050126]], dtype=float32)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(dataset.take(5))[:10, 2:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 20s 39ms/step - loss: 3.5191\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.5191378593444824"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(dataset)  # filtered 3.5 (normal), 20 secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    375/Unknown - 15s 39ms/step - loss: 3.5278"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-c0ce69ba6d27>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# unfiltered\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/zoobot/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/zoobot/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict)\u001b[0m\n\u001b[1;32m   1079\u001b[0m                 step_num=step):\n\u001b[1;32m   1080\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1081\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1082\u001b[0m               \u001b[0;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1083\u001b[0m               \u001b[0;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/zoobot/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/zoobot/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    616\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 618\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    619\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[0;32m~/anaconda3/envs/zoobot/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2420\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/zoobot/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1664\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1665\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1667\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/zoobot/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/zoobot/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/anaconda3/envs/zoobot/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.evaluate(dataset)  # unfiltered = 2.04 73 secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %timeit predictions = model.predict(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copied from trust_the_model.ipynb\n",
    "def show_galaxies(galaxies, scale=3, nrows=6, ncols=6):\n",
    "    fig = plt.gcf()\n",
    "\n",
    "    plt.figure(figsize=(scale * nrows, scale * ncols * 1.025))\n",
    "    gs1 = gridspec.GridSpec(nrows, ncols)\n",
    "    gs1.update(wspace=0.0, hspace=0.0)\n",
    "    galaxy_n = 0\n",
    "    for row_n in range(nrows):\n",
    "        for col_n in range(ncols):\n",
    "            galaxy = np.squeeze(galaxies[galaxy_n])\n",
    "            ax = plt.subplot(gs1[row_n, col_n])\n",
    "            ax.imshow(galaxy)\n",
    "#             ax.text(10, 20, 'Smooth = {:.2f}'.format(galaxy['smooth-or-featured_smooth_fraction']), fontsize=12, color='r')\n",
    "#             ax.text(10, 50, r'$\\rho = {:.2f}$, Var ${:.3f}$'.format(galaxy['median_prediction'], 3*galaxy['predictions_var']), fontsize=12, color='r')\n",
    "#             ax.text(10, 80, '$L = {:.2f}$'.format(galaxy['bcnn_likelihood']), fontsize=12, color='r')\n",
    "            ax.axis('off')\n",
    "            galaxy_n += 1\n",
    "#     print('Mean L: {:.2f}'.format(df[:nrows * ncols]['bcnn_likelihood'].mean()))\n",
    "    fig = plt.gcf()\n",
    "#     fig.tight_layout()\n",
    "    return fig\n",
    "\n",
    "for images, labels in dataset.take(1):\n",
    "    print(images.shape)\n",
    "    print(labels.shape)\n",
    "    \n",
    "# plt.hist(images.numpy()[0].flatten())\n",
    "\n",
    "_ = show_galaxies(images.numpy(), nrows=2, ncols=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_model = tf.keras.models.Sequential()\n",
    "pre_model.add(tf.keras.layers.Input(shape=(initial_size, initial_size, 1)))\n",
    "run_estimator_config.add_preprocessing_layers(pre_model, crop_size, final_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pre_model.predict(dataset.take(1))\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = show_galaxies(output, nrows=2, ncols=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = run_estimator_config.get_model(schema, initial_size, crop_size, final_size, weights_loc=checkpoint_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.predict(dataset.take(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from zoobot.estimators import efficientnet\n",
    "\n",
    "# input_shape = (final_size, final_size, 1)\n",
    "# effnet = efficientnet.EfficientNet_custom_top(\n",
    "#     schema=schema,\n",
    "#     input_shape=input_shape,\n",
    "#     get_effnet=efficientnet.EfficientNetB0\n",
    "#     # further kwargs will be passed to get_effnet\n",
    "#     # dropout_rate=dropout_rate,\n",
    "#     # drop_connect_rate=drop_connect_rate\n",
    "# )\n",
    "# # effnet.load_weights(checkpoint_dir)\n",
    "\n",
    "# model = tf.keras.models.Sequential()\n",
    "# model.add(pre_model)\n",
    "# model.add(effnet)\n",
    "\n",
    "# # model.load_weights(checkpoint_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_config = run_estimator_config.get_run_config(initial_size, final_size, crop_size, False, '', train_locs, eval_locs, 12, schema, batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_loc = 'data/experiments/live/latest/iteration_0/iteration.db'\n",
    "db = sqlite3.connect(db_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = database.get_all_subjects_df(db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unlabelled_locs = glob.glob(f'/home/walml/repos/zoobot/data/gz2/shards/all_featp5_facep5_sim_{initial_size}/*.tfrecord')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_str_dataset = input_utils.get_dataset(unlabelled_locs, feature_spec, batch_size=1, shuffle=False, repeat=False, drop_remainder=False)\n",
    "id_strs = [str(d['id_str'].numpy().squeeze())[2:-1] for d in id_str_dataset]\n",
    "len(id_strs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zoobot.active_learning import database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = database.make_predictions_on_tfrecord([unlabelled_locs[0]], model, run_config, db, n_samples, initial_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unlabelled_subjects, samples = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(unlabelled_subjects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unlabelled_subjects[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unlabelled_subjects[0]['predictions'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unlabelled_config = input_utils.InputConfig(\n",
    "        name='eval',\n",
    "        tfrecord_loc=[unlabelled_locs[0]],\n",
    "        label_cols=[],\n",
    "        stratify=False,\n",
    "        shuffle=False,  # see above\n",
    "        repeat=False,\n",
    "        drop_remainder=False,\n",
    "        stratify_probs=None,\n",
    "        geometric_augmentation=False,\n",
    "        photographic_augmentation=False,\n",
    "        contrast_range=(0.98, 1.02),\n",
    "        batch_size=batch_size,\n",
    "        initial_size=initial_size,\n",
    "        final_size=final_size,\n",
    "        channels=channels,\n",
    "        greyscale=True,\n",
    "        zoom_central=False  # SMOOTH MODE\n",
    "        # zoom_central=True  # BAR MODE\n",
    "    )\n",
    "unlabelled_dataset = input_utils.get_input(config=unlabelled_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_direct = np.stack([model.predict(unlabelled_dataset) for n in range(n_samples)], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_direct.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples[0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unlabelled_subjects[5]['predictions'][0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_direct[5, 0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema.answers[2].text, schema.answers[3].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema.answers[4].text, schema.answers[5].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=5, sharex=True)\n",
    "for subject_n in range(5):\n",
    "    ax = axes[subject_n]\n",
    "    ax.hist(predictions_direct[subject_n, 4] / predictions_direct[subject_n, 5], alpha=.5)\n",
    "    ax.hist(unlabelled_subjects[subject_n]['predictions'][4] / unlabelled_subjects[subject_n]['predictions'][5], alpha=.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=5, sharex=True, figsize=(4, 12))\n",
    "for subject_n in range(5):\n",
    "    ax = axes[subject_n]\n",
    "    ax.imshow(np.array(Image.open(df['file_loc'][subject_n])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_strs[0], unlabelled_subjects[0]['id_str']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.stack([model.predict(dataset) for n in range(n_samples)], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions[0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions[0, :2, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions[12, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions[12, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.hist(np.std(predictions[:, 0, :], axis=-1), bins=30)\n",
    "# plt.xlabel('Mean smooth/featured std')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for batch_x, batch_y in dataset:\n",
    "#     print(batch_y.numpy())\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels = np.concatenate([batch_y for (_, batch_y) in test_dataset], axis=0)\n",
    "# labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots()\n",
    "# ax.hist(predictions[:, 0], alpha=0.5, label='Predictions', density=True)\n",
    "# ax.hist(labels[:, 0] / labels[:, :2].sum(axis=1), alpha=0.5, label='Labels', density=True)\n",
    "# plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(predictions[:, 0].min(), labels[:, 0].min())\n",
    "# print(predictions[:, 0].max(), labels[:, 0].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# acquisitions = acquisition_utils.mutual_info_acquisition_func_multiq(predictions, schema, retirement=40)\n",
    "# acquisitions.shape\n",
    "# acquisitions\n",
    "\n",
    "# single_q_acquisitions = np.array(acquisition_utils.mutual_info_acquisition_func(predictions[:, 0], expected_votes=40))\n",
    "# single_q_acquisitions[:5], acquisitions[0, :5], acquisitions[1, :5]  # smooth mutual acq should be identical, for both answers by symmmetry\n",
    "# acquisitions[2, :5], acquisitions[3, :5]  # has-spiral-arms also by symmetry\n",
    "# acquisitions[4, :5], acquisitions[5, :5], acquisitions[6, :5]  # but for spiral winding there are 3 answers so *not* identical\n",
    "# predictions.shape, acquisitions.shape, len(id_strs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.shape, len(id_strs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def prediction_to_row(prediction, id_str):\n",
    "#     row = {\n",
    "#         'id_str': id_str\n",
    "#     }\n",
    "#     for n, col in enumerate(label_cols):\n",
    "#         answer = label_cols[n]\n",
    "#         row[answer + '_prediction'] = json.dumps(list(prediction[n].astype(float)))\n",
    "# #         row[answer + '_acquisition'] = acquisition[n]\n",
    "#         row[answer + '_prediction_mean'] = float(prediction[n].mean())\n",
    "# #         row[answer + '_acquisition'] = acquisition[n]\n",
    "# #         row['total_acquisition'] = acquisition.sum()\n",
    "#     return row\n",
    "\n",
    "def prediction_to_row(prediction, id_str):\n",
    "    row = {\n",
    "        'id_str': id_str\n",
    "    }\n",
    "    for n, col in enumerate(label_cols):\n",
    "        answer = label_cols[n]\n",
    "        row[answer + '_concentration'] = json.dumps(list(prediction[n].astype(float)))\n",
    "#         row[answer + '_acquisition'] = acquisition[n]\n",
    "        row[answer + '_concentration_mean'] = float(prediction[n].mean())\n",
    "#         row[answer + '_acquisition'] = acquisition[n]\n",
    "#         row['total_acquisition'] = acquisition.sum()\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def all_to_row(prediction, acquisition, id_str):\n",
    "#     row = {\n",
    "#         'id_str': id_str\n",
    "#     }\n",
    "#     for n, col in enumerate(label_cols):\n",
    "#         answer = label_cols[n]\n",
    "#         row[answer + '_prediction'] = prediction[n]\n",
    "# #         row[answer + '_acquisition'] = acquisition[n]\n",
    "#         row[answer + '_prediction_mean'] = float(prediction[n].mean())\n",
    "# #         row[answer + '_acquisition'] = acquisition[n]\n",
    "# #         row['total_acquisition'] = acquisition.sum()\n",
    "#     return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [prediction_to_row(predictions[n], id_strs[n]) for n in range(len(predictions))]\n",
    "# data = [all_to_row(predictions[n], acquisitions[n], id_strs[n]) for n in range(len(predictions))]\n",
    "predictions_df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(predictions_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog['dr7objid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# catalog['iauname'] = catalog['iauname'].astype(str)\n",
    "# predictions_df['iauname'] = predictions_df['id_str'].astype(str)\n",
    "catalog['id_str'] = catalog['dr7objid'].apply(lambda x: 'dr7objid_' + str(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions_df['id_str'].sort_values().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# catalog['iauname'].sort_values().values\n",
    "print(len(catalog))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df['id_str']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog['id_str']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(catalog, predictions_df, how='inner', on='id_str')\n",
    "print(len(df), len(predictions_df))\n",
    "assert len(df) == len(predictions_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for q in schema.questions:\n",
    "#     a = q.answers[0]\n",
    "#     print(a.text, mean_squared_error(df[a.text + '_fraction'], df[a.text + '_prediction_mean']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for q in schema.questions:\n",
    "#     a = q.answers[0]\n",
    "#     print(a.text, mean_absolute_error(df[a.text + '_fraction'], df[a.text + '_prediction_mean']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(12, 12))\n",
    "# axes = [ax for row in axes for ax in row]\n",
    "# for n, q in enumerate(schema.questions):\n",
    "#     a = q.answers[0]\n",
    "#     sns.scatterplot(data=df, x=a.text + '_fraction', y=a.text + '_prediction_mean', ax=axes[n], alpha=0.3)\n",
    "# fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for q in schema.questions:\n",
    "#     a = q.answers[0]\n",
    "#     print(a.text, mean_squared_error(df[a.text + '_fraction'], df[a.text + '_prediction_mean']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv('temp/calibration_predictions.csv', index=False)\n",
    "# df.to_csv('temp/10k_model_a_predictions.csv', index=False)\n",
    "# df.to_csv('temp/10k_model_b_predictions.csv', index=False)\n",
    "# df.to_csv('temp/dirichlet_concentrations_arc_al.csv', index=False)\n",
    "# df.to_csv('temp/dirichlet_concentrations_arc_bl.csv', index=False)\n",
    "# df.to_csv('temp/dirichlet_concentrations_arc_b.csv', index=False)\n",
    "# df.to_csv('temp/gz2_all_2p5_eval.csv', index=False)\n",
    "df.to_csv('temp/gz2_filtered_2p5_eval.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copied from trust_the_model.ipynb\n",
    "def show_galaxies(df, scale=3, nrows=6, ncols=6):\n",
    "    fig = plt.gcf()\n",
    "\n",
    "    plt.figure(figsize=(scale * nrows, scale * ncols * 1.025))\n",
    "    gs1 = gridspec.GridSpec(nrows, ncols)\n",
    "    gs1.update(wspace=0.0, hspace=0.0)\n",
    "    galaxy_n = 0\n",
    "    for row_n in range(nrows):\n",
    "        for col_n in range(ncols):\n",
    "            galaxy = df.iloc[galaxy_n]\n",
    "            image = Image.open(galaxy['file_loc'])\n",
    "            ax = plt.subplot(gs1[row_n, col_n])\n",
    "            ax.imshow(image)\n",
    "#             ax.text(10, 20, 'Smooth = {:.2f}'.format(galaxy['smooth-or-featured_smooth_fraction']), fontsize=12, color='r')\n",
    "#             ax.text(10, 50, r'$\\rho = {:.2f}$, Var ${:.3f}$'.format(galaxy['median_prediction'], 3*galaxy['predictions_var']), fontsize=12, color='r')\n",
    "#             ax.text(10, 80, '$L = {:.2f}$'.format(galaxy['bcnn_likelihood']), fontsize=12, color='r')\n",
    "            ax.axis('off')\n",
    "            galaxy_n += 1\n",
    "#     print('Mean L: {:.2f}'.format(df[:nrows * ncols]['bcnn_likelihood'].mean()))\n",
    "    fig = plt.gcf()\n",
    "#     fig.tight_layout()\n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def save_top_n(df, schema, save_dir):\n",
    "    for question in schema.questions:\n",
    "        for answer in question.answers:\n",
    "            fig = show_galaxies(df.sort_values(answer.text + '_prediction_mean', ascending=False)[:36])\n",
    "            fig.savefig(save_dir + '_' + answer.text + '.png')\n",
    "            plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = 'results/temp'\n",
    "save_top_n(df, schema, save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False  # moove later analysis elsewhere?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots()\n",
    "# ax.scatter(predictions[:, 0], labels[:, 0] / labels[:, :2].sum(axis=1))\n",
    "# plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.get_backend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots()\n",
    "# ax.scatter(predictions[:, 4], labels[:, 4] / labels[:, 4:7].sum(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots()\n",
    "# ax.scatter(predictions[:, 5], labels[:, 5] / labels[:, 4:7].sum(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots()\n",
    "# ax.scatter(predictions[:, 6], labels[:, 6] / labels[:, 4:7].sum(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to check that the right models have been loaded - should be around 40 for smooth, 0-40 for bars\n",
    "# plt.hist(sim_model.total_votes), sim_model.total_votes.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def galaxy_posterior_grid(df, schema):\n",
    "    \n",
    "    sns.set_context('paper', font_scale=1.5)\n",
    "    \n",
    "    scale = 1.5\n",
    "    \n",
    "    im_width = 2\n",
    "    posterior_width = 3\n",
    "    height = im_width\n",
    "    \n",
    "    n_galaxies = len(df)\n",
    "    n_posteriors = len(schema.answers)\n",
    "    \n",
    "    fig = plt.figure(figsize=(scale * (im_width + posterior_width*n_posteriors), (scale * n_galaxies * height)))  # width, height format\n",
    "    gs = gridspec.GridSpec(len(df) * height, im_width + posterior_width * len(schema.answers))  # y, x format\n",
    "    image_axes = []\n",
    "    posterior_axes = []  # (galaxy i.e. row, answer) shape\n",
    "    \n",
    "    # create the grid\n",
    "    for galaxy_n in range(len(df)):\n",
    "        y_slice = slice(galaxy_n*height, (galaxy_n+1)*height)\n",
    "        image_axes.append(plt.subplot(gs[y_slice, :im_width]))\n",
    "        \n",
    "        temp_galaxy_axes = []\n",
    "        for answer_n, answer in enumerate(schema.answers):\n",
    "            x_slice = slice(im_width+answer_n*posterior_width, im_width+(answer_n+1)*posterior_width)\n",
    "            temp_galaxy_axes.append(plt.subplot(gs[y_slice, x_slice]))\n",
    "        posterior_axes.append(temp_galaxy_axes)\n",
    "        \n",
    "    \n",
    "    # fill the images\n",
    "    for ax_n, ax in enumerate(image_axes):\n",
    "        plot_galaxy(df['file_loc'][ax_n], ax)\n",
    "    \n",
    "    # fill the posteriors\n",
    "    for answer_n, answer in enumerate(schema.answers):\n",
    "        samples, labels, total_votes = get_single_answer_data(df, answer)\n",
    "        galaxy_axes = [axes[answer_n] for axes in posterior_axes]\n",
    "        make_predictions.plot_samples(samples, labels, total_votes, fig, galaxy_axes, alpha=0.06)\n",
    "    \n",
    "    # fix x limits for comparison\n",
    "    for row_n, axes in enumerate(posterior_axes):\n",
    "        for answer_n, ax in enumerate(axes):\n",
    "            ax.set_xlim([0, 50])\n",
    "            if row_n == 0:\n",
    "                ax.set_title(schema.answers[answer_n].text)\n",
    "        \n",
    "#     for n in range(len(labels)):\n",
    "#         multiple_axes[n].set_ylabel(r'$p(k|N, D)$', visible=True)\n",
    "#         multiple_axes[n].yaxis.set_visible(True)\n",
    "#         single_axes[n].set_ylabel(r'$p(k|N, w)$', visible=True)\n",
    "#         single_axes[n].yaxis.set_visible(True)\n",
    "#         single_axes[n].yaxis.set_major_locator(plt.NullLocator())\n",
    "#         multiple_axes[n].yaxis.set_major_locator(plt.NullLocator())\n",
    "#         if n < len(labels) - 1:\n",
    "#             single_axes[n].xaxis.set_major_locator(plt.NullLocator())\n",
    "#             multiple_axes[n].xaxis.set_major_locator(plt.NullLocator())\n",
    "    \n",
    "# #     if QUESTION == 'bars':\n",
    "# #         question = 'Bar'\n",
    "# #     else:\n",
    "# #         question = 'Smooth'\n",
    "# #     single_axes[-1].set_xlabel(r\"$k$ '{}' votes, of $N$ total\".format(question))\n",
    "# #     multiple_axes[-1].set_xlabel(r\"$k$ '{}' votes, of $N$ total\".format(question))\n",
    "#     fig.tight_layout()\n",
    "\n",
    "    \n",
    "#     multiple_axes[0].legend(\n",
    "#         loc='lower center', \n",
    "#         bbox_to_anchor=(0.5, 1.1),\n",
    "#         ncol=1, \n",
    "#         fancybox=True, \n",
    "#         shadow=False\n",
    "#     )\n",
    "\n",
    "    fig.tight_layout()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = galaxy_posterior_grid(df[:5], schema)\n",
    "fig.savefig(save_dir + '/grid.pdf')\n",
    "fig.savefig(save_dir + '/grid.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def custom_samples_with_galaxies(samples, labels, total_votes, png_locs):\n",
    "    \n",
    "    sns.set_context('paper', font_scale=1.5)\n",
    "    \n",
    "    im_width = 2\n",
    "    single_width = 3\n",
    "    multiple_width = 3\n",
    "    height = im_width\n",
    "    \n",
    "    fig = plt.figure(figsize=(0.8 * len(labels) * height * 2., 0.8 * (im_width + single_width + multiple_width) * 1.75))\n",
    "    gs = gridspec.GridSpec(len(labels) * height, im_width + single_width + multiple_width)  # y, x format\n",
    "    image_axes = []\n",
    "    single_axes = []\n",
    "    multiple_axes = []\n",
    "    for galaxy_n in range(len(labels)):\n",
    "        x_slice = slice(galaxy_n*height, (galaxy_n+1)*height)\n",
    "        image_axes.append(plt.subplot(gs[x_slice, :im_width]))\n",
    "        single_axes.append(plt.subplot(gs[x_slice, im_width:im_width+single_width]))\n",
    "        multiple_axes.append(plt.subplot(gs[x_slice, im_width+single_width:]))\n",
    "    \n",
    "\n",
    "#     fig, axes = plt.subplots(nrows=len(labels), figsize=(3, len(labels)*1.5), sharex=True)\n",
    "    make_predictions.plot_samples(samples[:, :1], labels, total_votes, fig, single_axes, alpha=0.06)\n",
    "    for ax in single_axes:\n",
    "        ax.set_xlim([0, 50])\n",
    "\n",
    "    make_predictions.plot_samples(samples, labels, total_votes, fig, multiple_axes, alpha=0.06)\n",
    "    for ax in multiple_axes:\n",
    "        ax.set_xlim([0, 50])\n",
    "        \n",
    "        \n",
    "    for ax_n, ax in enumerate(image_axes):\n",
    "        plot_galaxy(png_locs[ax_n], ax)\n",
    "        \n",
    "    \n",
    "    for n in range(len(labels)):\n",
    "        multiple_axes[n].set_ylabel(r'$p(k|N, D)$', visible=True)\n",
    "        multiple_axes[n].yaxis.set_visible(True)\n",
    "        single_axes[n].set_ylabel(r'$p(k|N, w)$', visible=True)\n",
    "        single_axes[n].yaxis.set_visible(True)\n",
    "        single_axes[n].yaxis.set_major_locator(plt.NullLocator())\n",
    "        multiple_axes[n].yaxis.set_major_locator(plt.NullLocator())\n",
    "        if n < len(labels) - 1:\n",
    "            single_axes[n].xaxis.set_major_locator(plt.NullLocator())\n",
    "            multiple_axes[n].xaxis.set_major_locator(plt.NullLocator())\n",
    "    \n",
    "#     if QUESTION == 'bars':\n",
    "#         question = 'Bar'\n",
    "#     else:\n",
    "#         question = 'Smooth'\n",
    "#     single_axes[-1].set_xlabel(r\"$k$ '{}' votes, of $N$ total\".format(question))\n",
    "#     multiple_axes[-1].set_xlabel(r\"$k$ '{}' votes, of $N$ total\".format(question))\n",
    "    fig.tight_layout()\n",
    "\n",
    "    single_axes[0].legend(\n",
    "        loc='lower center', \n",
    "        bbox_to_anchor=(0.5, 1.1),\n",
    "        ncol=1, \n",
    "        fancybox=True, \n",
    "        shadow=False\n",
    "    )\n",
    "    \n",
    "    multiple_axes[0].legend(\n",
    "        loc='lower center', \n",
    "        bbox_to_anchor=(0.5, 1.1),\n",
    "        ncol=1, \n",
    "        fancybox=True, \n",
    "        shadow=False\n",
    "    )\n",
    "\n",
    "    \n",
    "    fig.tight_layout()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_galaxy(image_loc, ax, n_examples=10, crop=0):\n",
    "    im_size = 424\n",
    "    im = Image.open(image_loc)\n",
    "#     if QUESTION == 'bars':\n",
    "#         crop = 120\n",
    "#     else:\n",
    "    crop = 35\n",
    "    cropped_im = im.crop((crop, crop, 424 - crop, 424 - crop))\n",
    "    ax.imshow(cropped_im)\n",
    "    ax.grid(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    ax.get_xaxis().set_visible(False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = 'has-spiral-arms'\n",
    "answer = 'yes'\n",
    "n = 5\n",
    "samples, labels, total_votes = get_single_answer_data(question, answer)\n",
    "png_locs = df['file_loc'][:n]\n",
    "\n",
    "# catalog = sim_model.catalog[selected_slice]\n",
    "\n",
    "_ = custom_samples_with_galaxies(samples, labels, total_votes, png_locs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, axes = plt.subplots(1, 10, figsize=(20, 12))\n",
    "# for ax_n, ax in enumerate(axes):\n",
    "#     plot_galaxy(sim_model.catalog.iloc[ax_n]['png_loc'], ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected = slice(80, 73, -1)  #smooth\n",
    "\n",
    "# selected = slice(0, 7)\n",
    "\n",
    "if QUESTION == 'bars':\n",
    "    selected = slice(0, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.array(sim_model.model.samples)[selected, :]\n",
    "# np.array(sim_model.labels)[selected]\n",
    "# sim_model.catalog['smooth-or-featured_total-votes'][selected]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = custom_samples_with_galaxies(sim_model, selected)\n",
    "# fig.savefig(os.path.join(save_dir, 'mc_model_{}.png'.format(len(np.array(sim_model.labels)[selected]))))\n",
    "# fig.savefig(os.path.join(save_dir, 'mc_model_{}.pdf'.format(len(np.array(sim_model.labels)[selected]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# be sure to switch label in custom_samples before running this\n",
    "# fig = custom_samples(np.array(single_sim_model.model.samples)[selected, :1], np.array(single_sim_model.labels)[selected], total_votes=single_sim_model.total_votes)\n",
    "# fig.savefig(os.path.join(save_dir, 'single_model_{}.png'.format(len(np.array(sim_model.labels)[selected]))))\n",
    "# fig.savefig(os.path.join(save_dir, 'single_model_{}.eps'.format(len(np.array(sim_model.labels)[selected]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(font_scale=1.2)\n",
    "sns.set_style('white')\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ungrouped_coverage_df = discrete_coverage.evaluate_discrete_coverage(\n",
    "    sim_model.labels, \n",
    "    sim_model.bin_probs)\n",
    "coverage_df = ungrouped_coverage_df.groupby('max_state_error').agg({'prediction': 'sum', 'observed': 'sum'}).reset_index()\n",
    "\n",
    "ungrouped_single_coverage_df = discrete_coverage.evaluate_discrete_coverage(\n",
    "    single_sim_model.labels, \n",
    "    single_sim_model.bin_probs)\n",
    "single_coverage_df = ungrouped_single_coverage_df.groupby('max_state_error').agg({'prediction': 'sum', 'observed': 'sum'}).reset_index()\n",
    "\n",
    "\n",
    "plt.plot(coverage_df['max_state_error'], coverage_df['prediction'], label='MC Model Expects')\n",
    "plt.plot(single_coverage_df['max_state_error'], single_coverage_df['prediction'], label='Single Model Expects')\n",
    "plt.plot(single_coverage_df['max_state_error'], coverage_df['observed'], 'k--', label='Actual')\n",
    "\n",
    "ax.set_xlabel('Max Allowed Vote Error')\n",
    "ax.set_ylabel('Galaxies Within Max Error')\n",
    "ax.legend()\n",
    "ax.xaxis.set_major_formatter(StrMethodFormatter('{x:.0f}'))  # must expect 'x' kw arg\n",
    "\n",
    "ax.set_xlim([0, 15])\n",
    "fig.tight_layout()\n",
    "fig.savefig(os.path.join(save_dir, 'coverage_comparison_200_samples.png'))\n",
    "fig.savefig(os.path.join(save_dir, 'coverage_comparison_200_samples.pdf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ungrouped_coverage_df.to_csv(os.path.join(save_dir, QUESTION + '_ungrouped_coverage_df.csv'), index=False)\n",
    "ungrouped_single_coverage_df.to_csv(os.path.join(save_dir, QUESTION + '_ungrouped_coverage_df.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coverage_df['error'] = coverage_df['prediction'] - coverage_df['observed']\n",
    "coverage_df['relative_error'] = coverage_df['error'] / coverage_df['observed']\n",
    "coverage_df.to_csv(os.path.join(save_dir, QUESTION + '_coverage_df.csv'), index=False)\n",
    "coverage_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_coverage_df['error'] = single_coverage_df['prediction'] - single_coverage_df['observed']\n",
    "single_coverage_df['relative_error'] = single_coverage_df['error'] / single_coverage_df['observed']\n",
    "single_coverage_df.to_csv(os.path.join(save_dir, QUESTION + '_single_coverage_df.csv'), index=False)\n",
    "single_coverage_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO - I might consider adding an MSE model as a comparison, to hopefully beat. I think this might be quite similar though. Ideally I can compare this with previous work somehow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(font_scale=1.2)\n",
    "sns.set_style('white')\n",
    "fig, ax = plt.subplots()\n",
    "ax.hist(sim_model.abs_rho_error, bins=25)\n",
    "# ax.axvline(sim_model.mean_abs_rho_error, color='r') \n",
    "ax.set_xlim([0, 1.])\n",
    "ax.set_ylabel('Galaxies')\n",
    "ax.set_xlabel(r'| Expected $\\hat{\\rho}$ - observed vote fraction $\\frac{k}{N}$ |')\n",
    "fig.tight_layout()\n",
    "fig.savefig(os.path.join(save_dir, 'difference_in_rho.png'))\n",
    "fig.savefig(os.path.join(save_dir, 'difference_in_rho.pdf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_model.abs_rho_error.mean(), single_sim_model.abs_rho_error.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(sim_model.mean_abs_rho_error), np.sqrt(single_sim_model.mean_abs_rho_error)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(sim_model.mean_square_rho_error), np.sqrt(single_sim_model.mean_square_rho_error) # this is the rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alpha = 0.3\n",
    "# n_bins = 25\n",
    "\n",
    "# # dummy for bins\n",
    "# fig, ax = plt.subplots()\n",
    "# _, bins, _  = ax.hist(sim_model.labels / sim_model.total_votes, bins=n_bins, alpha=alpha, label=r'Observed $\\rho$')\n",
    "# ax.hist(sim_model.mean_rho_prediction, bins=n_bins, alpha=alpha, label=r'Mean Rho Prediction $\\hat{\\rho}}$')\n",
    "# # ax.hist(single_sim_model.mean_rho_prediction, bins=bins, alpha=alpha, label=r'Single Rho Prediction $\\hat{\\rho}}$')\n",
    "\n",
    "# fig, ax = plt.subplots()\n",
    "# sns.set(font_scale=1.)\n",
    "# sns.set_style('white')\n",
    "\n",
    "# ax.hist(sim_model.mean_rho_prediction, bins=bins, alpha=alpha, label=r'Mean Rho Prediction $\\hat{\\rho}}$')\n",
    "# # ax.hist(single_sim_model.mean_rho_prediction, bins=bins, alpha=alpha, label=r'Single Rho Prediction $\\hat{\\rho}}$')\n",
    "# ax.hist(sim_model.labels / sim_model.total_votes, bins=bins, alpha=alpha, label=r'Observed $\\rho$')\n",
    "# ax.legend()\n",
    "# ax.set_xlim([0., 1.])\n",
    "# ax.set_ylabel('Galaxies')\n",
    "# ax.set_xlabel(r'Typical vote fraction $\\rho$')\n",
    "# fig.tight_layout()\n",
    "# fig.savefig(os.path.join(save_dir, 'typical_vote_fraction_distribution.png'))\n",
    "\n",
    "# This is a repeat of the above histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(sim_model.mean_rho_prediction > 0.5), np.sum(single_sim_model.mean_rho_prediction > 0.5), np.sum((sim_model.labels / sim_model.total_votes) > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(sim_model.labels / sim_model.total_votes).min(), (sim_model.labels / sim_model.total_votes).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_model.mean_rho_prediction.min(), sim_model.mean_rho_prediction.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_sim_model.mean_rho_prediction.min(), single_sim_model.mean_rho_prediction.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_model.total_votes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save DataFrame of predictions + catalog (GZ2) for use elsewhere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_df = pd.DataFrame(data={\n",
    "    'total_votes': sim_model.total_votes, \n",
    "    'k': sim_model.labels, \n",
    "    'vote_fraction': (sim_model.labels / sim_model.total_votes), \n",
    "    'rho_prediction': sim_model.mean_rho_prediction\n",
    "#     'png_loc': sim_model.catalog.png_loc\n",
    "})\n",
    "safe_catalog_cols = list(set(sim_model.catalog.columns.values) - set(['total_votes', 'ra_subject', 'dec_subject']))\n",
    "df = pd.concat([response_df, sim_model.catalog[safe_catalog_cols]], axis=1)\n",
    "df['smooth'] = df['vote_fraction'] > 0.5\n",
    "df['confidence_proxy'] = np.abs(0.5 - df['rho_prediction'])\n",
    "df['rho_predictions'] = 0\n",
    "for n in range(len(df)):\n",
    "    df['rho_predictions'][n] = json.dumps(list(sim_model.model.samples[n, :]))\n",
    "    df = df.sort_values('confidence_proxy', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['rho_predictions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_parquet('/data/repos/zoobot/notebooks/{}_test_predictions_and_gz2_catalog.parquet'.format(QUESTION))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replicate (ish) Sanchez 2017 ROC Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix((sim_model.labels / sim_model.total_votes) > 0.5, sim_model.mean_rho_prediction > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " 1 - ((66 + 99) / (490 + 1845 + 66 + 99))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " 1 - ((189 + 81) / (1858 + 189 + 81 + 372))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "sns.set(font_scale=1.2)\n",
    "sns.set_style('white')\n",
    "\n",
    "fpr, tpr, _ = roc_curve(df['smooth'], df['rho_prediction'])\n",
    "ax.plot(fpr, tpr, label='All')\n",
    "df_low_entropy = df[df['confidence_proxy'] > 0.3]\n",
    "fpr, tpr, _ = roc_curve(df_low_entropy['smooth'], df_low_entropy['rho_prediction'])\n",
    "ax.plot(fpr, tpr, label=r'\"High Confidence\" i.e. $\\hat{\\rho} < 0.2$ or $\\hat{\\rho} > 0.8$')\n",
    "ax.set_xlabel('False Positive Rate')\n",
    "ax.set_ylabel('True Positive Rate')\n",
    "ax.legend()\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(os.path.join(save_dir, 'roc_curve.png'))\n",
    "fig.savefig(os.path.join(save_dir, 'roc_curve.pdf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df), len(df_low_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replicate(ish) Khan 2018 Confusion Matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> After selecting the OBJIDs from Table 2 based on the probability thresholds of 0.985 and 0.926 for spirals and ellipticals respectively,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdf_array = binom.cdf((df['total_votes'] / 2.).astype(int), df['total_votes'], df['rho_prediction'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df['total_votes'] / 2.).astype(int).sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['total_votes'].sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['rho_prediction'].sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(cdf_array, bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binom.cdf(20, 40, 0.88)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(1 - cdf_array > 0.985)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(cdf_array > 0.926)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_prob_df = df[(cdf_array < (1 - 0.985)) | (cdf_array > 0.926)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(high_prob_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if QUESTION == 'smooth':\n",
    "    spiral_pc_to_keep = 516 / 6677\n",
    "    n_spirals = int(len(df) * spiral_pc_to_keep)\n",
    "    elliptical_pc_to_keep = 550 / 5904\n",
    "    n_ellipticals = int(len(df) * elliptical_pc_to_keep)\n",
    "    print(spiral_pc_to_keep, n_spirals, elliptical_pc_to_keep, n_ellipticals)\n",
    "    high_prob_df = pd.concat([\n",
    "        df.sort_values('rho_prediction')[:n_spirals],\n",
    "        df.sort_values('rho_prediction', ascending=False)[:n_ellipticals]\n",
    "    ])\n",
    "if QUESTION == 'bars':\n",
    "    n_to_keep = int(len(df) * 0.08)\n",
    "    high_prob_df = pd.concat([\n",
    "        df.sort_values('rho_prediction')[:int(n_to_keep/2)],\n",
    "        df.sort_values('rho_prediction', ascending=False)[:int(n_to_keep/2)]\n",
    "    ])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_prob_df.sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(high_prob_df['vote_fraction'] >= 0.5, high_prob_df['rho_prediction'] >= 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error = high_prob_df[~(high_prob_df['vote_fraction'] > 0.5) & (high_prob_df['rho_prediction'] > 0.5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error['vote_fraction'] > 0.5, error['rho_prediction'] > 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open(error.iloc[0]['png_loc'])\n",
    "plt.imshow(img)\n",
    "fontdict = {'size': 16, 'color': 'white'}\n",
    "plt.text(30, 360, r'Expected vote frac $\\hat{\\rho}$: 0.80', fontdict=fontdict)\n",
    "plt.text(30, 400, r'Observed vote frac $\\frac{k}{N}$: 0.50', fontdict=fontdict)\n",
    "plt.axis('off')\n",
    "plt.savefig(os.path.join(save_dir, 'high_prob_error_0.png'))\n",
    "plt.savefig(os.path.join(save_dir, 'high_prob_error_0.eps'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img = Image.open(error.iloc[1]['png_loc'])\n",
    "# plt.imshow(img)\n",
    "# fontdict = {'size': 16, 'color': 'white'}\n",
    "# plt.text(30, 360, r'Expected vote frac $\\hat{\\rho}$: 0.13', fontdict=fontdict)\n",
    "# plt.text(30, 400, r'Observed vote frac $\\frac{k}{N}$: 0.54', fontdict=fontdict)\n",
    "# plt.axis('off')\n",
    "# plt.savefig(os.path.join(save_dir, 'high_prob_error_1.png'))\n",
    "# plt.savefig(os.path.join(save_dir, 'high_prob_error_1.eps'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(df['vote_fraction'][:int(len(df) / 2)] > 0.5, df['rho_prediction'][:int(len(df) / 2)] > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if QUESTION == 'smooth':\n",
    "    labels = ['Smooth', 'Featured']\n",
    "    \n",
    "#     cm = np.array([[ 232,    2], [   0, 191]])\n",
    "#     name = 'confusion_matrix_high_confidence'\n",
    "    \n",
    "    cm = np.array([[ 490,   66],\n",
    "       [  99, 1845]])\n",
    "    name = 'confusion_matrix'\n",
    "    \n",
    "if QUESTION == 'bars':\n",
    "    labels = ['No Bar', 'Bar']\n",
    "    cm = np.array([[100,    0], [   0,   100]])\n",
    "    name = 'confusion_matrix_high_confidence'\n",
    "    \n",
    "#     cm = np.array([[1858,    81], [   189,   372]])\n",
    "#     name = 'confusion_matrix'\n",
    "\n",
    "sns.set(font_scale=3.)\n",
    "sns.set_style('white')\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "ax = sns.heatmap(cm, annot=True, fmt='d', cmap=\"Blues\", xticklabels=labels, yticklabels=labels, cbar=False, square=True, ax=ax)\n",
    "ax.set_xlabel('Predicted')\n",
    "ax.set_ylabel('Observed')\n",
    "fig.tight_layout()\n",
    "fig.savefig(os.path.join(save_dir, '{}.png'.format(name)))\n",
    "fig.savefig(os.path.join(save_dir, '{}.pdf'.format(name)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1 - (8 / (1159 + 83 + 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sim_model.export_performance_metrics(save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw a galaxy, infer a range of p, redraw, and measure accuracy - work in progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot other standard acquisition visualisations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_acquisition_viz = False\n",
    "if new_acquisition_viz:\n",
    "    image_locs = sim_model.catalog['png_loc']\n",
    "    images = np.stack([np.array(Image.open(loc)) for loc in image_locs])\n",
    "    assert images.shape == (2500, 424, 424, 3)\n",
    "    acquisition_utils.save_acquisition_examples(images, sim_model.mutual_info, 'mutual_info', save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, row = plt.subplots(ncols=3, figsize=(12, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# row = sim_model.acquisition_vs_volunteer_votes(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualise Selection of Catalog Features w.r.t. Acquisition Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(constrained_layout=True, figsize=(20, 12))\n",
    "gs = gridspec.GridSpec(6, 5, figure=fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Smooth Votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax0 = plt.subplot(gs[:4, :])\n",
    "sns.scatterplot(\n",
    "    np.array(sim_model.catalog['smooth-or-featured_smooth_fraction'] * 40).astype(int),\n",
    "    sim_model.model.acquisitions, hue=np.array(sim_model.model.acquisitions) > np.array(sim_model.model.acquisitions[103]),\n",
    "    ax=ax0)\n",
    "ax0.set_ylabel('Mutual Information')\n",
    "ax0.set_xlabel('Smooth Votes')\n",
    "ax0.legend([r'Top 10% $\\mathcal{I}$', r'Bottom 90% $\\mathcal{I}$'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax1 = plt.subplot(gs[4:, :])\n",
    "ax1.hist(np.array(sim_model.labels * 40).astype(int), density=True, alpha=0.4)\n",
    "ax1.hist(np.array(sim_model.labels * 40).astype(int)[:200], density=True, alpha=0.4)\n",
    "ax1.set_ylabel('Frequency')\n",
    "ax1.set_xlabel('Smooth Votes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.savefig(os.path.join(save_dir, 'temp.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Redshift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "sns.jointplot(np.array(sim_model.labels * 40).astype(int), sim_model.catalog['redshift'], kind='kde')\n",
    "ax0.set_ylabel('Redshift')\n",
    "ax0.set_xlabel('Volunteer Votes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax0 = plt.subplot(gs[:2, :])\n",
    "sns.jointplot(np.array(sim_model.labels * 40).astype(int), sim_model.catalog['redshift'], kind='kde', ax=ax0)\n",
    "ax0.set_ylabel('Redshift')\n",
    "ax0.set_xlabel('Volunteer Votes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax0 = plt.subplot(gs[:2, :])\n",
    "sns.jointplot(sim_model.catalog['redshift'], sim_model.model.acquisitions, ax=ax0)\n",
    "ax0.set_ylabel('Mutual Information')\n",
    "ax0.set_xlabel('Redshift')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax1 = plt.subplot(gs[4:, :])\n",
    "\n",
    "ax1.hist(sim_model.catalog['redshift'], density=True, alpha=0.4)\n",
    "# ax1.hist(sim_model.catalog['redshift'], density=True, alpha=0.4)\n",
    "ax1.set_ylabel('Frequency')\n",
    "ax1.set_xlabel('Smooth Votes')\n",
    "# TODO sort by mutual information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Below here is only relevant for DECALS, with extra questions. TODO update with GZ2 merger options?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merger_strs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merger_label = 'merging_major-disturbance'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax0 = plt.subplot(gs[:2, :])\n",
    "sns.scatterplot(sim_model.catalog[merger_label], sim_model.model.mutual_info, ax=ax0)\n",
    "ax0.set_ylabel('Mutual Information')\n",
    "ax0.set_xlabel(merger_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.hist(sim_model.catalog[merger_label], bins=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featured_no_merger = sim_model.model.mutual_info[(sim_model.catalog[merger_label] == 0) & (sim_model.catalog['smooth-or-featured_smooth_fraction'] < 0.4)]\n",
    "featured_merger = sim_model.model.mutual_info[(sim_model.catalog[merger_label] > 0) & (sim_model.catalog['smooth-or-featured_smooth_fraction'] < 0.4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featured_no_merger.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featured_merger.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax.hist(featured_no_merger, alpha=0.3, density=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax.hist(featured_merger, alpha=0.3, density=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.scatterplot(\n",
    "    sim_model.catalog['smooth-or-featured_artifact'], \n",
    "    sim_model.model.mutual_info, \n",
    "    hue=sim_model.model.mutual_info > sim_model.model.mutual_info[103])\n",
    "ax.set_xlim([0, 14.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(\n",
    "    sim_model.catalog['smooth-or-featured_artifact'], \n",
    "    sim_model.model.mutual_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax.hist(\n",
    "    sim_model.catalog['smooth-or-featured_artifact'][sim_model.model.mutual_info > sim_model.model.mutual_info[100]],\n",
    "    density=True,\n",
    "    alpha=0.4,\n",
    ")\n",
    "ax.hist(\n",
    "    sim_model.catalog['smooth-or-featured_artifact'][sim_model.model.mutual_info < sim_model.model.mutual_info[100]],\n",
    "    density=True,\n",
    "    alpha=0.4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "has-spiral-arms_yes\n",
    "spiral-winding_prediction-encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(\n",
    "    sim_model.catalog['has-spiral-arms_yes'][sim_model.catalog['smooth-or-featured_smooth_fraction'] < 0.5], \n",
    "    sim_model.model.mutual_info[sim_model.catalog['smooth-or-featured_smooth_fraction'] < 0.5], \n",
    "    hue=sim_model.model.mutual_info > sim_model.model.mutual_info[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.hist(\n",
    "    sim_model.catalog['has-spiral-arms_yes'][sim_model.model.mutual_info > sim_model.model.mutual_info[100]],\n",
    "    density=True,\n",
    "    alpha=0.4,\n",
    ")\n",
    "ax.hist(\n",
    "    sim_model.catalog['has-spiral-arms_yes'][sim_model.model.mutual_info < sim_model.model.mutual_info[100]],\n",
    "    density=True,\n",
    "    alpha=0.4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.hist(\n",
    "    sim_model.catalog['redshift'][sim_model.model.mutual_info > sim_model.model.mutual_info[100]],\n",
    "    density=True,\n",
    "    alpha=0.4,\n",
    ")\n",
    "ax.hist(\n",
    "    sim_model.catalog['redshift'][sim_model.model.mutual_info < sim_model.model.mutual_info[100]],\n",
    "    density=True,\n",
    "    alpha=0.4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.hist(\n",
    "    sim_model.catalog['merging_major-disturbance'][sim_model.model.mutual_info > sim_model.model.mutual_info[100]],\n",
    "    density=True,\n",
    "    alpha=0.4,\n",
    ")\n",
    "ax.hist(\n",
    "    sim_model.catalog['merging_major-disturbance'][sim_model.model.mutual_info < sim_model.model.mutual_info[100]],\n",
    "    density=True,\n",
    "    alpha=0.4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for merger_label in merger_strs:\n",
    "    print('\\n' + merger_label)\n",
    "    print(sim_model.model.mutual_info[sim_model.catalog[merger_label] > 1].mean())\n",
    "    print(sim_model.model.mutual_info[sim_model.catalog[merger_label] == 1].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "    {'Volunteer Response': 'Merging', 'Mean Mutual Information': sim_model.model.mutual_info[sim_model.catalog['merging_both-v1'] > 1].mean()},\n",
    "    {'Volunteer Response': 'Major Disturbance', 'Mean Mutual Information': sim_model.model.mutual_info[sim_model.catalog['merging_major-disturbance'] > 1].mean()},\n",
    "    {'Volunteer Response': 'Minor Disturbance', 'Mean Mutual Information': sim_model.model.mutual_info[sim_model.catalog['merging_minor-disturbance'] > 1].mean()},\n",
    "    {'Volunteer Response': 'No Disturbance', 'Mean Mutual Information': sim_model.model.mutual_info[sim_model.catalog['merging_none'] > 20].mean()}\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax = sns.barplot(data=df, y='Volunteer Response', x='Mean Mutual Information', ax=ax)\n",
    "ax.set_xlim([0.2, 0.36])\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sim_model.model.mutual_info[(sim_model.catalog['merging_minor-disturbance'] + sim_model.catalog['merging_major-disturbance']) > 0].mean())\n",
    "print(sim_model.model.mutual_info[(sim_model.catalog['merging_minor-disturbance'] + sim_model.catalog['merging_major-disturbance']) == 0].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(sim_model.catalog['merging_tidal-debris-v1'], bins=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('zoobot': conda)",
   "language": "python",
   "name": "python37664bitzoobotcondad3adbdfef5c444648572db3b6ec7c1e0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
