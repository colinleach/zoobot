{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/walml/repos/zoobot/notebooks/multiq\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already up-to-date.\n"
     ]
    }
   ],
   "source": [
    "!git pull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import argparse\n",
    "import glob\n",
    "import json\n",
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib.ticker import StrMethodFormatter\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import seaborn as sns\n",
    "from sklearn import metrics\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from astropy.table import Table  # for NSA\n",
    "from astropy import units as u\n",
    "from sklearn.metrics import confusion_matrix, roc_curve\n",
    "from PIL import Image\n",
    "from scipy.stats import binom\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error, mean_absolute_error\n",
    "\n",
    "from shared_astro_utils import astropy_utils, matching_utils\n",
    "from zoobot.estimators import make_predictions, bayesian_estimator_funcs\n",
    "from zoobot.tfrecord import read_tfrecord\n",
    "from zoobot.uncertainty import discrete_coverage\n",
    "from zoobot.estimators import input_utils, losses\n",
    "from zoobot.tfrecord import catalog_to_tfrecord\n",
    "from zoobot.active_learning import metrics, simulated_metrics, acquisition_utils, check_uncertainty, simulation_timeline, run_estimator_config\n",
    "from zoobot import label_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    for gpu in gpus:\n",
    "        tf.config.experimental.set_memory_growth(gpu, True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/home/walml/repos/zoobot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start = 50\n",
    "# end = 60\n",
    "# start = 0\n",
    "# end=5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the (latest) model under `model_name` folder in `results_dir`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# catalog_loc = 'data/latest_labelled_catalog.csv\n",
    "catalog_loc = 'data/decals/decals_master_catalog.csv'\n",
    "# catalog_loc = 'data/gz2/gz2_master_catalog.csv'\n",
    "\n",
    "catalog = pd.read_csv(catalog_loc, dtype={'subject_id': str})  # original catalog\n",
    "\n",
    "catalog['file_loc'] = catalog['local_png_loc'].apply(lambda x: '/media/walml/beta/decals/png_native' + x[32:])\n",
    "catalog['file_loc'] = catalog['local_png_loc'].apply(lambda x: '/media/walml/beta/decals/png_native' + x[32:])\n",
    "\n",
    "\n",
    "# catalog_loc = 'data/decals/temp_calibration_catalog.csv'\n",
    "# catalog = pd.read_csv(catalog_loc, dtype={'subject_id': str})  # original catalog\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Loading multiple tfrecords with interleaving, shuffle=False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{smooth-or-featured, indices 0 to 2, asked after None: (0, 2), disk-edge-on, indices 3 to 4, asked after smooth-or-featured_featured-or-disk, index 1: (3, 4), has-spiral-arms, indices 5 to 6, asked after disk-edge-on_no, index 4: (5, 6), bar, indices 7 to 9, asked after disk-edge-on_no, index 4: (7, 9), bulge-size, indices 10 to 14, asked after disk-edge-on_no, index 4: (10, 14), how-rounded, indices 15 to 17, asked after smooth-or-featured_smooth, index 0: (15, 17), edge-on-bulge, indices 18 to 20, asked after disk-edge-on_yes, index 3: (18, 20), spiral-winding, indices 21 to 23, asked after has-spiral-arms_yes, index 5: (21, 23), spiral-arm-count, indices 24 to 29, asked after has-spiral-arms_yes, index 5: (24, 29), merging, indices 30 to 33, asked after None: (30, 33)}\n",
      "['/home/walml/repos/zoobot/results/temp/decals_n2_allq_m0_eval_shards/s300_shard_2.tfrecord', '/home/walml/repos/zoobot/results/temp/decals_n2_allq_m0_eval_shards/s300_shard_1.tfrecord', '/home/walml/repos/zoobot/results/temp/decals_n2_allq_m0_eval_shards/s300_shard_0.tfrecord']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Loading multiple tfrecords with interleaving, shuffle=False\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['J101523.33+031030.9',\n",
       " 'J112413.94+245257.5',\n",
       " 'J160105.65-004226.9',\n",
       " 'J112748.26+264900.1',\n",
       " 'J155214.79+164831.8']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Figures will be saved to here\n",
    "\n",
    "analysis_dir = 'analysis/multiquestion'\n",
    "# save_dir = f'{analysis_dir}/{model_name}'\n",
    "# if not os.path.exists(save_dir):\n",
    "#     os.mkdir(save_dir)\n",
    "\n",
    "# results_dir = '/home/walml/repos/zoobot/data/experiments/live/no_cutouts/iteration_0'\n",
    "# results_dir = '/home/walml/repos/zoobot/results/smooth_or_featured_offline'\n",
    "# results_dir = '/home/walml/repos/zoobot/results/debug'\n",
    "# results_dir = '/home/walml/repos/zoobot/results/latest/effnetB0_decals_mf_244px_256init_10k'\n",
    "# results_dir = '/home/walml/repos/zoobot/results/latest/latest_offline_full'\n",
    "\n",
    "# two identical models, trained at different times\n",
    "# results_dir = '/home/walml/repos/zoobot/results/latest/latest_offline_10k_x2val_b256'\n",
    "# results_dir = '/home/walml/repos/zoobot/results/latest/latest_offline_10k_x2val'\n",
    "\n",
    "# results_dir = '/home/walml/repos/zoobot/results/latest/latest_dirichlet_c100_active_n3_layers'\n",
    "# results_dir = '/home/walml/repos/zoobot/results/all_featp5_facep5_sim_256_arc_final_0'\n",
    "\n",
    "\n",
    "\n",
    "# decals cols\n",
    "questions = label_metadata.decals_questions\n",
    "version = 'decals'\n",
    "label_cols = label_metadata.decals_label_cols\n",
    "\n",
    "# gz2 cols\n",
    "# questions = label_metadata.gz2_questions\n",
    "# version = 'gz2'\n",
    "# label_cols = label_metadata.gz2_label_cols\n",
    "\n",
    "\n",
    "\n",
    "schema = losses.Schema(label_cols, questions, version=version)\n",
    "\n",
    "batch_size = 8\n",
    "initial_size = 300\n",
    "# initial_size = 128\n",
    "crop_size = int(initial_size * 0.75)\n",
    "# crop_size = 128\n",
    "final_size = 224\n",
    "channels = 3\n",
    "\n",
    "n_samples = 5\n",
    "\n",
    "# if loading single test tfrecord\n",
    "# tfrecord_locs = [f'data/decals/shards/multilabel_{img_size}/eval/s{initial_size}_shard_0.tfrecord']\n",
    "# tfrecord_locs = ['data/decals/shards/multilabel_master_256/train/s256_shard_0.tfrecord']\n",
    "# tfrecord_locs = glob.glob(f'/media/walml/beta/decals/multilabel_master_{initial_size}/train/*.tfrecord')[start:end]\n",
    "# tfrecord_locs = glob.glob(f'/home/walml/repos/zoobot/data/decals/shards/decals_multiq_{initial_size}_sim_init_2500_featp4/train_shards/*.tfrecord')[start:end]\n",
    "\n",
    "# for all labelled decals galaxies\n",
    "# train_locs = glob.glob(f'/home/walml/repos/zoobot/data/decals/shards/decals_multiq_{initial_size}/train_shards/*.tfrecord')\n",
    "# eval_locs = glob.glob(f'/home/walml/repos/zoobot/data/decals/shards/decals_multiq_{initial_size}/eval_shards/*.tfrecord')\n",
    "# tfrecord_locs = train_locs + eval_locs\n",
    "\n",
    "# for all decals galaxies after filter\n",
    "# train_locs = glob.glob(f'/home/walml/repos/zoobot/data/decals/shards/multilabel_master_filtered_{initial_size}/train/*.tfrecord')\n",
    "# eval_locs = glob.glob(f'/home/walml/repos/zoobot/data/decals/shards/multilabel_master_filtered_{initial_size}/eval/*.tfrecord')\n",
    "# tfrecord_locs = eval_locs\n",
    "\n",
    "# tfrecord_locs = train_locs[:1]\n",
    "\n",
    "# for calibration dr5 galaxies\n",
    "# eval_locs = glob.glob(f'/home/walml/repos/zoobot/data/decals/shards/temp_calibration_shards_feat/train/*.tfrecord')\n",
    "# tfrecord_locs = eval_locs\n",
    "\n",
    "# for 10k labelled/filtered GZ2 galaxies\n",
    "# train_locs = glob.glob(f'/home/walml/repos/zoobot/data/gz2/shards/all_featp5_facep5_sim_2p5_{initial_size}/train_shards/*.tfrecord')\n",
    "# eval_locs = glob.glob(f'/home/walml/repos/zoobot/data/gz2/shards/all_featp5_facep5_sim_2p5_{initial_size}_/eval_shards/*.tfrecord')\n",
    "# # tfrecord_locs = train_locs + eval_locs\n",
    "# tfrecord_locs = eval_locs\n",
    "\n",
    "# # for 10k UNFILTERED GZ2 galaxies\n",
    "# eval_locs = glob.glob(f'/home/walml/repos/zoobot/data/gz2/shards/all_sim_2p5_unfiltered_{initial_size}/eval_shards/*.tfrecord')\n",
    "# # tfrecord_locs = train_locs + eval_locs\n",
    "# tfrecord_locs = eval_locs\n",
    "\n",
    "\n",
    "# latest arc eval set\n",
    "# eval_locs = glob.glob(f'/home/walml/repos/zoobot/data/gz2/all_actual_sim_2p5_unfiltered_{initial_size}_arc_eval_shards/eval_shards/*.tfrecord')\n",
    "# # # tfrecord_locs = train_locs + eval_locs\n",
    "# tfrecord_locs = eval_locs\n",
    "\n",
    "eval_locs = glob.glob(f'/home/walml/repos/zoobot/results/temp/decals_n2_allq_m0_eval_shards/*.tfrecord')\n",
    "# # # tfrecord_locs = train_locs + eval_locs\n",
    "tfrecord_locs = eval_locs\n",
    "\n",
    "\n",
    "print(tfrecord_locs)\n",
    "eval_config = run_estimator_config.get_eval_config(tfrecord_locs, label_cols, batch_size, initial_size, final_size, channels)\n",
    "# print(eval_config.greyscale)\n",
    "# print(eval_config.permute_channels)\n",
    "eval_config.drop_remainder = False\n",
    "dataset = input_utils.get_input(config=eval_config)\n",
    "\n",
    "feature_spec = input_utils.get_feature_spec({'id_str': 'string'})\n",
    "id_str_dataset = input_utils.get_dataset(tfrecord_locs, feature_spec, batch_size=1, shuffle=False, repeat=False, drop_remainder=False)\n",
    "id_strs = [str(d['id_str'].numpy().squeeze())[2:-1] for d in id_str_dataset]\n",
    "id_strs[:5]\n",
    "\n",
    "# n = 0\n",
    "# for batch in id_str_dataset:\n",
    "#     for id_str in batch:\n",
    "#         n+=1\n",
    "# print(n)\n",
    "\n",
    "# counter = Counter()\n",
    "# n = 0\n",
    "# for g_batch, y_batch in dataset:\n",
    "# #     for g in g_batch:\n",
    "# #         counter[g.numpy().sum()] += 1\n",
    "#         n+=tf.shape(g_batch)[0]\n",
    "# print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, axes = plt.subplots(ncols=3)\n",
    "# n=0\n",
    "# for images, labels in dataset.take(3):\n",
    "#     image = images[0]\n",
    "#     axes[n].imshow(image.numpy().squeeze())\n",
    "#     n+= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(id_strs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # if loading png\n",
    "\n",
    "# print(catalog['file_loc'])\n",
    "# assert all([os.path.isfile(x) for x in catalog['file_loc']])\n",
    "# filenames = tf.constant(list(catalog['file_loc']), dtype=tf.string)\n",
    "# dataset = tf.data.Dataset.from_tensor_slices(filenames)\n",
    "\n",
    "# def parse_image(im):\n",
    "#     im = tf.image.decode_png(im, channels=channels)\n",
    "#     im = tf.image.convert_image_dtype(im, tf.float32)\n",
    "#     im = tf.image.resize(im, [initial_size, initial_size])\n",
    "#     return im\n",
    "\n",
    "\n",
    "# # for im in dataset.take(1):\n",
    "# #     print(im)\n",
    "\n",
    "# # assert False\n",
    "\n",
    "# dataset = dataset.map(tf.io.read_file)\n",
    "# dataset = dataset.map(parse_image)\n",
    "\n",
    "# config = default_estimator_params.get_eval_config(['do not use'], label_cols, batch_size, initial_size, final_size, channels)\n",
    "\n",
    "# dataset = dataset.batch(batch_size)\n",
    "\n",
    "# # for batch in dataset.take(1):\n",
    "# #     print(tf.shape(batch))\n",
    "# # #     plt.imshow(batch[0])\n",
    "\n",
    "\n",
    "# # dataset = dataset.map(lambda x: check_shape(x))\n",
    "\n",
    "# dataset = dataset.map(lambda x: input_utils.preprocess_images(x, config))\n",
    "\n",
    "\n",
    "# # for batch in dataset.take(1):\n",
    "# #     print(tf.shape(batch))\n",
    "# #     plt.imshow(batch[0].numpy().squeeze())\n",
    "\n",
    "\n",
    "# id_strs = catalog['iauname']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 300, 300, 1)\n"
     ]
    }
   ],
   "source": [
    "for images, _ in dataset.take(1):\n",
    "    print(images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Crop size and final size are similar: skipping resizing and cropping directly to final_size (ignoring crop_size)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results/temp/decals_retired_allq_m0/models/final\n"
     ]
    }
   ],
   "source": [
    "model = run_estimator_config.get_model(schema, initial_size, crop_size, final_size)\n",
    "# checkpoint_dir = 'results/debug_300/models/final'\n",
    "# checkpoint_dir = 'results/latest/test/models/final'\n",
    "# checkpoint_dir = 'results/temp/latest_offline_sim_unfiltered/in_progress'\n",
    "# checkpoint_dir = 'results/latest/latest_dirichlet_baseline_a/final'\n",
    "\n",
    "# checkpoint_dir = 'results/temp/gz2_all_q_warm_active/iteration_0/estimators/models/model_0/final'\n",
    "# checkpoint_dir = 'results/temp/gz2_all_q_warm_baseline/iteration_2/estimators/models/model_2/final'\n",
    "# checkpoint_dir = 'results/temp/gz2_all_q_opt4_warm_active/iteration_2/estimators/models/model_2/final'\n",
    "\n",
    "# n2, not necc. the best model\n",
    "# checkpoint_dir = 'results/temp/decals_n2_allq_m0/in_progress'\n",
    "\n",
    "# n2, not necc. the best model\n",
    "# checkpoint_dir = 'results/temp/decals_retired_allq_m0/models/final'\n",
    "\n",
    "checkpoint_dir = 'results/temp/decals_retired_allq_m0/models/final'\n",
    "\n",
    "# iteration 0!\n",
    "# checkpoint_dir = f'{results_dir}/iteration_0/estimators/models'\n",
    "# checkpoint_dir = f'{results_dir}/models'\n",
    "# checkpoint_dir = f'{results_dir}/final'\n",
    "\n",
    "print(checkpoint_dir)\n",
    "load_status = model.load_weights(checkpoint_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f3d1581efd0>"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_status.assert_nontrivial_match()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f3d1581efd0>"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_status.assert_existing_objects_matched()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[20.358316, 10.980032],\n",
       "       [51.719475, 33.65394 ],\n",
       "       [72.833336,  5.651007],\n",
       "       [ 8.864109, 22.148716],\n",
       "       [80.322975, 12.311265],\n",
       "       [ 9.764767, 13.030967],\n",
       "       [ 8.280451, 11.811539],\n",
       "       [21.803785,  4.809663],\n",
       "       [16.164717, 34.592922],\n",
       "       [20.656013,  9.512716]], dtype=float32)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(dataset.take(5))[:10, :2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.312257 ,  2.8522325],\n",
       "       [ 8.755309 , 43.133865 ],\n",
       "       [ 6.7384024,  6.765002 ],\n",
       "       [ 2.7138705,  2.0403795],\n",
       "       [ 8.486013 , 14.931778 ],\n",
       "       [ 2.3010445,  2.8900008],\n",
       "       [ 3.949268 ,  1.7112068],\n",
       "       [ 4.211546 ,  2.9462953],\n",
       "       [ 5.5215425, 62.367363 ],\n",
       "       [ 2.8931277,  2.719283 ]], dtype=float32)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(dataset.take(5))[:10, 2:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.evaluate(dataset)  # unfiltered = 2.04 73 secs for four q, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %timeit predictions = model.predict(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<MapDataset shapes: ((None, 300, 300, 1), (None, 34)), types: (tf.float32, tf.float32)>"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # copied from trust_the_model.ipynb\n",
    "# def show_galaxies(galaxies, scale=3, nrows=6, ncols=6):\n",
    "#     fig = plt.gcf()\n",
    "\n",
    "#     plt.figure(figsize=(scale * nrows, scale * ncols * 1.025))\n",
    "#     gs1 = gridspec.GridSpec(nrows, ncols)\n",
    "#     gs1.update(wspace=0.0, hspace=0.0)\n",
    "#     galaxy_n = 0\n",
    "#     for row_n in range(nrows):\n",
    "#         for col_n in range(ncols):\n",
    "#             galaxy = np.squeeze(galaxies[galaxy_n])\n",
    "#             ax = plt.subplot(gs1[row_n, col_n])\n",
    "#             ax.imshow(galaxy)\n",
    "# #             ax.text(10, 20, 'Smooth = {:.2f}'.format(galaxy['smooth-or-featured_smooth_fraction']), fontsize=12, color='r')\n",
    "# #             ax.text(10, 50, r'$\\rho = {:.2f}$, Var ${:.3f}$'.format(galaxy['median_prediction'], 3*galaxy['predictions_var']), fontsize=12, color='r')\n",
    "# #             ax.text(10, 80, '$L = {:.2f}$'.format(galaxy['bcnn_likelihood']), fontsize=12, color='r')\n",
    "#             ax.axis('off')\n",
    "#             galaxy_n += 1\n",
    "# #     print('Mean L: {:.2f}'.format(df[:nrows * ncols]['bcnn_likelihood'].mean()))\n",
    "#     fig = plt.gcf()\n",
    "# #     fig.tight_layout()\n",
    "#     return fig\n",
    "\n",
    "# for images, labels in dataset.take(1):\n",
    "#     print(images.shape)\n",
    "#     print(labels.shape)\n",
    "    \n",
    "# # plt.hist(images.numpy()[0].flatten())\n",
    "\n",
    "# _ = show_galaxies(images.numpy(), nrows=2, ncols=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre_model = tf.keras.models.Sequential()\n",
    "# pre_model.add(tf.keras.layers.Input(shape=(initial_size, initial_size, 1)))\n",
    "# run_estimator_config.add_preprocessing_layers(pre_model, crop_size, final_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output = pre_model.predict(dataset.take(1))\n",
    "# print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _ = show_galaxies(output, nrows=2, ncols=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = run_estimator_config.get_model(schema, initial_size, crop_size, final_size, weights_loc=checkpoint_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.predict(dataset.take(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from zoobot.estimators import efficientnet\n",
    "\n",
    "# input_shape = (final_size, final_size, 1)\n",
    "# effnet = efficientnet.EfficientNet_custom_top(\n",
    "#     schema=schema,\n",
    "#     input_shape=input_shape,\n",
    "#     get_effnet=efficientnet.EfficientNetB0\n",
    "#     # further kwargs will be passed to get_effnet\n",
    "#     # dropout_rate=dropout_rate,\n",
    "#     # drop_connect_rate=drop_connect_rate\n",
    "# )\n",
    "# # effnet.load_weights(checkpoint_dir)\n",
    "\n",
    "# model = tf.keras.models.Sequential()\n",
    "# model.add(pre_model)\n",
    "# model.add(effnet)\n",
    "\n",
    "# # model.load_weights(checkpoint_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run_config = run_estimator_config.get_run_config(initial_size, final_size, crop_size, False, '', train_locs, eval_locs, 12, schema, batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# db_loc = 'data/experiments/live/latest/iteration_0/iteration.db'\n",
    "# db = sqlite3.connect(db_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = database.get_all_subjects_df(db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unlabelled_locs = glob.glob(f'/home/walml/repos/zoobot/data/gz2/shards/all_featp5_facep5_sim_{initial_size}/*.tfrecord')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# id_str_dataset = input_utils.get_dataset(unlabelled_locs, feature_spec, batch_size=1, shuffle=False, repeat=False, drop_remainder=False)\n",
    "# id_strs = [str(d['id_str'].numpy().squeeze())[2:-1] for d in id_str_dataset]\n",
    "# len(id_strs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from zoobot.active_learning import database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions = database.make_predictions_on_tfrecord([unlabelled_locs[0]], model, run_config, db, n_samples, initial_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unlabelled_subjects, samples = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(unlabelled_subjects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unlabelled_subjects[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unlabelled_subjects[0]['predictions'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unlabelled_config = input_utils.InputConfig(\n",
    "#         name='eval',\n",
    "#         tfrecord_loc=[unlabelled_locs[0]],\n",
    "#         label_cols=[],\n",
    "#         stratify=False,\n",
    "#         shuffle=False,  # see above\n",
    "#         repeat=False,\n",
    "#         drop_remainder=False,\n",
    "#         stratify_probs=None,\n",
    "#         geometric_augmentation=False,\n",
    "#         photographic_augmentation=False,\n",
    "#         contrast_range=(0.98, 1.02),\n",
    "#         batch_size=batch_size,\n",
    "#         initial_size=initial_size,\n",
    "#         final_size=final_size,\n",
    "#         channels=channels,\n",
    "#         greyscale=True,\n",
    "#         zoom_central=False  # SMOOTH MODE\n",
    "#         # zoom_central=True  # BAR MODE\n",
    "#     )\n",
    "# unlabelled_dataset = input_utils.get_input(config=unlabelled_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions_direct = np.stack([model.predict(unlabelled_dataset) for n in range(n_samples)], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions_direct.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# samples[0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unlabelled_subjects[5]['predictions'][0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions_direct[5, 0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# schema.answers[2].text, schema.answers[3].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# schema.answers[4].text, schema.answers[5].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, axes = plt.subplots(nrows=5, sharex=True)\n",
    "# for subject_n in range(5):\n",
    "#     ax = axes[subject_n]\n",
    "#     ax.hist(predictions_direct[subject_n, 4] / predictions_direct[subject_n, 5], alpha=.5)\n",
    "#     ax.hist(unlabelled_subjects[subject_n]['predictions'][4] / unlabelled_subjects[subject_n]['predictions'][5], alpha=.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, axes = plt.subplots(nrows=5, sharex=True, figsize=(4, 12))\n",
    "# for subject_n in range(5):\n",
    "#     ax = axes[subject_n]\n",
    "#     ax.imshow(np.array(Image.open(df['file_loc'][subject_n])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# id_strs[0], unlabelled_subjects[0]['id_str']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.stack([model.predict(dataset) for n in range(n_samples)], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 34, 5)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([11.27927 , 14.975777, 17.126745, 16.46605 , 14.626597],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[11.27927  , 14.975777 , 17.126745 , 16.46605  , 14.626597 ],\n",
       "       [18.48789  , 15.061994 , 12.538382 , 11.535164 , 13.7275915]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0, :2, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([49.97901 , 59.155167, 58.436424, 69.242615, 68.42684 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[12, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([44.34936 , 47.56811 , 37.922855, 62.31121 , 37.526535],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[12, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.hist(np.std(predictions[:, 0, :], axis=-1), bins=30)\n",
    "# plt.xlabel('Mean smooth/featured std')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for batch_x, batch_y in dataset:\n",
    "#     print(batch_y.numpy())\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels = np.concatenate([batch_y for (_, batch_y) in test_dataset], axis=0)\n",
    "# labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots()\n",
    "# ax.hist(predictions[:, 0], alpha=0.5, label='Predictions', density=True)\n",
    "# ax.hist(labels[:, 0] / labels[:, :2].sum(axis=1), alpha=0.5, label='Labels', density=True)\n",
    "# plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(predictions[:, 0].min(), labels[:, 0].min())\n",
    "# print(predictions[:, 0].max(), labels[:, 0].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# acquisitions = acquisition_utils.mutual_info_acquisition_func_multiq(predictions, schema, retirement=40)\n",
    "# acquisitions.shape\n",
    "# acquisitions\n",
    "\n",
    "# single_q_acquisitions = np.array(acquisition_utils.mutual_info_acquisition_func(predictions[:, 0], expected_votes=40))\n",
    "# single_q_acquisitions[:5], acquisitions[0, :5], acquisitions[1, :5]  # smooth mutual acq should be identical, for both answers by symmmetry\n",
    "# acquisitions[2, :5], acquisitions[3, :5]  # has-spiral-arms also by symmetry\n",
    "# acquisitions[4, :5], acquisitions[5, :5], acquisitions[6, :5]  # but for spiral winding there are 3 answers so *not* identical\n",
    "# predictions.shape, acquisitions.shape, len(id_strs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 34, 5), 10000)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.shape, len(id_strs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([11.27927 , 14.975777, 17.126745, 16.46605 , 14.626597],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def prediction_to_row(prediction, id_str):\n",
    "#     row = {\n",
    "#         'id_str': id_str\n",
    "#     }\n",
    "#     for n, col in enumerate(label_cols):\n",
    "#         answer = label_cols[n]\n",
    "\n",
    "# #         row[answer + '_acquisition'] = acquisition[n]\n",
    "#         row[answer + '_prediction_mean'] = float(prediction[n].mean())\n",
    "# #         row[answer + '_acquisition'] = acquisition[n]\n",
    "# #         row['total_acquisition'] = acquisition.sum()\n",
    "#     return row\n",
    "\n",
    "def prediction_to_row(prediction, id_str):\n",
    "    row = {\n",
    "        'id_str': id_str\n",
    "    }\n",
    "    for n, col in enumerate(label_cols):\n",
    "        answer = label_cols[n]\n",
    "        row[answer + '_concentration'] = json.dumps(list(prediction[n].astype(float)))\n",
    "#         row[answer + '_acquisition'] = acquisition[n]\n",
    "        row[answer + '_concentration_mean'] = float(prediction[n].mean())\n",
    "#         row[answer + '_acquisition'] = acquisition[n]\n",
    "#         row['total_acquisition'] = acquisition.sum()\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def all_to_row(prediction, acquisition, id_str):\n",
    "#     row = {\n",
    "#         'id_str': id_str\n",
    "#     }\n",
    "#     for n, col in enumerate(label_cols):\n",
    "#         answer = label_cols[n]\n",
    "#         row[answer + '_prediction'] = prediction[n]\n",
    "# #         row[answer + '_acquisition'] = acquisition[n]\n",
    "#         row[answer + '_prediction_mean'] = float(prediction[n].mean())\n",
    "# #         row[answer + '_acquisition'] = acquisition[n]\n",
    "# #         row['total_acquisition'] = acquisition.sum()\n",
    "#     return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [prediction_to_row(predictions[n], id_strs[n]) for n in range(len(predictions))]\n",
    "# data = [all_to_row(predictions[n], acquisitions[n], id_strs[n]) for n in range(len(predictions))]\n",
    "predictions_df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predictions_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_str</th>\n",
       "      <th>smooth-or-featured_smooth_concentration</th>\n",
       "      <th>smooth-or-featured_smooth_concentration_mean</th>\n",
       "      <th>smooth-or-featured_featured-or-disk_concentration</th>\n",
       "      <th>smooth-or-featured_featured-or-disk_concentration_mean</th>\n",
       "      <th>smooth-or-featured_artifact_concentration</th>\n",
       "      <th>smooth-or-featured_artifact_concentration_mean</th>\n",
       "      <th>disk-edge-on_yes_concentration</th>\n",
       "      <th>disk-edge-on_yes_concentration_mean</th>\n",
       "      <th>disk-edge-on_no_concentration</th>\n",
       "      <th>...</th>\n",
       "      <th>spiral-arm-count_cant-tell_concentration</th>\n",
       "      <th>spiral-arm-count_cant-tell_concentration_mean</th>\n",
       "      <th>merging_none_concentration</th>\n",
       "      <th>merging_none_concentration_mean</th>\n",
       "      <th>merging_minor-disturbance_concentration</th>\n",
       "      <th>merging_minor-disturbance_concentration_mean</th>\n",
       "      <th>merging_major-disturbance_concentration</th>\n",
       "      <th>merging_major-disturbance_concentration_mean</th>\n",
       "      <th>merging_merger_concentration</th>\n",
       "      <th>merging_merger_concentration_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>J101523.33+031030.9</td>\n",
       "      <td>[11.27927017211914, 14.975776672363281, 17.126...</td>\n",
       "      <td>14.894887</td>\n",
       "      <td>[18.487890243530273, 15.061993598937988, 12.53...</td>\n",
       "      <td>14.270205</td>\n",
       "      <td>[3.4109861850738525, 3.6765503883361816, 3.380...</td>\n",
       "      <td>3.371450</td>\n",
       "      <td>[2.5431180000305176, 2.891010284423828, 2.7779...</td>\n",
       "      <td>2.771492</td>\n",
       "      <td>[73.60625457763672, 58.1546630859375, 51.68944...</td>\n",
       "      <td>...</td>\n",
       "      <td>[6.270047664642334, 8.276326179504395, 12.5538...</td>\n",
       "      <td>9.155304</td>\n",
       "      <td>[16.36289405822754, 17.06951141357422, 14.9404...</td>\n",
       "      <td>13.893324</td>\n",
       "      <td>[7.7284440994262695, 8.662688255310059, 7.3509...</td>\n",
       "      <td>7.001131</td>\n",
       "      <td>[2.550448417663574, 2.3602328300476074, 1.9933...</td>\n",
       "      <td>2.039750</td>\n",
       "      <td>[3.5474438667297363, 4.097710609436035, 4.0339...</td>\n",
       "      <td>4.585111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>J112413.94+245257.5</td>\n",
       "      <td>[55.1696891784668, 52.06551742553711, 56.90679...</td>\n",
       "      <td>54.522839</td>\n",
       "      <td>[30.61265754699707, 31.842456817626953, 28.707...</td>\n",
       "      <td>31.032757</td>\n",
       "      <td>[8.016695022583008, 8.519285202026367, 8.50559...</td>\n",
       "      <td>8.310714</td>\n",
       "      <td>[37.72706985473633, 42.812862396240234, 31.658...</td>\n",
       "      <td>38.771183</td>\n",
       "      <td>[6.244181156158447, 6.101380825042725, 6.82457...</td>\n",
       "      <td>...</td>\n",
       "      <td>[16.076433181762695, 14.546131134033203, 18.80...</td>\n",
       "      <td>16.023624</td>\n",
       "      <td>[92.08403778076172, 94.09244537353516, 88.3727...</td>\n",
       "      <td>92.109886</td>\n",
       "      <td>[6.697113513946533, 6.890059947967529, 6.08404...</td>\n",
       "      <td>6.518374</td>\n",
       "      <td>[1.4896457195281982, 1.5561150312423706, 1.476...</td>\n",
       "      <td>1.500419</td>\n",
       "      <td>[1.2816667556762695, 1.238523006439209, 1.4674...</td>\n",
       "      <td>1.310111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>J160105.65-004226.9</td>\n",
       "      <td>[72.8885269165039, 62.529762268066406, 68.5110...</td>\n",
       "      <td>67.382690</td>\n",
       "      <td>[6.07484245300293, 6.279238224029541, 5.604297...</td>\n",
       "      <td>5.960749</td>\n",
       "      <td>[7.311710357666016, 6.899960994720459, 6.60113...</td>\n",
       "      <td>6.780965</td>\n",
       "      <td>[8.313241958618164, 6.744441509246826, 6.20512...</td>\n",
       "      <td>6.890455</td>\n",
       "      <td>[31.76457977294922, 30.494199752807617, 26.252...</td>\n",
       "      <td>...</td>\n",
       "      <td>[18.716087341308594, 17.575172424316406, 20.37...</td>\n",
       "      <td>18.915979</td>\n",
       "      <td>[84.1072006225586, 77.57942199707031, 71.59207...</td>\n",
       "      <td>76.379982</td>\n",
       "      <td>[8.765542984008789, 8.74241828918457, 10.08154...</td>\n",
       "      <td>9.079222</td>\n",
       "      <td>[1.8897054195404053, 1.8869670629501343, 1.846...</td>\n",
       "      <td>1.868123</td>\n",
       "      <td>[1.0784064531326294, 1.0940051078796387, 1.112...</td>\n",
       "      <td>1.105595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>J112748.26+264900.1</td>\n",
       "      <td>[10.218161582946777, 9.084182739257812, 8.2000...</td>\n",
       "      <td>8.763184</td>\n",
       "      <td>[19.81637191772461, 20.72105598449707, 20.2951...</td>\n",
       "      <td>20.260975</td>\n",
       "      <td>[3.1757473945617676, 2.962010145187378, 2.6536...</td>\n",
       "      <td>2.941709</td>\n",
       "      <td>[1.7829853296279907, 2.0597589015960693, 1.996...</td>\n",
       "      <td>1.903531</td>\n",
       "      <td>[68.4912109375, 75.38482666015625, 81.52665710...</td>\n",
       "      <td>...</td>\n",
       "      <td>[13.298824310302734, 11.231612205505371, 10.60...</td>\n",
       "      <td>11.610242</td>\n",
       "      <td>[18.421968460083008, 20.00270652770996, 21.238...</td>\n",
       "      <td>18.143351</td>\n",
       "      <td>[11.918533325195312, 12.801078796386719, 12.58...</td>\n",
       "      <td>11.604419</td>\n",
       "      <td>[7.076321125030518, 7.527082443237305, 6.91198...</td>\n",
       "      <td>7.214477</td>\n",
       "      <td>[1.628361701965332, 1.37748384475708, 1.325240...</td>\n",
       "      <td>1.466835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>J155214.79+164831.8</td>\n",
       "      <td>[70.9332275390625, 78.71728515625, 64.24332427...</td>\n",
       "      <td>76.407028</td>\n",
       "      <td>[11.820240020751953, 10.94378662109375, 10.623...</td>\n",
       "      <td>11.463373</td>\n",
       "      <td>[8.661657333374023, 9.23896598815918, 7.588526...</td>\n",
       "      <td>9.027744</td>\n",
       "      <td>[16.46335220336914, 16.7069091796875, 15.18986...</td>\n",
       "      <td>18.117764</td>\n",
       "      <td>[14.67911148071289, 14.895379066467285, 12.161...</td>\n",
       "      <td>...</td>\n",
       "      <td>[17.69595718383789, 16.06884002685547, 17.0653...</td>\n",
       "      <td>16.611118</td>\n",
       "      <td>[84.24547576904297, 90.71809387207031, 78.3669...</td>\n",
       "      <td>89.167542</td>\n",
       "      <td>[8.992124557495117, 9.326862335205078, 8.07801...</td>\n",
       "      <td>8.414492</td>\n",
       "      <td>[1.755096673965454, 1.8085262775421143, 1.6271...</td>\n",
       "      <td>1.710882</td>\n",
       "      <td>[1.2377533912658691, 1.1164424419403076, 1.286...</td>\n",
       "      <td>1.155625</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 69 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                id_str            smooth-or-featured_smooth_concentration  \\\n",
       "0  J101523.33+031030.9  [11.27927017211914, 14.975776672363281, 17.126...   \n",
       "1  J112413.94+245257.5  [55.1696891784668, 52.06551742553711, 56.90679...   \n",
       "2  J160105.65-004226.9  [72.8885269165039, 62.529762268066406, 68.5110...   \n",
       "3  J112748.26+264900.1  [10.218161582946777, 9.084182739257812, 8.2000...   \n",
       "4  J155214.79+164831.8  [70.9332275390625, 78.71728515625, 64.24332427...   \n",
       "\n",
       "   smooth-or-featured_smooth_concentration_mean  \\\n",
       "0                                     14.894887   \n",
       "1                                     54.522839   \n",
       "2                                     67.382690   \n",
       "3                                      8.763184   \n",
       "4                                     76.407028   \n",
       "\n",
       "   smooth-or-featured_featured-or-disk_concentration  \\\n",
       "0  [18.487890243530273, 15.061993598937988, 12.53...   \n",
       "1  [30.61265754699707, 31.842456817626953, 28.707...   \n",
       "2  [6.07484245300293, 6.279238224029541, 5.604297...   \n",
       "3  [19.81637191772461, 20.72105598449707, 20.2951...   \n",
       "4  [11.820240020751953, 10.94378662109375, 10.623...   \n",
       "\n",
       "   smooth-or-featured_featured-or-disk_concentration_mean  \\\n",
       "0                                          14.270205        \n",
       "1                                          31.032757        \n",
       "2                                           5.960749        \n",
       "3                                          20.260975        \n",
       "4                                          11.463373        \n",
       "\n",
       "           smooth-or-featured_artifact_concentration  \\\n",
       "0  [3.4109861850738525, 3.6765503883361816, 3.380...   \n",
       "1  [8.016695022583008, 8.519285202026367, 8.50559...   \n",
       "2  [7.311710357666016, 6.899960994720459, 6.60113...   \n",
       "3  [3.1757473945617676, 2.962010145187378, 2.6536...   \n",
       "4  [8.661657333374023, 9.23896598815918, 7.588526...   \n",
       "\n",
       "   smooth-or-featured_artifact_concentration_mean  \\\n",
       "0                                        3.371450   \n",
       "1                                        8.310714   \n",
       "2                                        6.780965   \n",
       "3                                        2.941709   \n",
       "4                                        9.027744   \n",
       "\n",
       "                      disk-edge-on_yes_concentration  \\\n",
       "0  [2.5431180000305176, 2.891010284423828, 2.7779...   \n",
       "1  [37.72706985473633, 42.812862396240234, 31.658...   \n",
       "2  [8.313241958618164, 6.744441509246826, 6.20512...   \n",
       "3  [1.7829853296279907, 2.0597589015960693, 1.996...   \n",
       "4  [16.46335220336914, 16.7069091796875, 15.18986...   \n",
       "\n",
       "   disk-edge-on_yes_concentration_mean  \\\n",
       "0                             2.771492   \n",
       "1                            38.771183   \n",
       "2                             6.890455   \n",
       "3                             1.903531   \n",
       "4                            18.117764   \n",
       "\n",
       "                       disk-edge-on_no_concentration  ...  \\\n",
       "0  [73.60625457763672, 58.1546630859375, 51.68944...  ...   \n",
       "1  [6.244181156158447, 6.101380825042725, 6.82457...  ...   \n",
       "2  [31.76457977294922, 30.494199752807617, 26.252...  ...   \n",
       "3  [68.4912109375, 75.38482666015625, 81.52665710...  ...   \n",
       "4  [14.67911148071289, 14.895379066467285, 12.161...  ...   \n",
       "\n",
       "            spiral-arm-count_cant-tell_concentration  \\\n",
       "0  [6.270047664642334, 8.276326179504395, 12.5538...   \n",
       "1  [16.076433181762695, 14.546131134033203, 18.80...   \n",
       "2  [18.716087341308594, 17.575172424316406, 20.37...   \n",
       "3  [13.298824310302734, 11.231612205505371, 10.60...   \n",
       "4  [17.69595718383789, 16.06884002685547, 17.0653...   \n",
       "\n",
       "  spiral-arm-count_cant-tell_concentration_mean  \\\n",
       "0                                      9.155304   \n",
       "1                                     16.023624   \n",
       "2                                     18.915979   \n",
       "3                                     11.610242   \n",
       "4                                     16.611118   \n",
       "\n",
       "                          merging_none_concentration  \\\n",
       "0  [16.36289405822754, 17.06951141357422, 14.9404...   \n",
       "1  [92.08403778076172, 94.09244537353516, 88.3727...   \n",
       "2  [84.1072006225586, 77.57942199707031, 71.59207...   \n",
       "3  [18.421968460083008, 20.00270652770996, 21.238...   \n",
       "4  [84.24547576904297, 90.71809387207031, 78.3669...   \n",
       "\n",
       "  merging_none_concentration_mean  \\\n",
       "0                       13.893324   \n",
       "1                       92.109886   \n",
       "2                       76.379982   \n",
       "3                       18.143351   \n",
       "4                       89.167542   \n",
       "\n",
       "             merging_minor-disturbance_concentration  \\\n",
       "0  [7.7284440994262695, 8.662688255310059, 7.3509...   \n",
       "1  [6.697113513946533, 6.890059947967529, 6.08404...   \n",
       "2  [8.765542984008789, 8.74241828918457, 10.08154...   \n",
       "3  [11.918533325195312, 12.801078796386719, 12.58...   \n",
       "4  [8.992124557495117, 9.326862335205078, 8.07801...   \n",
       "\n",
       "  merging_minor-disturbance_concentration_mean  \\\n",
       "0                                     7.001131   \n",
       "1                                     6.518374   \n",
       "2                                     9.079222   \n",
       "3                                    11.604419   \n",
       "4                                     8.414492   \n",
       "\n",
       "             merging_major-disturbance_concentration  \\\n",
       "0  [2.550448417663574, 2.3602328300476074, 1.9933...   \n",
       "1  [1.4896457195281982, 1.5561150312423706, 1.476...   \n",
       "2  [1.8897054195404053, 1.8869670629501343, 1.846...   \n",
       "3  [7.076321125030518, 7.527082443237305, 6.91198...   \n",
       "4  [1.755096673965454, 1.8085262775421143, 1.6271...   \n",
       "\n",
       "  merging_major-disturbance_concentration_mean  \\\n",
       "0                                     2.039750   \n",
       "1                                     1.500419   \n",
       "2                                     1.868123   \n",
       "3                                     7.214477   \n",
       "4                                     1.710882   \n",
       "\n",
       "                        merging_merger_concentration  \\\n",
       "0  [3.5474438667297363, 4.097710609436035, 4.0339...   \n",
       "1  [1.2816667556762695, 1.238523006439209, 1.4674...   \n",
       "2  [1.0784064531326294, 1.0940051078796387, 1.112...   \n",
       "3  [1.628361701965332, 1.37748384475708, 1.325240...   \n",
       "4  [1.2377533912658691, 1.1164424419403076, 1.286...   \n",
       "\n",
       "  merging_merger_concentration_mean  \n",
       "0                          4.585111  \n",
       "1                          1.310111  \n",
       "2                          1.105595  \n",
       "3                          1.466835  \n",
       "4                          1.155625  \n",
       "\n",
       "[5 rows x 69 columns]"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# catalog['dr7objid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog['iauname'] = catalog['iauname'].astype(str)\n",
    "# predictions_df['iauname'] = predictions_df['id_str'].astype(str)\n",
    "# catalog['id_str'] = catalog['dr7objid'].apply(lambda x: 'dr7objid_' + str(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions_df['id_str'].sort_values().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "309398\n"
     ]
    }
   ],
   "source": [
    "# catalog['iauname'].sort_values().values\n",
    "print(len(catalog))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       J101523.33+031030.9\n",
       "1       J112413.94+245257.5\n",
       "2       J160105.65-004226.9\n",
       "3       J112748.26+264900.1\n",
       "4       J155214.79+164831.8\n",
       "               ...         \n",
       "9995    J002315.35-011046.1\n",
       "9996    J100818.28-002136.7\n",
       "9997    J120818.30+240608.8\n",
       "9998    J143428.37+231812.9\n",
       "9999    J165006.69+232633.6\n",
       "Name: id_str, Length: 10000, dtype: object"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_df['id_str']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         J094651.40-010228.5\n",
       "1         J094630.85-004554.5\n",
       "2         J094631.59-005917.7\n",
       "3         J094744.18-004013.4\n",
       "4         J094751.74-003242.0\n",
       "                 ...         \n",
       "309393    J143642.06-012542.2\n",
       "309394    J143539.18-012924.0\n",
       "309395    J230924.60-001458.1\n",
       "309396    J235101.08-100042.7\n",
       "309397    J235320.91-103238.7\n",
       "Name: id_str, Length: 309398, dtype: object"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "catalog['id_str']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 10000\n"
     ]
    }
   ],
   "source": [
    "df = pd.merge(catalog, predictions_df, how='inner', on='id_str')\n",
    "print(len(df), len(predictions_df))\n",
    "assert len(df) == len(predictions_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for q in schema.questions:\n",
    "#     a = q.answers[0]\n",
    "#     print(a.text, mean_squared_error(df[a.text + '_fraction'], df[a.text + '_prediction_mean']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for q in schema.questions:\n",
    "#     a = q.answers[0]\n",
    "#     print(a.text, mean_absolute_error(df[a.text + '_fraction'], df[a.text + '_prediction_mean']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(12, 12))\n",
    "# axes = [ax for row in axes for ax in row]\n",
    "# for n, q in enumerate(schema.questions):\n",
    "#     a = q.answers[0]\n",
    "#     sns.scatterplot(data=df, x=a.text + '_fraction', y=a.text + '_prediction_mean', ax=axes[n], alpha=0.3)\n",
    "# fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for q in schema.questions:\n",
    "#     a = q.answers[0]\n",
    "#     print(a.text, mean_squared_error(df[a.text + '_fraction'], df[a.text + '_prediction_mean']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv('temp/calibration_predictions.csv', index=False)\n",
    "# df.to_csv('temp/10k_model_a_predictions.csv', index=False)\n",
    "# df.to_csv('temp/10k_model_b_predictions.csv', index=False)\n",
    "# df.to_csv('temp/dirichlet_concentrations_arc_al.csv', index=False)\n",
    "# df.to_csv('temp/dirichlet_concentrations_arc_bl.csv', index=False)\n",
    "# df.to_csv('temp/dirichlet_concentrations_arc_b.csv', index=False)\n",
    "# df.to_csv('temp/gz2_all_2p5_eval.csv', index=False)\n",
    "# df.to_csv('temp/gz2_filtered_2p5_eval.csv', index=False)\n",
    "# df.to_csv('temp/gz2_allq_it0_m0.csv', index=False)\n",
    "# df.to_csv('temp/gz2_allq_it0_m1.csv', index=False)\n",
    "\n",
    "# df.to_csv('temp/gz2_allq_opt4_it2_m2.csv', index=False)\n",
    "# df.to_csv('temp/gz2_allq_baseline_it2_m2.csv', index=False)\n",
    "\n",
    "# df.to_csv('temp/decals_n2_allq_m0.csv', index=False)\n",
    "df.to_csv('temp/decals_retired_allq_m0.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-182-a871fdc9ebee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copied from trust_the_model.ipynb\n",
    "def show_galaxies(df, scale=3, nrows=6, ncols=6):\n",
    "    fig = plt.gcf()\n",
    "\n",
    "    plt.figure(figsize=(scale * nrows, scale * ncols * 1.025))\n",
    "    gs1 = gridspec.GridSpec(nrows, ncols)\n",
    "    gs1.update(wspace=0.0, hspace=0.0)\n",
    "    galaxy_n = 0\n",
    "    for row_n in range(nrows):\n",
    "        for col_n in range(ncols):\n",
    "            galaxy = df.iloc[galaxy_n]\n",
    "            image = Image.open(galaxy['file_loc'])\n",
    "            ax = plt.subplot(gs1[row_n, col_n])\n",
    "            ax.imshow(image)\n",
    "#             ax.text(10, 20, 'Smooth = {:.2f}'.format(galaxy['smooth-or-featured_smooth_fraction']), fontsize=12, color='r')\n",
    "#             ax.text(10, 50, r'$\\rho = {:.2f}$, Var ${:.3f}$'.format(galaxy['median_prediction'], 3*galaxy['predictions_var']), fontsize=12, color='r')\n",
    "#             ax.text(10, 80, '$L = {:.2f}$'.format(galaxy['bcnn_likelihood']), fontsize=12, color='r')\n",
    "            ax.axis('off')\n",
    "            galaxy_n += 1\n",
    "#     print('Mean L: {:.2f}'.format(df[:nrows * ncols]['bcnn_likelihood'].mean()))\n",
    "    fig = plt.gcf()\n",
    "#     fig.tight_layout()\n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('temp/decals_retired_allq_m0.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'save_top_n' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-b5152d88294c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msave_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'results/temp/decals_allq_top_n'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msave_top_n\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschema\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'save_top_n' is not defined"
     ]
    }
   ],
   "source": [
    "save_dir = 'results/temp/decals_allq_top_n'\n",
    "save_top_n(df, schema, save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False  # moove later analysis elsewhere?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots()\n",
    "# ax.scatter(predictions[:, 0], labels[:, 0] / labels[:, :2].sum(axis=1))\n",
    "# plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.get_backend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots()\n",
    "# ax.scatter(predictions[:, 4], labels[:, 4] / labels[:, 4:7].sum(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots()\n",
    "# ax.scatter(predictions[:, 5], labels[:, 5] / labels[:, 4:7].sum(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots()\n",
    "# ax.scatter(predictions[:, 6], labels[:, 6] / labels[:, 4:7].sum(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to check that the right models have been loaded - should be around 40 for smooth, 0-40 for bars\n",
    "# plt.hist(sim_model.total_votes), sim_model.total_votes.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def galaxy_posterior_grid(df, schema):\n",
    "    \n",
    "    sns.set_context('paper', font_scale=1.5)\n",
    "    \n",
    "    scale = 1.5\n",
    "    \n",
    "    im_width = 2\n",
    "    posterior_width = 3\n",
    "    height = im_width\n",
    "    \n",
    "    n_galaxies = len(df)\n",
    "    n_posteriors = len(schema.answers)\n",
    "    \n",
    "    fig = plt.figure(figsize=(scale * (im_width + posterior_width*n_posteriors), (scale * n_galaxies * height)))  # width, height format\n",
    "    gs = gridspec.GridSpec(len(df) * height, im_width + posterior_width * len(schema.answers))  # y, x format\n",
    "    image_axes = []\n",
    "    posterior_axes = []  # (galaxy i.e. row, answer) shape\n",
    "    \n",
    "    # create the grid\n",
    "    for galaxy_n in range(len(df)):\n",
    "        y_slice = slice(galaxy_n*height, (galaxy_n+1)*height)\n",
    "        image_axes.append(plt.subplot(gs[y_slice, :im_width]))\n",
    "        \n",
    "        temp_galaxy_axes = []\n",
    "        for answer_n, answer in enumerate(schema.answers):\n",
    "            x_slice = slice(im_width+answer_n*posterior_width, im_width+(answer_n+1)*posterior_width)\n",
    "            temp_galaxy_axes.append(plt.subplot(gs[y_slice, x_slice]))\n",
    "        posterior_axes.append(temp_galaxy_axes)\n",
    "        \n",
    "    \n",
    "    # fill the images\n",
    "    for ax_n, ax in enumerate(image_axes):\n",
    "        plot_galaxy(df['file_loc'][ax_n], ax)\n",
    "    \n",
    "    # fill the posteriors\n",
    "    for answer_n, answer in enumerate(schema.answers):\n",
    "        samples, labels, total_votes = get_single_answer_data(df, answer)\n",
    "        galaxy_axes = [axes[answer_n] for axes in posterior_axes]\n",
    "        make_predictions.plot_samples(samples, labels, total_votes, fig, galaxy_axes, alpha=0.06)\n",
    "    \n",
    "    # fix x limits for comparison\n",
    "    for row_n, axes in enumerate(posterior_axes):\n",
    "        for answer_n, ax in enumerate(axes):\n",
    "            ax.set_xlim([0, 50])\n",
    "            if row_n == 0:\n",
    "                ax.set_title(schema.answers[answer_n].text)\n",
    "        \n",
    "#     for n in range(len(labels)):\n",
    "#         multiple_axes[n].set_ylabel(r'$p(k|N, D)$', visible=True)\n",
    "#         multiple_axes[n].yaxis.set_visible(True)\n",
    "#         single_axes[n].set_ylabel(r'$p(k|N, w)$', visible=True)\n",
    "#         single_axes[n].yaxis.set_visible(True)\n",
    "#         single_axes[n].yaxis.set_major_locator(plt.NullLocator())\n",
    "#         multiple_axes[n].yaxis.set_major_locator(plt.NullLocator())\n",
    "#         if n < len(labels) - 1:\n",
    "#             single_axes[n].xaxis.set_major_locator(plt.NullLocator())\n",
    "#             multiple_axes[n].xaxis.set_major_locator(plt.NullLocator())\n",
    "    \n",
    "# #     if QUESTION == 'bars':\n",
    "# #         question = 'Bar'\n",
    "# #     else:\n",
    "# #         question = 'Smooth'\n",
    "# #     single_axes[-1].set_xlabel(r\"$k$ '{}' votes, of $N$ total\".format(question))\n",
    "# #     multiple_axes[-1].set_xlabel(r\"$k$ '{}' votes, of $N$ total\".format(question))\n",
    "#     fig.tight_layout()\n",
    "\n",
    "    \n",
    "#     multiple_axes[0].legend(\n",
    "#         loc='lower center', \n",
    "#         bbox_to_anchor=(0.5, 1.1),\n",
    "#         ncol=1, \n",
    "#         fancybox=True, \n",
    "#         shadow=False\n",
    "#     )\n",
    "\n",
    "    fig.tight_layout()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = galaxy_posterior_grid(df[:5], schema)\n",
    "fig.savefig(save_dir + '/grid.pdf')\n",
    "fig.savefig(save_dir + '/grid.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def custom_samples_with_galaxies(samples, labels, total_votes, png_locs):\n",
    "    \n",
    "    sns.set_context('paper', font_scale=1.5)\n",
    "    \n",
    "    im_width = 2\n",
    "    single_width = 3\n",
    "    multiple_width = 3\n",
    "    height = im_width\n",
    "    \n",
    "    fig = plt.figure(figsize=(0.8 * len(labels) * height * 2., 0.8 * (im_width + single_width + multiple_width) * 1.75))\n",
    "    gs = gridspec.GridSpec(len(labels) * height, im_width + single_width + multiple_width)  # y, x format\n",
    "    image_axes = []\n",
    "    single_axes = []\n",
    "    multiple_axes = []\n",
    "    for galaxy_n in range(len(labels)):\n",
    "        x_slice = slice(galaxy_n*height, (galaxy_n+1)*height)\n",
    "        image_axes.append(plt.subplot(gs[x_slice, :im_width]))\n",
    "        single_axes.append(plt.subplot(gs[x_slice, im_width:im_width+single_width]))\n",
    "        multiple_axes.append(plt.subplot(gs[x_slice, im_width+single_width:]))\n",
    "    \n",
    "\n",
    "#     fig, axes = plt.subplots(nrows=len(labels), figsize=(3, len(labels)*1.5), sharex=True)\n",
    "    make_predictions.plot_samples(samples[:, :1], labels, total_votes, fig, single_axes, alpha=0.06)\n",
    "    for ax in single_axes:\n",
    "        ax.set_xlim([0, 50])\n",
    "\n",
    "    make_predictions.plot_samples(samples, labels, total_votes, fig, multiple_axes, alpha=0.06)\n",
    "    for ax in multiple_axes:\n",
    "        ax.set_xlim([0, 50])\n",
    "        \n",
    "        \n",
    "    for ax_n, ax in enumerate(image_axes):\n",
    "        plot_galaxy(png_locs[ax_n], ax)\n",
    "        \n",
    "    \n",
    "    for n in range(len(labels)):\n",
    "        multiple_axes[n].set_ylabel(r'$p(k|N, D)$', visible=True)\n",
    "        multiple_axes[n].yaxis.set_visible(True)\n",
    "        single_axes[n].set_ylabel(r'$p(k|N, w)$', visible=True)\n",
    "        single_axes[n].yaxis.set_visible(True)\n",
    "        single_axes[n].yaxis.set_major_locator(plt.NullLocator())\n",
    "        multiple_axes[n].yaxis.set_major_locator(plt.NullLocator())\n",
    "        if n < len(labels) - 1:\n",
    "            single_axes[n].xaxis.set_major_locator(plt.NullLocator())\n",
    "            multiple_axes[n].xaxis.set_major_locator(plt.NullLocator())\n",
    "    \n",
    "#     if QUESTION == 'bars':\n",
    "#         question = 'Bar'\n",
    "#     else:\n",
    "#         question = 'Smooth'\n",
    "#     single_axes[-1].set_xlabel(r\"$k$ '{}' votes, of $N$ total\".format(question))\n",
    "#     multiple_axes[-1].set_xlabel(r\"$k$ '{}' votes, of $N$ total\".format(question))\n",
    "    fig.tight_layout()\n",
    "\n",
    "    single_axes[0].legend(\n",
    "        loc='lower center', \n",
    "        bbox_to_anchor=(0.5, 1.1),\n",
    "        ncol=1, \n",
    "        fancybox=True, \n",
    "        shadow=False\n",
    "    )\n",
    "    \n",
    "    multiple_axes[0].legend(\n",
    "        loc='lower center', \n",
    "        bbox_to_anchor=(0.5, 1.1),\n",
    "        ncol=1, \n",
    "        fancybox=True, \n",
    "        shadow=False\n",
    "    )\n",
    "\n",
    "    \n",
    "    fig.tight_layout()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_galaxy(image_loc, ax, n_examples=10, crop=0):\n",
    "    im_size = 424\n",
    "    im = Image.open(image_loc)\n",
    "#     if QUESTION == 'bars':\n",
    "#         crop = 120\n",
    "#     else:\n",
    "    crop = 35\n",
    "    cropped_im = im.crop((crop, crop, 424 - crop, 424 - crop))\n",
    "    ax.imshow(cropped_im)\n",
    "    ax.grid(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    ax.get_xaxis().set_visible(False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = 'has-spiral-arms'\n",
    "answer = 'yes'\n",
    "n = 5\n",
    "samples, labels, total_votes = get_single_answer_data(question, answer)\n",
    "png_locs = df['file_loc'][:n]\n",
    "\n",
    "# catalog = sim_model.catalog[selected_slice]\n",
    "\n",
    "_ = custom_samples_with_galaxies(samples, labels, total_votes, png_locs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, axes = plt.subplots(1, 10, figsize=(20, 12))\n",
    "# for ax_n, ax in enumerate(axes):\n",
    "#     plot_galaxy(sim_model.catalog.iloc[ax_n]['png_loc'], ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected = slice(80, 73, -1)  #Â smooth\n",
    "\n",
    "# selected = slice(0, 7)\n",
    "\n",
    "if QUESTION == 'bars':\n",
    "    selected = slice(0, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.array(sim_model.model.samples)[selected, :]\n",
    "# np.array(sim_model.labels)[selected]\n",
    "# sim_model.catalog['smooth-or-featured_total-votes'][selected]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = custom_samples_with_galaxies(sim_model, selected)\n",
    "# fig.savefig(os.path.join(save_dir, 'mc_model_{}.png'.format(len(np.array(sim_model.labels)[selected]))))\n",
    "# fig.savefig(os.path.join(save_dir, 'mc_model_{}.pdf'.format(len(np.array(sim_model.labels)[selected]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# be sure to switch label in custom_samples before running this\n",
    "# fig = custom_samples(np.array(single_sim_model.model.samples)[selected, :1], np.array(single_sim_model.labels)[selected], total_votes=single_sim_model.total_votes)\n",
    "# fig.savefig(os.path.join(save_dir, 'single_model_{}.png'.format(len(np.array(sim_model.labels)[selected]))))\n",
    "# fig.savefig(os.path.join(save_dir, 'single_model_{}.eps'.format(len(np.array(sim_model.labels)[selected]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(font_scale=1.2)\n",
    "sns.set_style('white')\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ungrouped_coverage_df = discrete_coverage.evaluate_discrete_coverage(\n",
    "    sim_model.labels, \n",
    "    sim_model.bin_probs)\n",
    "coverage_df = ungrouped_coverage_df.groupby('max_state_error').agg({'prediction': 'sum', 'observed': 'sum'}).reset_index()\n",
    "\n",
    "ungrouped_single_coverage_df = discrete_coverage.evaluate_discrete_coverage(\n",
    "    single_sim_model.labels, \n",
    "    single_sim_model.bin_probs)\n",
    "single_coverage_df = ungrouped_single_coverage_df.groupby('max_state_error').agg({'prediction': 'sum', 'observed': 'sum'}).reset_index()\n",
    "\n",
    "\n",
    "plt.plot(coverage_df['max_state_error'], coverage_df['prediction'], label='MC Model Expects')\n",
    "plt.plot(single_coverage_df['max_state_error'], single_coverage_df['prediction'], label='Single Model Expects')\n",
    "plt.plot(single_coverage_df['max_state_error'], coverage_df['observed'], 'k--', label='Actual')\n",
    "\n",
    "ax.set_xlabel('Max Allowed Vote Error')\n",
    "ax.set_ylabel('Galaxies Within Max Error')\n",
    "ax.legend()\n",
    "ax.xaxis.set_major_formatter(StrMethodFormatter('{x:.0f}'))  # must expect 'x' kw arg\n",
    "\n",
    "ax.set_xlim([0, 15])\n",
    "fig.tight_layout()\n",
    "fig.savefig(os.path.join(save_dir, 'coverage_comparison_200_samples.png'))\n",
    "fig.savefig(os.path.join(save_dir, 'coverage_comparison_200_samples.pdf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ungrouped_coverage_df.to_csv(os.path.join(save_dir, QUESTION + '_ungrouped_coverage_df.csv'), index=False)\n",
    "ungrouped_single_coverage_df.to_csv(os.path.join(save_dir, QUESTION + '_ungrouped_coverage_df.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coverage_df['error'] = coverage_df['prediction'] - coverage_df['observed']\n",
    "coverage_df['relative_error'] = coverage_df['error'] / coverage_df['observed']\n",
    "coverage_df.to_csv(os.path.join(save_dir, QUESTION + '_coverage_df.csv'), index=False)\n",
    "coverage_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_coverage_df['error'] = single_coverage_df['prediction'] - single_coverage_df['observed']\n",
    "single_coverage_df['relative_error'] = single_coverage_df['error'] / single_coverage_df['observed']\n",
    "single_coverage_df.to_csv(os.path.join(save_dir, QUESTION + '_single_coverage_df.csv'), index=False)\n",
    "single_coverage_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO - I might consider adding an MSE model as a comparison, to hopefully beat. I think this might be quite similar though. Ideally I can compare this with previous work somehow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(font_scale=1.2)\n",
    "sns.set_style('white')\n",
    "fig, ax = plt.subplots()\n",
    "ax.hist(sim_model.abs_rho_error, bins=25)\n",
    "# ax.axvline(sim_model.mean_abs_rho_error, color='r') \n",
    "ax.set_xlim([0, 1.])\n",
    "ax.set_ylabel('Galaxies')\n",
    "ax.set_xlabel(r'| Expected $\\hat{\\rho}$ - observed vote fraction $\\frac{k}{N}$ |')\n",
    "fig.tight_layout()\n",
    "fig.savefig(os.path.join(save_dir, 'difference_in_rho.png'))\n",
    "fig.savefig(os.path.join(save_dir, 'difference_in_rho.pdf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_model.abs_rho_error.mean(), single_sim_model.abs_rho_error.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(sim_model.mean_abs_rho_error), np.sqrt(single_sim_model.mean_abs_rho_error)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(sim_model.mean_square_rho_error), np.sqrt(single_sim_model.mean_square_rho_error) # this is the rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alpha = 0.3\n",
    "# n_bins = 25\n",
    "\n",
    "# # dummy for bins\n",
    "# fig, ax = plt.subplots()\n",
    "# _, bins, _  = ax.hist(sim_model.labels / sim_model.total_votes, bins=n_bins, alpha=alpha, label=r'Observed $\\rho$')\n",
    "# ax.hist(sim_model.mean_rho_prediction, bins=n_bins, alpha=alpha, label=r'Mean Rho Prediction $\\hat{\\rho}}$')\n",
    "# # ax.hist(single_sim_model.mean_rho_prediction, bins=bins, alpha=alpha, label=r'Single Rho Prediction $\\hat{\\rho}}$')\n",
    "\n",
    "# fig, ax = plt.subplots()\n",
    "# sns.set(font_scale=1.)\n",
    "# sns.set_style('white')\n",
    "\n",
    "# ax.hist(sim_model.mean_rho_prediction, bins=bins, alpha=alpha, label=r'Mean Rho Prediction $\\hat{\\rho}}$')\n",
    "# # ax.hist(single_sim_model.mean_rho_prediction, bins=bins, alpha=alpha, label=r'Single Rho Prediction $\\hat{\\rho}}$')\n",
    "# ax.hist(sim_model.labels / sim_model.total_votes, bins=bins, alpha=alpha, label=r'Observed $\\rho$')\n",
    "# ax.legend()\n",
    "# ax.set_xlim([0., 1.])\n",
    "# ax.set_ylabel('Galaxies')\n",
    "# ax.set_xlabel(r'Typical vote fraction $\\rho$')\n",
    "# fig.tight_layout()\n",
    "# fig.savefig(os.path.join(save_dir, 'typical_vote_fraction_distribution.png'))\n",
    "\n",
    "# This is a repeat of the above histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(sim_model.mean_rho_prediction > 0.5), np.sum(single_sim_model.mean_rho_prediction > 0.5), np.sum((sim_model.labels / sim_model.total_votes) > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(sim_model.labels / sim_model.total_votes).min(), (sim_model.labels / sim_model.total_votes).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_model.mean_rho_prediction.min(), sim_model.mean_rho_prediction.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_sim_model.mean_rho_prediction.min(), single_sim_model.mean_rho_prediction.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_model.total_votes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save DataFrame of predictions + catalog (GZ2) for use elsewhere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_df = pd.DataFrame(data={\n",
    "    'total_votes': sim_model.total_votes, \n",
    "    'k': sim_model.labels, \n",
    "    'vote_fraction': (sim_model.labels / sim_model.total_votes), \n",
    "    'rho_prediction': sim_model.mean_rho_prediction\n",
    "#     'png_loc': sim_model.catalog.png_loc\n",
    "})\n",
    "safe_catalog_cols = list(set(sim_model.catalog.columns.values) - set(['total_votes', 'ra_subject', 'dec_subject']))\n",
    "df = pd.concat([response_df, sim_model.catalog[safe_catalog_cols]], axis=1)\n",
    "df['smooth'] = df['vote_fraction'] > 0.5\n",
    "df['confidence_proxy'] = np.abs(0.5 - df['rho_prediction'])\n",
    "df['rho_predictions'] = 0\n",
    "for n in range(len(df)):\n",
    "    df['rho_predictions'][n] = json.dumps(list(sim_model.model.samples[n, :]))\n",
    "    df = df.sort_values('confidence_proxy', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['rho_predictions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_parquet('/data/repos/zoobot/notebooks/{}_test_predictions_and_gz2_catalog.parquet'.format(QUESTION))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replicate (ish) Sanchez 2017 ROC Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix((sim_model.labels / sim_model.total_votes) > 0.5, sim_model.mean_rho_prediction > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " 1 - ((66 + 99) / (490 + 1845 + 66 + 99))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " 1 - ((189 + 81) / (1858 + 189 + 81 + 372))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "sns.set(font_scale=1.2)\n",
    "sns.set_style('white')\n",
    "\n",
    "fpr, tpr, _ = roc_curve(df['smooth'], df['rho_prediction'])\n",
    "ax.plot(fpr, tpr, label='All')\n",
    "df_low_entropy = df[df['confidence_proxy'] > 0.3]\n",
    "fpr, tpr, _ = roc_curve(df_low_entropy['smooth'], df_low_entropy['rho_prediction'])\n",
    "ax.plot(fpr, tpr, label=r'\"High Confidence\" i.e. $\\hat{\\rho} < 0.2$ or $\\hat{\\rho} > 0.8$')\n",
    "ax.set_xlabel('False Positive Rate')\n",
    "ax.set_ylabel('True Positive Rate')\n",
    "ax.legend()\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(os.path.join(save_dir, 'roc_curve.png'))\n",
    "fig.savefig(os.path.join(save_dir, 'roc_curve.pdf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df), len(df_low_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replicate(ish) Khan 2018 Confusion Matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> After selecting the OBJIDs from Table 2 based on the probability thresholds of 0.985 and 0.926 for spirals and ellipticals respectively,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdf_array = binom.cdf((df['total_votes'] / 2.).astype(int), df['total_votes'], df['rho_prediction'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df['total_votes'] / 2.).astype(int).sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['total_votes'].sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['rho_prediction'].sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(cdf_array, bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binom.cdf(20, 40, 0.88)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(1 - cdf_array > 0.985)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(cdf_array > 0.926)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_prob_df = df[(cdf_array < (1 - 0.985)) | (cdf_array > 0.926)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(high_prob_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if QUESTION == 'smooth':\n",
    "    spiral_pc_to_keep = 516 / 6677\n",
    "    n_spirals = int(len(df) * spiral_pc_to_keep)\n",
    "    elliptical_pc_to_keep = 550 / 5904\n",
    "    n_ellipticals = int(len(df) * elliptical_pc_to_keep)\n",
    "    print(spiral_pc_to_keep, n_spirals, elliptical_pc_to_keep, n_ellipticals)\n",
    "    high_prob_df = pd.concat([\n",
    "        df.sort_values('rho_prediction')[:n_spirals],\n",
    "        df.sort_values('rho_prediction', ascending=False)[:n_ellipticals]\n",
    "    ])\n",
    "if QUESTION == 'bars':\n",
    "    n_to_keep = int(len(df) * 0.08)\n",
    "    high_prob_df = pd.concat([\n",
    "        df.sort_values('rho_prediction')[:int(n_to_keep/2)],\n",
    "        df.sort_values('rho_prediction', ascending=False)[:int(n_to_keep/2)]\n",
    "    ])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_prob_df.sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(high_prob_df['vote_fraction'] >= 0.5, high_prob_df['rho_prediction'] >= 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error = high_prob_df[~(high_prob_df['vote_fraction'] > 0.5) & (high_prob_df['rho_prediction'] > 0.5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error['vote_fraction'] > 0.5, error['rho_prediction'] > 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open(error.iloc[0]['png_loc'])\n",
    "plt.imshow(img)\n",
    "fontdict = {'size': 16, 'color': 'white'}\n",
    "plt.text(30, 360, r'Expected vote frac $\\hat{\\rho}$: 0.80', fontdict=fontdict)\n",
    "plt.text(30, 400, r'Observed vote frac $\\frac{k}{N}$: 0.50', fontdict=fontdict)\n",
    "plt.axis('off')\n",
    "plt.savefig(os.path.join(save_dir, 'high_prob_error_0.png'))\n",
    "plt.savefig(os.path.join(save_dir, 'high_prob_error_0.eps'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img = Image.open(error.iloc[1]['png_loc'])\n",
    "# plt.imshow(img)\n",
    "# fontdict = {'size': 16, 'color': 'white'}\n",
    "# plt.text(30, 360, r'Expected vote frac $\\hat{\\rho}$: 0.13', fontdict=fontdict)\n",
    "# plt.text(30, 400, r'Observed vote frac $\\frac{k}{N}$: 0.54', fontdict=fontdict)\n",
    "# plt.axis('off')\n",
    "# plt.savefig(os.path.join(save_dir, 'high_prob_error_1.png'))\n",
    "# plt.savefig(os.path.join(save_dir, 'high_prob_error_1.eps'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(df['vote_fraction'][:int(len(df) / 2)] > 0.5, df['rho_prediction'][:int(len(df) / 2)] > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if QUESTION == 'smooth':\n",
    "    labels = ['Smooth', 'Featured']\n",
    "    \n",
    "#     cm = np.array([[ 232,    2], [   0, 191]])\n",
    "#     name = 'confusion_matrix_high_confidence'\n",
    "    \n",
    "    cm = np.array([[ 490,   66],\n",
    "       [  99, 1845]])\n",
    "    name = 'confusion_matrix'\n",
    "    \n",
    "if QUESTION == 'bars':\n",
    "    labels = ['No Bar', 'Bar']\n",
    "    cm = np.array([[100,    0], [   0,   100]])\n",
    "    name = 'confusion_matrix_high_confidence'\n",
    "    \n",
    "#     cm = np.array([[1858,    81], [   189,   372]])\n",
    "#     name = 'confusion_matrix'\n",
    "\n",
    "sns.set(font_scale=3.)\n",
    "sns.set_style('white')\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "ax = sns.heatmap(cm, annot=True, fmt='d', cmap=\"Blues\", xticklabels=labels, yticklabels=labels, cbar=False, square=True, ax=ax)\n",
    "ax.set_xlabel('Predicted')\n",
    "ax.set_ylabel('Observed')\n",
    "fig.tight_layout()\n",
    "fig.savefig(os.path.join(save_dir, '{}.png'.format(name)))\n",
    "fig.savefig(os.path.join(save_dir, '{}.pdf'.format(name)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1 - (8 / (1159 + 83 + 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sim_model.export_performance_metrics(save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw a galaxy, infer a range of p, redraw, and measure accuracy - work in progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot other standard acquisition visualisations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_acquisition_viz = False\n",
    "if new_acquisition_viz:\n",
    "    image_locs = sim_model.catalog['png_loc']\n",
    "    images = np.stack([np.array(Image.open(loc)) for loc in image_locs])\n",
    "    assert images.shape == (2500, 424, 424, 3)\n",
    "    acquisition_utils.save_acquisition_examples(images, sim_model.mutual_info, 'mutual_info', save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, row = plt.subplots(ncols=3, figsize=(12, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# row = sim_model.acquisition_vs_volunteer_votes(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualise Selection of Catalog Features w.r.t. Acquisition Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(constrained_layout=True, figsize=(20, 12))\n",
    "gs = gridspec.GridSpec(6, 5, figure=fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Smooth Votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax0 = plt.subplot(gs[:4, :])\n",
    "sns.scatterplot(\n",
    "    np.array(sim_model.catalog['smooth-or-featured_smooth_fraction'] * 40).astype(int),\n",
    "    sim_model.model.acquisitions, hue=np.array(sim_model.model.acquisitions) > np.array(sim_model.model.acquisitions[103]),\n",
    "    ax=ax0)\n",
    "ax0.set_ylabel('Mutual Information')\n",
    "ax0.set_xlabel('Smooth Votes')\n",
    "ax0.legend([r'Top 10% $\\mathcal{I}$', r'Bottom 90% $\\mathcal{I}$'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax1 = plt.subplot(gs[4:, :])\n",
    "ax1.hist(np.array(sim_model.labels * 40).astype(int), density=True, alpha=0.4)\n",
    "ax1.hist(np.array(sim_model.labels * 40).astype(int)[:200], density=True, alpha=0.4)\n",
    "ax1.set_ylabel('Frequency')\n",
    "ax1.set_xlabel('Smooth Votes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.savefig(os.path.join(save_dir, 'temp.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Redshift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "sns.jointplot(np.array(sim_model.labels * 40).astype(int), sim_model.catalog['redshift'], kind='kde')\n",
    "ax0.set_ylabel('Redshift')\n",
    "ax0.set_xlabel('Volunteer Votes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax0 = plt.subplot(gs[:2, :])\n",
    "sns.jointplot(np.array(sim_model.labels * 40).astype(int), sim_model.catalog['redshift'], kind='kde', ax=ax0)\n",
    "ax0.set_ylabel('Redshift')\n",
    "ax0.set_xlabel('Volunteer Votes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax0 = plt.subplot(gs[:2, :])\n",
    "sns.jointplot(sim_model.catalog['redshift'], sim_model.model.acquisitions, ax=ax0)\n",
    "ax0.set_ylabel('Mutual Information')\n",
    "ax0.set_xlabel('Redshift')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax1 = plt.subplot(gs[4:, :])\n",
    "\n",
    "ax1.hist(sim_model.catalog['redshift'], density=True, alpha=0.4)\n",
    "# ax1.hist(sim_model.catalog['redshift'], density=True, alpha=0.4)\n",
    "ax1.set_ylabel('Frequency')\n",
    "ax1.set_xlabel('Smooth Votes')\n",
    "# TODO sort by mutual information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Below here is only relevant for DECALS, with extra questions. TODO update with GZ2 merger options?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merger_strs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merger_label = 'merging_major-disturbance'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax0 = plt.subplot(gs[:2, :])\n",
    "sns.scatterplot(sim_model.catalog[merger_label], sim_model.model.mutual_info, ax=ax0)\n",
    "ax0.set_ylabel('Mutual Information')\n",
    "ax0.set_xlabel(merger_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.hist(sim_model.catalog[merger_label], bins=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featured_no_merger = sim_model.model.mutual_info[(sim_model.catalog[merger_label] == 0) & (sim_model.catalog['smooth-or-featured_smooth_fraction'] < 0.4)]\n",
    "featured_merger = sim_model.model.mutual_info[(sim_model.catalog[merger_label] > 0) & (sim_model.catalog['smooth-or-featured_smooth_fraction'] < 0.4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featured_no_merger.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featured_merger.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax.hist(featured_no_merger, alpha=0.3, density=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax.hist(featured_merger, alpha=0.3, density=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.scatterplot(\n",
    "    sim_model.catalog['smooth-or-featured_artifact'], \n",
    "    sim_model.model.mutual_info, \n",
    "    hue=sim_model.model.mutual_info > sim_model.model.mutual_info[103])\n",
    "ax.set_xlim([0, 14.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(\n",
    "    sim_model.catalog['smooth-or-featured_artifact'], \n",
    "    sim_model.model.mutual_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax.hist(\n",
    "    sim_model.catalog['smooth-or-featured_artifact'][sim_model.model.mutual_info > sim_model.model.mutual_info[100]],\n",
    "    density=True,\n",
    "    alpha=0.4,\n",
    ")\n",
    "ax.hist(\n",
    "    sim_model.catalog['smooth-or-featured_artifact'][sim_model.model.mutual_info < sim_model.model.mutual_info[100]],\n",
    "    density=True,\n",
    "    alpha=0.4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "has-spiral-arms_yes\n",
    "spiral-winding_prediction-encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(\n",
    "    sim_model.catalog['has-spiral-arms_yes'][sim_model.catalog['smooth-or-featured_smooth_fraction'] < 0.5], \n",
    "    sim_model.model.mutual_info[sim_model.catalog['smooth-or-featured_smooth_fraction'] < 0.5], \n",
    "    hue=sim_model.model.mutual_info > sim_model.model.mutual_info[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.hist(\n",
    "    sim_model.catalog['has-spiral-arms_yes'][sim_model.model.mutual_info > sim_model.model.mutual_info[100]],\n",
    "    density=True,\n",
    "    alpha=0.4,\n",
    ")\n",
    "ax.hist(\n",
    "    sim_model.catalog['has-spiral-arms_yes'][sim_model.model.mutual_info < sim_model.model.mutual_info[100]],\n",
    "    density=True,\n",
    "    alpha=0.4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.hist(\n",
    "    sim_model.catalog['redshift'][sim_model.model.mutual_info > sim_model.model.mutual_info[100]],\n",
    "    density=True,\n",
    "    alpha=0.4,\n",
    ")\n",
    "ax.hist(\n",
    "    sim_model.catalog['redshift'][sim_model.model.mutual_info < sim_model.model.mutual_info[100]],\n",
    "    density=True,\n",
    "    alpha=0.4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.hist(\n",
    "    sim_model.catalog['merging_major-disturbance'][sim_model.model.mutual_info > sim_model.model.mutual_info[100]],\n",
    "    density=True,\n",
    "    alpha=0.4,\n",
    ")\n",
    "ax.hist(\n",
    "    sim_model.catalog['merging_major-disturbance'][sim_model.model.mutual_info < sim_model.model.mutual_info[100]],\n",
    "    density=True,\n",
    "    alpha=0.4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for merger_label in merger_strs:\n",
    "    print('\\n' + merger_label)\n",
    "    print(sim_model.model.mutual_info[sim_model.catalog[merger_label] > 1].mean())\n",
    "    print(sim_model.model.mutual_info[sim_model.catalog[merger_label] == 1].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "    {'Volunteer Response': 'Merging', 'Mean Mutual Information': sim_model.model.mutual_info[sim_model.catalog['merging_both-v1'] > 1].mean()},\n",
    "    {'Volunteer Response': 'Major Disturbance', 'Mean Mutual Information': sim_model.model.mutual_info[sim_model.catalog['merging_major-disturbance'] > 1].mean()},\n",
    "    {'Volunteer Response': 'Minor Disturbance', 'Mean Mutual Information': sim_model.model.mutual_info[sim_model.catalog['merging_minor-disturbance'] > 1].mean()},\n",
    "    {'Volunteer Response': 'No Disturbance', 'Mean Mutual Information': sim_model.model.mutual_info[sim_model.catalog['merging_none'] > 20].mean()}\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax = sns.barplot(data=df, y='Volunteer Response', x='Mean Mutual Information', ax=ax)\n",
    "ax.set_xlim([0.2, 0.36])\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sim_model.model.mutual_info[(sim_model.catalog['merging_minor-disturbance'] + sim_model.catalog['merging_major-disturbance']) > 0].mean())\n",
    "print(sim_model.model.mutual_info[(sim_model.catalog['merging_minor-disturbance'] + sim_model.catalog['merging_major-disturbance']) == 0].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(sim_model.catalog['merging_tidal-debris-v1'], bins=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('zoobot': conda)",
   "language": "python",
   "name": "python37664bitzoobotcondad3adbdfef5c444648572db3b6ec7c1e0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
